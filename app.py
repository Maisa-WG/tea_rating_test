import streamlit as st
import os
import json
import numpy as np
import faiss
import time
import pickle
from pathlib import Path
from io import BytesIO
from typing import List, Dict, Any, Tuple, Optional
from PyPDF2 import PdfReader
from http import HTTPStatus
import dashscope
from dashscope import TextEmbedding
from openai import OpenAI
from docx import Document
import matplotlib.pyplot as plt
from scipy.interpolate import make_interp_spline

# ==========================================
# [SECTION 0] åŸºç¡€é…ç½®ä¸è·¯å¾„å®šä¹‰
# ==========================================

st.set_page_config(
    page_title="èŒ¶é¥®å…­å› å­AIè¯„åˆ†å™¨ Pro",
    page_icon="ğŸµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ ·å¼å®šä¹‰
st.markdown("""
    <style>
    .main-title {font-size: 2.5em; font-weight: bold; text-align: center; color: #2E7D32; margin-bottom: 0.5em;}
    .slogan {font-size: 1.2em; font-style: italic; text-align: center; color: #558B2F; margin-bottom: 30px; font-family: "KaiTi", "æ¥·ä½“", serif;}
    .factor-card {background-color: #F1F8E9; padding: 15px; border-radius: 10px; margin-bottom: 10px; border-left: 5px solid #4CAF50;}
    .score-header {display:flex; justify-content:space-between; font-weight:bold; color:#2E7D32;}
    .advice-tag {font-size: 0.85em; padding: 2px 6px; border-radius: 4px; margin-top: 5px; background-color: #fff; border: 1px dashed #4CAF50; color: #388E3C; display: inline-block;}
    .master-comment {background-color: #FFFDE7; border: 1px solid #FFF9C4; padding: 15px; border-radius: 8px; font-family: "KaiTi", serif; font-size: 1.1em; color: #5D4037; margin-bottom: 20px; line-height: 1.6;}
    .ft-card {border: 1px solid #ddd; padding: 15px; border-radius: 8px; background-color: #f8f9fa; margin-top: 10px;}
    </style>
""", unsafe_allow_html=True)

class PathConfig:
    """è·¯å¾„ç®¡ç†ç±»"""
    # å¤–éƒ¨èµ„æºæ–‡ä»¶ï¼ˆä½äºåŒçº§ç›®å½•ï¼‰
    SRC_SYS_PROMPT = Path("sys_p.txt")
    SRC_SEED_CASES = Path("seed_case.json")

    # è¿è¡Œæ—¶æ•°æ®ç›®å½•
    DATA_DIR = Path("./tea_data")
    
    def __init__(self):
        self.DATA_DIR.mkdir(exist_ok=True)
        # å‘é‡åº“ä¸æŒä¹…åŒ–æ•°æ®
        self.kb_index = self.DATA_DIR / "kb.index"
        self.kb_chunks = self.DATA_DIR / "kb_chunks.pkl"
        self.case_index = self.DATA_DIR / "cases.index"
        self.case_data = self.DATA_DIR / "cases.json"
        
        # å¾®è°ƒä¸Prompté…ç½®
        self.training_file = self.DATA_DIR / "deepseek_finetune.jsonl"
        self.ft_status = self.DATA_DIR / "ft_status.json"
        self.prompt_config_file = self.DATA_DIR / "prompts.json"

PATHS = PathConfig()

# é»˜è®¤çš„ç”¨æˆ·Promptæ¨¡æ¿ï¼ˆSystem Promptå°†ä»æ–‡ä»¶è¯»å–ï¼‰
DEFAULT_USER_TEMPLATE = """ã€å¾…è¯„åˆ†äº§å“ã€‘
{product_desc}

ã€å‚è€ƒæ ‡å‡†ï¼ˆçŸ¥è¯†åº“ï¼‰ã€‘
{context_text}

ã€ç›¸ä¼¼åˆ¤ä¾‹å¾—åˆ†å‚è€ƒï¼ˆæ¡ˆä¾‹åº“ï¼‰ã€‘
{case_text}

è¯·ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹JSONæ ¼å¼ï¼ˆä¸å«Markdownï¼‰ï¼š
{{
  "master_comment": "çº¦100å­—çš„å®—å¸ˆçº§æ€»è¯„ï¼Œå¯Œå«æ–‡åŒ–æ„è•´...",
  "scores": {{
    "ä¼˜é›…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è¾¨è¯†åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "åè°ƒæ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "é¥±å’Œåº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "æŒä¹…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è‹¦æ¶©åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}}
  }}
}}"""

# ==========================================
# [SECTION 1] èµ„æºä¸æ•°æ®ç®¡ç†
# ==========================================

class ResourceManager:
    """è´Ÿè´£å¤–éƒ¨æ–‡ä»¶åŠ è½½ã€æ•°æ®æŒä¹…åŒ–åŠæ ¼å¼è½¬æ¢"""

    @staticmethod
    def load_external_text(path: Path, fallback: str = "") -> str:
        """è¯»å–å¤–éƒ¨æ–‡æœ¬æ–‡ä»¶ (å¦‚ sys_p.txt)"""
        if path.exists():
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read().strip()
            except Exception as e:
                st.error(f"åŠ è½½æ–‡ä»¶ {path} å¤±è´¥: {e}")
        return fallback

    @staticmethod
    def load_external_json(path: Path, fallback: Any = None) -> Any:
        """è¯»å–å¤–éƒ¨JSONæ–‡ä»¶ (å¦‚ seed_case.json)"""
        if path.exists():
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                st.error(f"åŠ è½½æ–‡ä»¶ {path} å¤±è´¥: {e}")
        return fallback if fallback is not None else []

    @staticmethod
    def save(index: Any, data: Any, idx_path: Path, data_path: Path, is_json: bool = False):
        """ä¿å­˜ FAISS ç´¢å¼•å’Œæ•°æ®æ–‡ä»¶"""
        if index: faiss.write_index(index, str(idx_path))
        with open(data_path, "w" if is_json else "wb") as f:
            if is_json: json.dump(data, f, ensure_ascii=False, indent=2)
            else: pickle.dump(data, f)
    
    @staticmethod
    def load(idx_path: Path, data_path: Path, is_json: bool = False) -> Tuple[Any, List]:
        """åŠ è½½ FAISS ç´¢å¼•å’Œæ•°æ®æ–‡ä»¶"""
        if idx_path.exists() and data_path.exists():
            try:
                index = faiss.read_index(str(idx_path))
                with open(data_path, "r" if is_json else "rb") as f:
                    data = json.load(f) if is_json else pickle.load(f)
                return index, data
            except: pass
        return faiss.IndexFlatL2(1024), []

# ä»¥ä¸‹ä¸‰ä¸ªæ–¹æ³•ç”¨äºå¾®è°ƒ
    @staticmethod
    def append_to_finetune(case_text: str, scores: Dict, sys_prompt: str, user_tpl: str, master_comment: str = "ï¼ˆäººå·¥æ ¡å‡†ï¼‰") -> bool:
        """å°†åˆ¤ä¾‹å†™å…¥å¾®è°ƒæ•°æ®é›† (.jsonl)"""
        try:
            user_content = user_tpl.format(product_desc=case_text, context_text="", case_text="")
            assistant_content = json.dumps({"master_comment": master_comment, "scores": scores}, ensure_ascii=False)
            entry = {
                "messages": [
                    {"role": "system", "content": sys_prompt},
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": assistant_content}
                ]
            }
            with open(PATHS.training_file, "a", encoding="utf-8") as f:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
            return True
        except Exception as e:
            print(f"[ERROR] Finetune append failed: {e}")
            return False

    @staticmethod
    def save_ft_status(job_id, status, fine_tuned_model=None):
        data = {"job_id": job_id, "status": status, "timestamp": time.time()}
        if fine_tuned_model: data["fine_tuned_model"] = fine_tuned_model
        with open(PATHS.ft_status, 'w') as f: json.dump(data, f)

    @staticmethod
    def load_ft_status():
        if PATHS.ft_status.exists():
            try: return json.load(open(PATHS.ft_status, 'r'))
            except: pass
        return None

# ==========================================
# [SECTION 2] AI æœåŠ¡ (Embedding & LLM)
# ==========================================

class AliyunEmbedder:
    def __init__(self, api_key):
        self.model_name = "text-embedding-v4"
        dashscope.api_key = api_key 

    def encode(self, texts: List[str]) -> np.ndarray:
        if not texts: return np.zeros((0, 1024), dtype="float32")
        if isinstance(texts, str): texts = [texts]
        try:
            resp = TextEmbedding.call(model=self.model_name, input=texts)
            if resp.status_code == HTTPStatus.OK:
                return np.array([i['embedding'] for i in resp.output['embeddings']]).astype("float32")
        except: pass
        return np.zeros((len(texts), 1024), dtype="float32")

def run_scoring(text: str, kb_res: Tuple, case_res: Tuple, prompt_cfg: Dict, embedder: AliyunEmbedder, client: OpenAI, model_id: str, k_num: int, c_num: int):
    """æ‰§è¡Œ RAG æ£€ç´¢ä¸ LLM è¯„åˆ†"""
    # 1. å‘é‡åŒ–ä¸ RAG æ£€ç´¢
    vec = embedder.encode([text]) 
    
    ctx_txt, hits = "ï¼ˆæ— æ‰‹å†Œèµ„æ–™ï¼‰", []
    if kb_res[0].ntotal > 0:
        _, idx = kb_res[0].search(vec, k_num)
        hits = [kb_res[1][i] for i in idx[0] if i < len(kb_res[1])]
        ctx_txt = "\n".join([f"- {h[:200]}..." for h in hits])

    # å¦‚æœåç»­ç”¨Loraå¾®è°ƒæ–¹æ³•çš„è¯æ˜¯å¦æ˜¯è€ƒè™‘åˆ é™¤è¿™ä¸€æ®µfew-shot    
    case_txt, found_cases = "ï¼ˆæ— ç›¸ä¼¼åˆ¤ä¾‹ï¼‰", []
    if case_res[0].ntotal > 0:
        _, idx = case_res[0].search(vec, c_num)
        for i in idx[0]:
            if i < len(case_res[1]) and i >= 0:
                c = case_res[1][i]
                found_cases.append(c)
                sc = c.get('scores', {})
                u_sc = sc.get('ä¼˜é›…æ€§',{}).get('score', 0) if isinstance(sc,dict) and 'ä¼˜é›…æ€§' in sc else 0
                k_sc = sc.get('è‹¦æ¶©åº¦',{}).get('score', 0) if isinstance(sc,dict) and 'è‹¦æ¶©åº¦' in sc else 0
                case_txt += f"\nå‚è€ƒæ¡ˆä¾‹: {c['text'][:30]}... -> ä¼˜é›…æ€§:{u_sc} è‹¦æ¶©åº¦:{k_sc}"

    # 2. ç»„è£… Prompt
    sys_p = prompt_cfg.get('system_template', "")
    user_p = prompt_cfg.get('user_template', "").format(product_desc=text, context_text=ctx_txt, case_text=case_txt)

    # 3. è°ƒç”¨ LLM
    try:
        resp = client.chat.completions.create(
            model=model_id,
            messages=[{"role":"system", "content":sys_p}, {"role":"user", "content":user_p}],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        return json.loads(resp.choices[0].message.content), hits, found_cases
    except Exception as e:
        st.error(f"Inference Error: {e}")
        return None, [], []

# ==========================================
# [SECTION 3] è¾…åŠ©ä¸å¯è§†åŒ–
# ==========================================

def parse_file(uploaded_file) -> str:
    """è§£æä¸Šä¼ æ–‡ä»¶"""
    try:
        if uploaded_file.name.endswith('.txt'): return uploaded_file.read().decode("utf-8")
        if uploaded_file.name.endswith('.pdf'): return "".join([p.extract_text() for p in PdfReader(uploaded_file).pages])
        if uploaded_file.name.endswith('.docx'): return "\n".join([p.text for p in Document(uploaded_file).paragraphs])
    except: return ""
    return ""

def create_word_report(results: List[Dict]) -> BytesIO:
    """ç”ŸæˆWordæŠ¥å‘Š"""
    doc = Document()
    doc.add_heading("èŒ¶è¯„æ‰¹é‡è¯„åˆ†æŠ¥å‘Š", 0)
    for item in results:
        doc.add_heading(f"æ¡ç›® {item['id']}", 1)
        doc.add_paragraph(f"åŸæ–‡ï¼š{item['text']}")
        s = item.get('scores', {}).get('scores', {})
        mc = item.get('scores', {}).get('master_comment', '')
        if mc: doc.add_paragraph(f"æ€»è¯„ï¼š{mc}", style="Intense Quote")
        
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'
        hdr = table.rows[0].cells
        hdr[0].text, hdr[1].text, hdr[2].text, hdr[3].text = 'å› å­', 'åˆ†æ•°', 'è¯„è¯­', 'å»ºè®®'
        for k, v in s.items():
            r = table.add_row().cells
            r[0].text = k
            r[1].text = str(v.get('score',''))
            r[2].text = v.get('comment','')
            r[3].text = v.get('suggestion','')
        doc.add_paragraph("_"*20)
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

def plot_flavor_shape(scores_data: Dict):
    """ç»˜åˆ¶é£å‘³å½¢æ€å›¾"""
    s = scores_data["scores"]
    top = (s["ä¼˜é›…æ€§"]["score"] + s["è¾¨è¯†åº¦"]["score"]) / 2
    mid = (s["åè°ƒæ€§"]["score"] + s["é¥±å’Œåº¦"]["score"]) / 2
    base = (s["æŒä¹…æ€§"]["score"] + s["è‹¦æ¶©åº¦"]["score"]) / 2
    
    fig, ax = plt.subplots(figsize=(4, 5))
    fig.patch.set_alpha(0); ax.patch.set_alpha(0)

    y = np.array([1, 2, 3]) 
    x = np.array([base, mid, top])
    y_new = np.linspace(1, 3, 300)
    try:
        spl = make_interp_spline(y, x, k=2)
        x_smooth = spl(y_new)
    except:
        x_smooth = np.interp(y_new, y, x)
    x_smooth = np.maximum(x_smooth, 0.1)

    colors = {'base': '#8B4513', 'mid': '#D2691E', 'top': '#FFD700'}
    for mask, col in [((y_new>=1.0)&(y_new<=1.6), colors['base']), 
                      ((y_new>1.6)&(y_new<=2.4), colors['mid']), 
                      ((y_new>2.4)&(y_new<=3.0), colors['top'])]:
        ax.fill_betweenx(y_new[mask], -x_smooth[mask], x_smooth[mask], color=col, alpha=0.9, edgecolor=None)

    ax.plot(x_smooth, y_new, 'k', linewidth=1, alpha=0.2)
    ax.plot(-x_smooth, y_new, 'k', linewidth=1, alpha=0.2)
    ax.axhline(y=1.6, color='w', linestyle=':', alpha=0.5)
    ax.axhline(y=2.4, color='w', linestyle=':', alpha=0.5)
    
    font = {'ha': 'center', 'va': 'center', 'color': 'white', 'fontweight': 'bold', 'fontsize': 12}
    ax.text(0, 2.7, f"Top\n{top:.1f}", **font)
    ax.text(0, 2.0, f"Mid\n{mid:.1f}", **font)
    ax.text(0, 1.3, f"Base\n{base:.1f}", **font)
    ax.axis('off'); ax.set_xlim(-10, 10); ax.set_ylim(0.8, 3.2)
    return fig

def bootstrap_seed_cases(embedder: AliyunEmbedder):
    """
    åˆå§‹åŒ–åˆ¤ä¾‹åº“ï¼šå¦‚æœå†…å­˜/ç£ç›˜ä¸­ä¸ºç©ºï¼Œåˆ™ä» seed_case.json æ–‡ä»¶è¯»å–ã€‚
    """
    case_idx, case_data = st.session_state.cases
    if len(case_data) > 0: return

    # ä»å¤–éƒ¨ JSON åŠ è½½
    seed_cases = ResourceManager.load_external_json(PATHS.SRC_SEED_CASES)
    if not seed_cases:
        st.warning("seed_case.json æœªæ‰¾åˆ°æˆ–ä¸ºç©ºï¼Œåˆ¤ä¾‹åº“åˆå§‹åŒ–è·³è¿‡ã€‚")
        return

    texts = [c["text"] for c in seed_cases]
    vecs = embedder.encode(texts)

    if case_idx.ntotal == 0: case_idx = faiss.IndexFlatL2(1024)
    if len(vecs) > 0:
        case_idx.add(vecs)
        case_data.extend(seed_cases)
        st.session_state.cases = (case_idx, case_data)
        ResourceManager.save(case_idx, case_data, PATHS.case_index, PATHS.case_data, is_json=True)

# ==========================================
# [SECTION 4] ä¸»ç¨‹åºé€»è¾‘
# ==========================================

# A. åˆå§‹åŒ– Session
if'loaded' not in st.session_state:
    # 1. åŠ è½½RAGä¸åˆ¤ä¾‹æ•°æ®
    kb_idx, kb_data = ResourceManager.load(PATHS.kb_index, PATHS.kb_chunks)
    case_idx, case_data = ResourceManager.load(PATHS.case_index, PATHS.case_data, is_json=True)
    st.session_state.kb = (kb_idx, kb_data)
    st.session_state.cases = (case_idx, case_data)
    
    # 2. åŠ è½½ Prompt é…ç½®
    # ä¼˜å…ˆè¯»å–æŒä¹…åŒ–çš„ prompts.jsonï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™ä» sys_p.txt æ„å»ºé»˜è®¤é…ç½® - å®ç°promptsä¿®æ”¹æ°¸ä¹…åŒ–
    if PATHS.prompt_config_file.exists():
        try:
            with open(PATHS.prompt_config_file, 'r') as f:
                st.session_state.prompt_config = json.load(f)
        except: pass
    
    if'prompt_config' not in st.session_state:
        # ä» sys_p.txt è¯»å– System Promptï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„ User Prompt
        sys_prompt_content = ResourceManager.load_external_text(PATHS.SRC_SYS_PROMPT, fallback="ä½ æ˜¯ä¸€åèŒ¶è¯„ä¸“å®¶...")
        st.session_state.prompt_config = {
            "system_template": sys_prompt_content,
            "user_template": DEFAULT_USER_TEMPLATE
        }
    

    st.session_state.loaded = True

# B. ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    st.markdown("**ğŸ” API é…ç½®**")
    aliyun_key = os.getenv("ALIYUN_API_KEY") or st.secrets.get("ALIYUN_API_KEY", "")
    deepseek_key = os.getenv("DEEPSEEK_API_KEY") or st.secrets.get("DEEPSEEK_API_KEY", "")

    if not aliyun_key or not deepseek_key:
        st.warning("âš ï¸ æœªé…ç½® API Key")
        st.stop()
    else:
        st.success("âœ… API å°±ç»ª")

    st.markdown("---")
    st.markdown(f"**é¢„å¤„ç†æ¨¡å‹ï¼š** `Deepseek-chat`")
    st.markdown(f"**è¯„åˆ†æ¨¡å‹ï¼š** `Qwen2.5-7B-Instruct`")
    model_id = "Qwen2.5-7B-Instruct"
    # åŠ è½½å¾®è°ƒæ¨¡å‹ï¼ˆå¦‚æœ‰ï¼‰
    ft_status = ResourceManager.load_ft_status()
    if ft_status and ft_status.get("status") == "succeeded":
        st.info(f"ğŸ‰ å‘ç°å¾®è°ƒæ¨¡å‹ï¼š`{ft_status.get('fine_tuned_model')}`")

    embedder = AliyunEmbedder(aliyun_key)
    client = OpenAI(api_key="dummy", base_url="http://117.50.89.74:8000/v1")
    # ç¡®ä¿åˆå§‹åŒ–åˆ¤ä¾‹
    bootstrap_seed_cases(embedder)
    # å±•ç¤ºå½“å‰RAGä¸åˆ¤ä¾‹å®¹é‡
    st.markdown("---")
    st.markdown(f"çŸ¥è¯†åº“: {len(st.session_state.kb[1])} | åˆ¤ä¾‹åº“: {len(st.session_state.cases[1])}")
    st.caption("å¿«é€Ÿä¸Šä¼ ä»…æ”¯æŒ.zipæ–‡ä»¶æ ¼å¼ã€‚")
    st.caption("å°‘é‡æ–‡ä»¶ä¸Šä¼ è¯·è‡³\"æ¨¡å‹è°ƒä¼˜\"æ¿å—ã€‚")
    # 
    if st.button("ğŸ“¤ å¯¼å‡ºæ•°æ®"):
        import zipfile, shutil
        temp_dir = Path("./temp_export"); temp_dir.mkdir(exist_ok=True)
        for p in [PATHS.kb_index, PATHS.kb_chunks, PATHS.case_index, PATHS.case_data, PATHS.prompt_config_file]:
            if p.exists(): shutil.copy2(p, temp_dir / p.name)
        zip_path = Path("./rag_export.zip")
        with zipfile.ZipFile(zip_path, 'w') as z:
            for f in temp_dir.iterdir(): z.write(f, f.name)
        with open(zip_path, 'rb') as f:
            st.download_button("â¬‡ï¸ ä¸‹è½½ZIP", f, "tea_data.zip", "application/zip")
        shutil.rmtree(temp_dir); zip_path.unlink()

    if st.button("ğŸ“¥ å¯¼å…¥æ•°æ®"):
        u_zip = st.file_uploader("ä¸Šä¼ ZIP", type=['zip'])
        if u_zip:
            import zipfile, tempfile
            with tempfile.TemporaryDirectory() as td:
                zp = Path(td)/"u.zip"
                with open(zp,'wb') as f: f.write(u_zip.getvalue())
                with zipfile.ZipFile(zp,'r') as z: z.extractall(PATHS.DATA_DIR)
                st.success("å¯¼å…¥æˆåŠŸï¼Œè¯·åˆ·æ–°"); st.rerun()

# C. ä¸»ç•Œé¢
st.markdown('<div class="main-title">ğŸµ èŒ¶å“å…­å› å­ AI è¯„åˆ†å™¨ Pro</div>', unsafe_allow_html=True)
st.markdown('<div class="slogan">â€œä¸€ç‰‡å¶å­è½å…¥æ°´ä¸­ï¼Œæ”¹å˜äº†æ°´çš„å‘³é“...â€</div>', unsafe_allow_html=True)

tab1, tab2, tab3 = st.tabs(["ğŸ’¡ äº¤äº’è¯„åˆ†", "ğŸš€ æ‰¹é‡è¯„åˆ†", "ğŸ› ï¸ æ¨¡å‹è°ƒä¼˜"])

# --- Tab 1: äº¤äº’è¯„åˆ† ---
with tab1:
    st.info("å°†å‚è€ƒçŸ¥è¯†åº“ä¸åˆ¤ä¾‹åº“è¿›è¡Œè¯„åˆ†ã€‚ç¡®è®¤ç»“æœå¯ä¸€é”®æ›´æ–°åˆ¤ä¾‹åº“ã€‚")
    c1, c2, c3, c4, c5 = st.columns([1, 3, 1, 3, 1])
    r_num = c2.number_input("å‚è€ƒçŸ¥è¯†åº“æ¡ç›®æ•°é‡", 1, 20, 3, key="r1")
    c_num = c4.number_input("å‚è€ƒåˆ¤ä¾‹åº“æ¡ç›®æ•°é‡", 1, 20, 2, key="c1")
    # ä½¿ç”¨ä¼šè¯çŠ¶æ€å­˜å‚¨ç”¨æˆ·è¾“å…¥ï¼Œé¿å…åˆ·æ–°åä¸¢å¤±
    if'current_user_input' not in st.session_state: st.session_state.current_user_input = ""
    user_input = st.text_area("è¯·è¾“å…¥èŒ¶è¯„æè¿°:", value=st.session_state.current_user_input, height=150, key="ui")
    st.session_state.current_user_input = user_input
    # ä½¿ç”¨ä¼šè¯çŠ¶æ€å­˜å‚¨è¯„åˆ†ç»“æœ
    if'last_scores' not in st.session_state: 
        st.session_state.last_scores = None
        st.session_state.last_master_comment = ""
    
    if st.button("å¼€å§‹è¯„åˆ†", type="primary", use_container_width=True):
        if not user_input: st.warning("è¯·è¾“å…¥å†…å®¹")
        else:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {model_id} å“é‰´..."):
                scores, kb_h, case_h = run_scoring(user_input, st.session_state.kb, st.session_state.cases, st.session_state.prompt_config, embedder, client, "Qwen2.5-7B-Instruct", r_num, c_num)
                if scores:
                    st.session_state.last_scores = scores
                    st.session_state.last_master_comment = scores.get("master_comment", "")
                    st.rerun()
    
    if st.session_state.last_scores:
        s = st.session_state.last_scores["scores"]
        mc = st.session_state.last_master_comment
        st.markdown(f'<div class="master-comment"><b>ğŸ‘µ å®—å¸ˆæ€»è¯„ï¼š</b><br>{mc}</div>', unsafe_allow_html=True)
        # å±•ç¤ºè¯„åˆ†ç»“æœ
        cols = st.columns(3)
        factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
        for i, f in enumerate(factors):
            if f in s:
                d = s[f]
                with cols[i%3]:
                    st.markdown(f"""<div class="factor-card"><div class="score-header"><span>{f}</span><span>{d['score']}/9</span></div><div>{d['comment']}</div><div class="advice-tag">ğŸ’¡ {d.get('suggestion','')}</div></div>""", unsafe_allow_html=True)
        
        left_col, right_col = st.columns([2, 8]) 
        with left_col:
            st.subheader("ğŸ“Š é£å‘³å½¢æ€")
            st.pyplot(plot_flavor_shape(st.session_state.last_scores), use_container_width=True)
        with right_col:
            st.subheader("ğŸ“ å¾—åˆ†æ ¡å‡†ä¸ä¿å­˜")
            if st.button("ğŸ’¾ è¯„åˆ†å‡†ç¡®ï¼ä¸€é”®ä¿å­˜ï¼"):
                nc = {"text": user_input, "scores": s, "tags": "äº¤äº’-åŸå§‹", "master_comment": mc, "created_at": time.strftime("%Y-%m-%d")}
                st.session_state.cases[1].append(nc)
                st.session_state.cases[0].add(embedder.encode([user_input]))
                ResourceManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS.case_index, PATHS.case_data, is_json=True)
                st.success("å·²ä¿å­˜"); st.rerun()

            st.markdown("---")
            st.subheader("ğŸ› ï¸ è¯„åˆ†æœ‰è¯¯ï¼éœ€è¦æ ¡å‡†ï¼")
            cal_master = st.text_area("æ ¡å‡†æ€»è¯„", mc)
            cal_scores = {}
            st.write("###### åˆ†é¡¹è°ƒæ•´") # åŠ ä¸ªå°æ ‡é¢˜æç¤º
            for f in factors:
                if f in s:
                    # ä½¿ç”¨ container(border=True) å½¢æˆå¡ç‰‡å¼å¸ƒå±€ï¼Œè§†è§‰æ›´æ•´æ´
                    with st.container(border=True):
                        # æ ‡é¢˜ä¸åˆ†æ•°æ”¾åœ¨ä¸€èµ·
                        st.markdown(f"**ğŸ“Œ {f}**") 
                        
                        cal_scores[f] = {
                            # å°†åˆ†æ•°æ»‘å—æ”¾åœ¨æœ€ä¸Šæ–¹
                            "score": st.number_input("åˆ†æ•°", 0, 9, int(s[f]['score']), 1, key=f"s_{f}", label_visibility="collapsed"),
                            # è¯„è¯­å’Œå»ºè®®ç›´æ¥åˆ—åœ¨ä¸‹æ–¹
                            # height=68 çº¦ä¸ºä¸¤è¡Œçš„é«˜åº¦ï¼ŒèŠ‚çœç©ºé—´ï¼Œç”¨æˆ·è¾“å…¥å¤šæ—¶ä¼šè‡ªåŠ¨æ»šåŠ¨
                            "comment": st.text_area(f"{f} è¯„è¯­", s[f]['comment'], key=f"c_{f}", height=68),
                            "suggestion": st.text_area(f"{f} å»ºè®®", s[f].get('suggestion',''), key=f"sg_{f}", height=68)
                        }
            
            if st.button("ğŸ’¾ ä¿å­˜æ ¡å‡†è¯„åˆ†", type="primary"):
                nc = {"text": user_input, "scores": cal_scores, "tags": "äº¤äº’-æ ¡å‡†", "master_comment": cal_master, "created_at": time.strftime("%Y-%m-%d")}
                st.session_state.cases[1].append(nc)
                st.session_state.cases[0].add(embedder.encode([user_input]))
                ResourceManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS.case_index, PATHS.case_data, is_json=True)
                ResourceManager.append_to_finetune(user_input, cal_scores, st.session_state.prompt_config['system_template'], st.session_state.prompt_config['user_template'], cal_master)
                st.success("æ ¡å‡†å·²ä¿å­˜"); st.rerun()

# --- Tab 2: æ‰¹é‡è¯„åˆ† ---
with tab2:
    f = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (.txt/.docx)")
    c1, c2 = st.columns(2)
    r_n = c1.number_input("RAGæ•°", 1, 20, 3, key="rb")
    c_n = c2.number_input("Caseæ•°", 1, 20, 2, key="cb")
    if f and st.button("æ‰¹é‡å¤„ç†"):
        lines = [l.strip() for l in parse_file(f).split('\n') if len(l)>10]
        res, bar = [], st.progress(0)
        for i, l in enumerate(lines):
            s, _, _ = run_scoring(l, st.session_state.kb, st.session_state.cases, st.session_state.prompt_config, embedder, client, "Qwen2.5-7B-Instruct", r_n, c_n)
            res.append({"id":i+1, "text":l, "scores":s})
            bar.progress((i+1)/len(lines))
        st.success("å®Œæˆ")
        st.download_button("ä¸‹è½½Word", create_word_report(res), "report.docx")

# --- Tab 3: æ¨¡å‹è°ƒä¼˜ ---
with tab3:
    c1, c2, c3 = st.columns(3)
    
    with c1:
        st.subheader("ğŸ“š çŸ¥è¯†åº“")
        up = st.file_uploader("ä¸Šä¼ PDF", accept_multiple_files=True)
        if up and st.button("æ›´æ–°çŸ¥è¯†åº“"):
            raw = "".join([parse_file(u) for u in up])
            cks = [raw[i:i+600] for i in range(0,len(raw),500)]
            idx = faiss.IndexFlatL2(1024); idx.add(embedder.encode(cks))
            st.session_state.kb = (idx, cks)
            ResourceManager.save(idx, cks, PATHS.kb_index, PATHS.kb_chunks)
            st.success("å·²æ›´æ–°"); st.rerun()

    with c2:
        st.subheader("âš–ï¸ åˆ¤ä¾‹ä¸å¾®è°ƒ")
        st.info(f"ç°æœ‰åˆ¤ä¾‹: {len(st.session_state.cases[1])}")
        
        if st.button("å°†åˆ¤ä¾‹è½¬ä¸ºå¾®è°ƒæ•°æ®"):
            cnt = 0
            for c in st.session_state.cases[1]:
                if ResourceManager.append_to_finetune(c["text"], c["scores"], st.session_state.prompt_config.get('system_template',''), st.session_state.prompt_config.get('user_template','')): cnt += 1
            st.success(f"å¯¼å…¥ {cnt} æ¡")

        st.markdown("#### DeepSeek å¾®è°ƒ")
        if st.button("å¯åŠ¨å¾®è°ƒ"):
            try:
                with open(PATHS.training_file, "rb") as f: file_obj = client.files.create(file=f, purpose="fine-tune")
                # æ³¨æ„ï¼šæ­¤å¤„ Model ID å¯èƒ½éœ€æ ¹æ® DeepSeek å®é™… API è°ƒæ•´
                job = client.fine_tuning.jobs.create(training_file=file_obj.id, model="deepseek-chat", suffix="tea-v1")
                ResourceManager.save_ft_status(job.id, "queued")
                st.success(f"ä»»åŠ¡ID: {job.id}")
            except Exception as e:
                st.error(f"å¤±è´¥: {e}")
                if PATHS.training_file.exists():
                    with open(PATHS.training_file, "rb") as f: st.download_button("ä¸‹è½½æ•°æ®", f, "train.jsonl")

        fts = ResourceManager.load_ft_status()
        if fts:
            st.code(f"Job: {fts.get('job_id')}\nStatus: {fts.get('status')}")
            if st.button("åˆ·æ–°çŠ¶æ€"):
                try:
                    job = client.fine_tuning.jobs.retrieve(fts['job_id'])
                    ResourceManager.save_ft_status(job.id, job.status, getattr(job,'fine_tuned_model',None))
                    st.rerun()
                except: pass

        with st.expander("â• æ·»åŠ ç²¾ç»†åˆ¤ä¾‹"):
            with st.form("case_form"):
                f_txt = st.text_area("åˆ¤ä¾‹æè¿°", height=80)
                f_tag = st.text_input("æ ‡ç­¾", "äººå·¥å½•å…¥")
                st.markdown("**å› å­è¯„åˆ†è¯¦æƒ…**")
                fc1, fc2 = st.columns(2)
                factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
                input_scores = {}
                for i, f in enumerate(factors):
                    with (fc1 if i%2==0 else fc2):
                        val = st.number_input(f"{f}åˆ†æ•°", 0,9,7, key=f"s_{i}")
                        cmt = st.text_input(f"{f}è¯„è¯­", key=f"c_{i}")
                        sug = st.text_input(f"{f}å»ºè®®", key=f"a_{i}")
                        input_scores[f] = {"score": val, "comment": cmt, "suggestion": sug}
                
                if st.form_submit_button("ä¿å­˜"):
                    if not embedder: st.error("éœ€ API Key")
                    else:
                        new_c = {"text": f_txt, "tags": f_tag, "scores": input_scores}
                        st.session_state.cases[1].append(new_c)
                        vec = embedder.encode([f_txt])
                        st.session_state.cases[0].add(vec)
                        ResourceManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS['case_index'], PATHS['case_data'], is_json=True)
                        
                        sys_p = st.session_state.prompt_config['system_template']
                        ResourceManager.append_to_finetune(f_txt, input_scores, sys_p, st.session_state.prompt_config['user_template'])
                        
                        st.success("å·²ä¿å­˜ï¼")
                        time.sleep(1); st.rerun()
    
    with c3:
        st.subheader("ğŸ“ Prompt é…ç½®")
        pc = st.session_state.prompt_config
        st.caption("ç³»ç»Ÿæç¤ºè¯ (system_template) é»˜è®¤åŠ è½½è‡ª sys_p.txt")
        st.caption("ç”¨æˆ·æç¤ºè¯ (user_template) é»˜è®¤ä½¿ç”¨å†…ç½®ä»£ç é…ç½®")
        
        sys_t = st.text_area("ç³»ç»Ÿæç¤ºè¯", pc.get('system_template',''), height=200)
        user_t = st.text_area("ç”¨æˆ·æç¤ºè¯", pc.get('user_template',''), height=200)
        
        if st.button("ä¿å­˜ Prompt åˆ°æ–‡ä»¶"):
            new_cfg = {"system_template": sys_t, "user_template": user_t}
            st.session_state.prompt_config = new_cfg
            with open(PATHS.prompt_config_file, 'w', encoding='utf-8') as f:
                json.dump(new_cfg, f, ensure_ascii=False, indent=2)
            st.success("Prompt å·²æ›´æ–°å¹¶ä¿å­˜åˆ° prompts.json")
