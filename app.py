import streamlit as st
import os
import json
import numpy as np
import faiss
import time
import pickle
import re
from pathlib import Path
from io import BytesIO
from typing import List, Dict, Any
from PyPDF2 import PdfReader
from http import HTTPStatus
import dashscope
from dashscope import TextEmbedding
from openai import OpenAI
from docx import Document

# ==========================================
# 0. åŸºç¡€é…ç½®ä¸æŒä¹…åŒ–è·¯å¾„
# ==========================================
st.set_page_config(
    page_title="èŒ¶é¥®å…­å› å­AIè¯„åˆ†å™¨ Pro",
    page_icon="ğŸµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®šä¹‰è®°å¿†å­˜å‚¨ç›®å½•
DATA_DIR = Path("./tea_data")
DATA_DIR.mkdir(exist_ok=True) 

# å®šä¹‰æ–‡ä»¶è·¯å¾„
PATHS = {
    "kb_index": DATA_DIR / "kb.index",
    "kb_chunks": DATA_DIR / "kb_chunks.pkl",
    "case_index": DATA_DIR / "cases.index",
    "case_data": DATA_DIR / "cases.json",
    "training_file": DATA_DIR / "deepseek_finetune.jsonl", # å¾®è°ƒæ•°æ®
    "ft_status": DATA_DIR / "ft_status.json", # è®°å½•å¾®è°ƒä»»åŠ¡IDå’ŒçŠ¶æ€
    "prompt": DATA_DIR / "prompts.json"
}

# æ ·å¼
st.markdown("""
    <style>
    .main-title {font-size: 2.5em; font-weight: bold; text-align: center; color: #2E7D32; margin-bottom: 0.5em;}
    .slogan {font-size: 1.2em; font-style: italic; text-align: center; color: #558B2F; margin-bottom: 30px; font-family: "KaiTi", "æ¥·ä½“", serif;}
    .factor-card {background-color: #F1F8E9; padding: 15px; border-radius: 10px; margin-bottom: 10px; border-left: 5px solid #4CAF50;}
    .score-header {display:flex; justify-content:space-between; font-weight:bold; color:#2E7D32;}
    .advice-tag {font-size: 0.85em; padding: 2px 6px; border-radius: 4px; margin-top: 5px; background-color: #fff; border: 1px dashed #4CAF50; color: #388E3C; display: inline-block;}
    .master-comment {background-color: #FFFDE7; border: 1px solid #FFF9C4; padding: 15px; border-radius: 8px; font-family: "KaiTi", serif; font-size: 1.1em; color: #5D4037; margin-bottom: 20px; line-height: 1.6;}
    .ft-card {border: 1px solid #ddd; padding: 15px; border-radius: 8px; background-color: #f8f9fa; margin-top: 10px;}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 1. æ ¸å¿ƒæ•°æ®ç®¡ç†
# ==========================================

class DataManager:
    @staticmethod
    def save(index, data, idx_path, data_path, is_json=False):
        if index: faiss.write_index(index, str(idx_path))
        with open(data_path, "w" if is_json else "wb") as f:
            if is_json: json.dump(data, f, ensure_ascii=False, indent=2)
            else: pickle.dump(data, f)

    @staticmethod
    def append_to_finetune(case_text, scores, system_prompt, user_template):
        try:
            user_content = user_template.format(product_desc=case_text, context_text="", case_text="")
            assistant_content = json.dumps({"master_comment": "ï¼ˆäººå·¥æ ¡å‡†ï¼‰", "scores": scores}, ensure_ascii=False)
            entry = {
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": assistant_content}
                ]
            }
            with open(PATHS['training_file'], "a", encoding="utf-8") as f:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
            return True
        except: return False

    @staticmethod
    def load(idx_path, data_path, is_json=False):
        if idx_path.exists() and data_path.exists():
            try:
                index = faiss.read_index(str(idx_path))
                with open(data_path, "r" if is_json else "rb") as f:
                    data = json.load(f) if is_json else pickle.load(f)
                return index, data
            except: pass
        return faiss.IndexFlatL2(1024), []
    
    @staticmethod
    def save_ft_status(job_id, status, fine_tuned_model=None):
        """ä¿å­˜å¾®è°ƒä»»åŠ¡çŠ¶æ€"""
        data = {"job_id": job_id, "status": status, "timestamp": time.time()}
        if fine_tuned_model: data["fine_tuned_model"] = fine_tuned_model
        with open(PATHS['ft_status'], 'w') as f:
            json.dump(data, f)

    @staticmethod
    def load_ft_status():
        if PATHS['ft_status'].exists():
            try: return json.load(open(PATHS['ft_status'], 'r'))
            except: pass
        return None

class AliyunEmbedder:
    def __init__(self, api_key):
        self.model_name = "text-embedding-v4"
        dashscope.api_key = api_key 

    def encode(self, texts: List[str]) -> np.ndarray:
        if not texts: return np.zeros((0, 1024), dtype="float32")
        if isinstance(texts, str): texts = [texts]
        try:
            resp = TextEmbedding.call(model=self.model_name, input=texts)
            if resp.status_code == HTTPStatus.OK:
                return np.array([i['embedding'] for i in resp.output['embeddings']]).astype("float32")
        except: pass
        return np.zeros((len(texts), 1024), dtype="float32")

# é»˜è®¤ Prompt
DEFAULT_PROMPT_CONFIG = {
    "system_template": """ä½ æ˜¯ä¸€åèµ„æ·±çš„èŒ¶é¥®äº§å“ç ”å‘ä¸æ„Ÿå®˜åˆ†æä¸“å®¶ï¼Œç²¾é€šã€Šä¸­å›½èŒ¶æ„Ÿå®˜å“é‰´æ‰‹å†Œã€‹ç­‰å·²ä¸Šä¼ çš„æƒå¨æ–‡çŒ®åŠæ‰‹å†Œã€‚
è¯·åŸºäºç»™å®šçš„äº§å“æè¿°ã€å‚è€ƒèµ„æ–™å’Œç›¸ä¼¼å†å²åˆ¤ä¾‹ï¼Œä¸¥æ ¼æŒ‰ç…§"ç½—é©¬æµ‹è¯„æ³•2.0"è¿›è¡Œä¸“ä¸šè¯„åˆ†ã€‚

====================
ä¸€ã€è¯„åˆ†æ–¹æ³•ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰
====================

ç½—é©¬æµ‹è¯„æ³•2.0
ä¸‰æ®µï¼ˆæ®µä½ï¼‰ä¸å…­å› å­å¦‚ä¸‹ï¼ˆæ¯ä¸ªå› å­ 0â€“9 åˆ†ï¼Œæ•´æ•°ï¼‰ï¼š

ã€å‰æ®µï¼šé¦™ã€‘
1) â‘ ä¼˜é›…æ€§ï¼šé¦™æ°”å¼•å‘çš„æ„‰æ‚¦æ„Ÿ
2) â‘¡è¾¨è¯†åº¦ï¼šé¦™æ°”å¯è¢«è¯†åˆ«è®°å¿†

ã€ä¸­æ®µï¼šå‘³ã€‘
3) â‘¢åè°ƒæ€§ï¼šèŒ¶æ±¤å†…å«ç‰©çš„èåˆåº¦
4) â‘£é¥±å’Œåº¦ï¼šæ•´ä½“èŒ¶æ±¤çš„æµ“åšåº¦

ã€åæ®µï¼šéŸµã€‘
5) â‘¤æŒä¹…æ€§ï¼šèŒ¶æ±¤åœ¨å£è…”ä¸­çš„ä½™éŸµ
6) â‘¥è‹¦æ¶©åº¦ï¼šè‹¦å‘³ã€æ”¶æ•›æ‹‰æ‰¯æ„Ÿ

é‡è¦ï¼šä½ åªèƒ½è¯„è¿™å…­é¡¹ï¼›ä¸è¦æ·»åŠ ä»»ä½•é¢å¤–ç»´åº¦ï¼ˆä¾‹å¦‚äº§åœ°ã€å·¥è‰ºã€æ ‘é¾„ã€å“ç‰Œã€ä»·æ ¼ã€åŒ…è£…ç­‰ï¼‰ã€‚

====================
äºŒã€ä¿¡æ¯æ¥æºçº¦æŸï¼ˆéå¸¸é‡è¦ï¼‰
====================

1) è¯„åˆ†åªèƒ½æ¥è‡ªâ€œç”¨æˆ·è¾“å…¥çš„èŒ¶è¯„æ–‡æœ¬â€ä¸­æ˜ç¡®è¡¨è¾¾æˆ–å¯ç›´æ¥å¯¹åº”çš„æè¿°ã€‚
2) ä¸èƒ½ä½¿ç”¨å¤–éƒ¨å¸¸è¯†ã€èŒ¶ç±»åˆ»æ¿å°è±¡ã€äº§åœ°/å“ç§æ¨æ–­ã€æˆ–ä»»ä½•â€œè„‘è¡¥è”æƒ³â€æ¥è¡¥é½ä¿¡æ¯ã€‚
   - å³ä½¿ç”¨æˆ·è¯´çš„æ˜¯â€œé“è§‚éŸ³/é¾™äº•/æ™®æ´±â€ï¼Œä¹Ÿä¸å…è®¸å› ä¸ºèŒ¶åè€Œé»˜è®¤é¦™æ°”æˆ–æ»‹å‘³ç‰¹å¾ã€‚
3) è‹¥æŸå› å­åœ¨èŒ¶è¯„ä¸­â€œæœªæåŠæˆ–æè¿°æå…¶æ¨¡ç³Šâ€ï¼Œä½ ä»å¿…é¡»ç»™å‡º 0â€“9 åˆ†ï¼Œä½†å¿…é¡»ï¼š
   - åœ¨è¯¥å› å­çš„ evidence å†™â€œæœªæåŠ/è¯æ®ä¸è¶³â€
   - å°† confidence æ ‡ä¸º low
   - åˆ†æ•°é‡‡ç”¨â€œä¸­æ€§ä¿å®ˆåˆ† 4â€ï¼ˆé™¤éç”¨æˆ·æ˜ç¡®è¡¨è¾¾è´Ÿé¢/æ­£é¢åˆ°è¶³ä»¥æ”¹å˜åˆ†æ•°ï¼‰
4) ä¸è¦å†™é•¿ç¯‡æ„Ÿæƒ³ï¼›ä¸è¦æ‰©å†™ç”¨æˆ·æ²¡æœ‰è¯´è¿‡çš„ç»†èŠ‚ã€‚

====================
ä¸‰ã€0â€“9 åˆ†é€šç”¨æ ‡å°ºï¼ˆç”¨äºå…­å› å­ï¼‰
====================

é‡‡ç”¨â€œè´¨é‡/ä½“éªŒå¥½åâ€çš„æ–¹å‘ï¼šåˆ†æ•°è¶Šé«˜ï¼Œä½“éªŒè¶Šå¥½ï¼ˆåŒ…æ‹¬è‹¦æ¶©åº¦ä¹Ÿæ˜¯â€œè¶Šèˆ’é€‚è¶Šé«˜åˆ†â€ï¼Œä¸æ˜¯â€œè¶Šè‹¦è¶Šé«˜åˆ†â€ï¼‰ã€‚

é€šç”¨é”šç‚¹ï¼ˆæŒ‰ç”¨æˆ·æªè¾å¼ºåº¦åšä¿å®ˆæ˜ å°„ï¼‰ï¼š
- 9ï¼šæä½³/æƒŠè‰³/éå¸¸é«˜çº§/å‡ ä¹æ— å¯æŒ‘å‰”ï¼ˆç”¨æˆ·è¡¨è¾¾éå¸¸å¼ºçƒˆçš„è‚¯å®šï¼‰
- 8ï¼šä¼˜ç§€/å¾ˆå–œæ¬¢/æ˜æ˜¾é«˜æ°´å¹³
- 7ï¼šå¾ˆå¥½/æ¸…æ™°æ˜æ˜¾çš„ä¼˜ç‚¹
- 6ï¼šå¥½/æ»¡æ„/æ•´ä½“ä¸é”™
- 5ï¼šä¸­ç­‰åä¸Š/è¿˜å¯ä»¥
- 4ï¼šä¸€èˆ¬/ä¸­æ€§/è¯æ®ä¸è¶³æ—¶çš„é»˜è®¤ä¿å®ˆåˆ†
- 3ï¼šåå¼±/æœ‰æ˜æ˜¾ä¸è¶³
- 2ï¼šè¾ƒå·®/ç¼ºç‚¹çªå‡º
- 1ï¼šå¾ˆå·®/å‡ ä¹ä¸å¯æ¥å—
- 0ï¼šä¸¥é‡ç¼ºé™·/æ˜æ˜¾ä¸é€‚/éš¾ä»¥ä¸‹å’½ï¼ˆç”¨æˆ·è¡¨è¾¾æç«¯è´Ÿé¢ï¼‰

ã€è‹¦æ¶©åº¦ç‰¹åˆ«è¯´æ˜ï¼ˆå¿…é¡»æ‰§è¡Œï¼‰ã€‘
- 9ï¼šå‡ ä¹ä¸è‹¦ä¸æ¶©ï¼Œæˆ–è‹¦æ¶©æè½»å¾®ä¸”å¾ˆå¿«åŒ–å¼€ï¼Œå£è…”æ— æ‹‰æ‰¯æ”¶æ•›ä¸é€‚
- 6â€“7ï¼šæœ‰è½»å¾®è‹¦/æ¶©ä½†å¯æ¥å—ï¼ŒåŒ–å¾—å¿«ï¼Œä¸å½±å“æ•´ä½“èˆ’é€‚
- 4â€“5ï¼šè‹¦/æ¶©å­˜åœ¨ä¸”è¾ƒæ˜æ˜¾ï¼Œä½†ä»èƒ½å–ï¼Œèˆ’é€‚åº¦ä¸€èˆ¬
- 0â€“3ï¼šè‹¦æ¶©å¼ºçƒˆã€é”å–‰ã€æ‹‰æ‰¯æ„Ÿé‡ã€æ”¶æ•›æ˜æ˜¾ã€éš¾å—ï¼ˆæŒ‰ç”¨æˆ·æè¿°å¼ºåº¦ç»™ä½åˆ†ï¼‰

====================
å››ã€å› å­è§£é‡Šå£å¾„ï¼ˆç”¨äºæŠ“å–è¯æ®ä¸æ‰“åˆ†ï¼‰
====================

ä½ éœ€è¦ä»èŒ¶è¯„é‡Œæå–ä¸æ¯ä¸ªå› å­â€œç›´æ¥ç›¸å…³â€çš„è¯­å¥ä½œä¸ºè¯æ®ï¼ˆå°½é‡çŸ­ï¼Œæœ€å¤š 2 æ®µåŸå¥/çŸ­è¯­ï¼‰ã€‚

â‘ ä¼˜é›…æ€§ï¼ˆé¦™æ°”æ„‰æ‚¦æ„Ÿï¼‰å…³æ³¨ï¼š
- æ­£å‘ï¼šæ¸…é›…ã€å¹½é›…ã€èˆ’æœã€å¹²å‡€ã€ç»†è…»ã€æ„‰æ‚¦ã€é«˜çº§ã€æŸ”å’Œä¸åˆºé¼»ã€é—»ç€å¾ˆäº«å—
- è´Ÿå‘ï¼šæ‚ã€é—·ã€åˆºé¼»ã€éœ‰ã€é¦Šã€ç„¦ã€çƒŸã€é’è‡­ã€å‹è¿«æ„Ÿã€ä¸èˆ’æœ

â‘¡è¾¨è¯†åº¦ï¼ˆé¦™æ°”å¯è¯†åˆ«ä¸è®°å¿†ç‚¹ï¼‰å…³æ³¨ï¼š
- æ­£å‘ï¼šé¦™å‹å…·ä½“å¯æŒ‡è®¤ï¼ˆå¦‚å…°èŠ±é¦™/èœœé¦™/æœé¦™/æœ¨è´¨é¦™ç­‰ï¼‰ã€ç‰¹å¾é²œæ˜ã€æœ‰è®°å¿†ç‚¹ã€ä¸€é—»å°±çŸ¥é“
- è´Ÿå‘ï¼šé¦™æ°”å¹³ã€ç³Šã€æ·¡ã€è¯´ä¸æ¸…ã€ä¸çªå‡ºã€æ··æ‚éš¾è¾¨

â‘¢åè°ƒæ€§ï¼ˆèåˆåº¦/å¹³è¡¡åº¦ï¼‰å…³æ³¨ï¼š
- æ­£å‘ï¼šåè°ƒã€å¹³è¡¡ã€åœ†æ¶¦ã€èåˆå¥½ã€ä¸çªå…€ã€å‰åç»Ÿä¸€ã€é¡ºå£
- è´Ÿå‘ï¼šå‰²è£‚ã€å¤±è¡¡ã€æŸå‘³çªå…€ï¼ˆé…¸/è‹¦/æ¶©/ç”œè…»/é’å‘³ç­‰é¡¶å‡ºæ¥ï¼‰ã€å†²çªæ„Ÿ

â‘£é¥±å’Œåº¦ï¼ˆèŒ¶æ±¤æµ“åšåº¦/å……å®åº¦ï¼‰å…³æ³¨ï¼š
- æ­£å‘ï¼šæµ“åšã€é¥±æ»¡ã€åšåº¦ã€ç¨ æ»‘ã€èƒ¶è´¨æ„Ÿã€ç‰©è´¨æ„Ÿå¼ºã€ä¸°å¯Œ
- è´Ÿå‘ï¼šå¯¡æ·¡ã€æ°´è–„ã€ç©ºã€è½»é£˜ã€æ²¡å†…å®¹ã€åƒæ°´

â‘¤æŒä¹…æ€§ï¼ˆä½™éŸµ/å›ç”˜/ä½™é¦™/ç”Ÿæ´¥æŒç»­ï¼‰å…³æ³¨ï¼š
- æ­£å‘ï¼šå›ç”˜æŒä¹…ã€ä½™é¦™ä¹…ã€å–‰éŸµé•¿ã€å£è…”ç•™é¦™ã€ç”Ÿæ´¥æŒç»­ã€å’½ä¸‹åè¿˜åœ¨
- è´Ÿå‘ï¼šæ•£å¾—å¿«ã€ä½™å‘³çŸ­ã€å›ç”˜ä¸€é—ªè€Œè¿‡ã€å–å®Œæ²¡æ„Ÿè§‰

â‘¥è‹¦æ¶©åº¦ï¼ˆè‹¦å‘³/æ”¶æ•›/æ‹‰æ‰¯æ„Ÿçš„èˆ’é€‚åº¦ï¼‰å…³æ³¨ï¼š
- é«˜åˆ†ï¼šä¸è‹¦ä¸æ¶©ã€å¾®è‹¦å³åŒ–ã€æ¶©ä¸æ‹‰æ‰¯ã€å¾ˆé¡º
- ä½åˆ†ï¼šè‹¦æ¶©é‡ã€é”å–‰ã€åˆ®å£ã€æ‹‰æ‰¯å¼ºã€æ”¶æ•›æ˜æ˜¾ä¸”ä¹…

====================
äº”ã€å·¥ä½œæµç¨‹ï¼ˆå¿…é¡»æŒ‰æ­¥éª¤æ‰§è¡Œï¼‰
====================

Step 1ï¼šé€šè¯»ç”¨æˆ·èŒ¶è¯„ï¼Œä»…æå–ä¸å…­å› å­ç›¸å…³çš„å¥å­/çŸ­è¯­ï¼ˆä¸è¦æ‰©å†™ï¼‰ã€‚
Step 2ï¼šå¯¹æ¯ä¸ªå› å­ï¼š
- æ‰¾è¯æ®ï¼ˆevidenceï¼‰
- ç»™ 0â€“9 æ•´æ•°åˆ†ï¼ˆscoreï¼‰
- å†™ 2â€“3 å¥è¯¦ç»†çš„è§£é‡Šï¼ˆreasonï¼‰ï¼Œè§£é‡Šå¿…é¡»èƒ½è¢«è¯æ®ç›´æ¥æ”¯æ’‘
- ç»™å‡ºç½®ä¿¡åº¦ï¼šhigh / medium / low
Step 3ï¼šè®¡ç®—æ®µä½å°ç»“ï¼ˆå¯è®¡ç®—ä½†ä¸å¾—æ›¿ä»£å…­å› å­ï¼‰ï¼š
- å‰æ®µï¼ˆé¦™ï¼‰= (ä¼˜é›…æ€§ + è¾¨è¯†åº¦) / 2
- ä¸­æ®µï¼ˆå‘³ï¼‰= (åè°ƒæ€§ + é¥±å’Œåº¦) / 2
- åæ®µï¼ˆéŸµï¼‰= (æŒä¹…æ€§ + è‹¦æ¶©åº¦) / 2
å¹¶è¾“å‡º overallï¼ˆæ€»åˆ† sum=6é¡¹ä¹‹å’Œï¼Œavg=å¹³å‡åˆ†ï¼‰ã€‚
Step 4ï¼šåˆ—å‡ºâ€œä¿¡æ¯ä¸è¶³é¡¹â€ï¼ˆå“ªäº›å› å­ evidence=æœªæåŠ/è¯æ®ä¸è¶³ï¼‰ï¼‰ã€‚
Step 5ï¼šåˆ—å‡ºå¸®åŠ©æå‡èŒ¶é¥®è¯„åˆ†çš„å»ºè®®ï¼ˆsuggestionï¼‰ã€‚

====================
å…­ã€ä¸¥æ ¼ç¦æ­¢äº‹é¡¹
====================

- ç¦æ­¢å‡ºç°ï¼šæ ¹æ®èŒ¶ç±»/äº§åœ°/å·¥è‰ºâ€œæ¨æµ‹â€é¦™æ°”æ»‹å‘³ï¼›ç¦æ­¢â€œæƒ³è±¡â€æ²¡å†™çš„ä½“éªŒã€‚
- ç¦æ­¢æŠŠâ€œè€æ³¡æ¬¡æ•°/ä»·æ ¼/åŒ…è£…/å“ç‰Œæ•…äº‹â€å½“ä½œä»»ä½•å› å­çš„è¯æ®ã€‚
- ç¦æ­¢è¾“å‡ºé JSON å†…å®¹ã€‚
- ç¦æ­¢è¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼ˆåªç»™ç»“æœ JSONï¼‰ã€‚

{model_description}""",
    
    "user_template": """ã€å¾…è¯„åˆ†äº§å“ã€‘
{product_desc}

ã€å‚è€ƒæ ‡å‡†ï¼ˆæ‰‹å†Œï¼‰ã€‘
{context_text}

ã€å†å²åˆ¤ä¾‹å‚è€ƒï¼ˆFew-Shotï¼‰ã€‘
{case_text}

è¯·ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹JSONæ ¼å¼ï¼ˆä¸å«Markdownï¼‰ï¼š
{{
  "master_comment": "çº¦100å­—çš„å®—å¸ˆçº§æ€»è¯„ï¼Œå¯Œå«æ–‡åŒ–æ„è•´...",
  "scores": {{
    "ä¼˜é›…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è¾¨è¯†åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "åè°ƒæ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "é¥±å’Œåº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "æŒä¹…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è‹¦æ¶©åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}}
  }}
}}"""
}


# ==========================================
# 2. é€»è¾‘å‡½æ•°
# ==========================================

def get_model_desc(): return "ä¼˜é›…æ€§/è¾¨è¯†åº¦/åè°ƒæ€§/é¥±å’Œåº¦/æŒä¹…æ€§/è‹¦æ¶©åº¦ï¼Œå…³æ³¨å„é˜¶æ®µæ„Ÿå®˜è¡¨ç°ã€‚"

def run_scoring(text, kb_res, case_res, prompt_cfg, embedder, client, model_id):
    vec = embedder.encode([text])
    ctx_txt, hits = "ï¼ˆæ— æ‰‹å†Œèµ„æ–™ï¼‰", []
    if kb_res[0].ntotal > 0:
        _, idx = kb_res[0].search(vec, 3)
        hits = [kb_res[1][i] for i in idx[0] if i < len(kb_res[1])]
        ctx_txt = "\n".join([f"- {h[:200]}..." for h in hits])
        
    case_txt, found_cases = "ï¼ˆæ— ç›¸ä¼¼åˆ¤ä¾‹ï¼‰", []
    if case_res[0].ntotal > 0:
        _, idx = case_res[0].search(vec, 2)
        for i in idx[0]:
            if i < len(case_res[1]) and i >= 0:
                c = case_res[1][i]
                found_cases.append(c)
                sc = c.get('scores', {})
                u_sc = sc.get('ä¼˜é›…æ€§',{}).get('score', 0) if isinstance(sc,dict) and 'ä¼˜é›…æ€§' in sc else 0
                k_sc = sc.get('è‹¦æ¶©åº¦',{}).get('score', 0) if isinstance(sc,dict) and 'è‹¦æ¶©åº¦' in sc else 0
                case_txt += f"\nå‚è€ƒæ¡ˆä¾‹: {c['text'][:30]}... -> ä¼˜é›…æ€§:{u_sc} è‹¦æ¶©åº¦:{k_sc}"

    sys_p = prompt_cfg.get('system_template', DEFAULT_PROMPT_CONFIG['system_template']).replace("{model_description}", get_model_desc())
    user_p = prompt_cfg.get('user_template', DEFAULT_PROMPT_CONFIG['user_template']).format(product_desc=text, context_text=ctx_txt, case_text=case_txt)

    try:
        resp = client.chat.completions.create(
            model=model_id, # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ Model ID
            messages=[{"role":"system", "content":sys_p}, {"role":"user", "content":user_p}],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        return json.loads(resp.choices[0].message.content), hits, found_cases
    except Exception as e:
        st.error(f"Inference Error: {e}")
        return None, [], []

def parse_file(uploaded_file):
    try:
        if uploaded_file.name.endswith('.txt'): return uploaded_file.read().decode("utf-8")
        if uploaded_file.name.endswith('.pdf'): return "".join([p.extract_text() for p in PdfReader(uploaded_file).pages])
        if uploaded_file.name.endswith('.docx'): return "\n".join([p.text for p in Document(uploaded_file).paragraphs])
    except: return ""
    return ""

def create_word_report(results):
    doc = Document()
    doc.add_heading("èŒ¶è¯„æ‰¹é‡è¯„åˆ†æŠ¥å‘Š", 0)
    for item in results:
        doc.add_heading(f"æ¡ç›® {item['id']}", 1)
        doc.add_paragraph(f"åŸæ–‡ï¼š{item['text']}")
        s = item.get('scores', {}).get('scores', {})
        mc = item.get('scores', {}).get('master_comment', '')
        if mc: doc.add_paragraph(f"æ€»è¯„ï¼š{mc}", style="Intense Quote")
        
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'
        hdr = table.rows[0].cells
        hdr[0].text, hdr[1].text, hdr[2].text, hdr[3].text = 'å› å­', 'åˆ†æ•°', 'è¯„è¯­', 'å»ºè®®'
        for k, v in s.items():
            r = table.add_row().cells
            r[0].text = k
            r[1].text = str(v.get('score',''))
            r[2].text = v.get('comment','')
            r[3].text = v.get('suggestion','')
        doc.add_paragraph("_"*20)
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# ==========================================
# 3. é¡µé¢åˆå§‹åŒ–
# ==========================================

if 'loaded' not in st.session_state:
    kb_idx, kb_data = DataManager.load(PATHS['kb_index'], PATHS['kb_chunks'])
    case_idx, case_data = DataManager.load(PATHS['case_index'], PATHS['case_data'], is_json=True)
    st.session_state.kb = (kb_idx, kb_data)
    st.session_state.cases = (case_idx, case_data)
    
    if PATHS['prompt'].exists():
        try:
            with open(PATHS['prompt'], 'r') as f: st.session_state.prompt_config = json.load(f)
        except: st.session_state.prompt_config = DEFAULT_PROMPT_CONFIG.copy()
    else:
        st.session_state.prompt_config = DEFAULT_PROMPT_CONFIG.copy()
    
    st.session_state.loaded = True
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    st.markdown("**ğŸ” API é…ç½®ï¼ˆé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰**")

    # ä»ç¯å¢ƒå˜é‡ / secrets è¯»å–
    aliyun_key = os.getenv("ALIYUN_API_KEY") or st.secrets.get("ALIYUN_API_KEY", "")
    deepseek_key = os.getenv("DEEPSEEK_API_KEY") or st.secrets.get("DEEPSEEK_API_KEY", "")

    if not aliyun_key or not deepseek_key:
        st.warning("âš ï¸ å½“å‰æœªé…ç½® API Keyï¼Œç³»ç»Ÿå°†æ— æ³•è¿è¡Œ")
        st.stop()
    else:
        # âœ… API Key å­˜åœ¨ï¼Œè§†ä¸ºâ€œè°ƒç”¨å¯ç”¨â€
        st.success("âœ… API è°ƒç”¨æˆåŠŸ")

    st.markdown("---")
    st.markdown("**ğŸ§  æ¨¡å‹è®¾å®š**")

    # å›ºå®šæ¨¡å‹
    model_name = "deepseek-chat"
    st.markdown(f"**å½“å‰æ¨¡å‹ï¼š** `{model_name}`")

    # å¦‚å­˜åœ¨å¾®è°ƒæ¨¡å‹ï¼Œä»…å±•ç¤ºæç¤ºï¼ˆä¸å…è®¸åˆ‡æ¢ï¼‰
    ft_status = DataManager.load_ft_status()
    if ft_status and ft_status.get("status") == "succeeded":
        ft_model = ft_status.get("fine_tuned_model")
        st.info(f"ğŸ‰ å·²æ£€æµ‹åˆ°å¾®è°ƒæ¨¡å‹ï¼š`{ft_model}`ï¼ˆå½“å‰æœªå¯ç”¨ï¼‰")

    model_id = model_name   # æ„ä¹‰ä¸æ˜

    embedder = AliyunEmbedder(aliyun_key)
    client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")
    
    st.markdown("---")
    st.markdown("**ğŸ“š RAG çŸ¥è¯†åº“ç®¡ç†**")
    
    # æ˜¾ç¤ºå½“å‰ RAG çŠ¶æ€
    st.caption(f"çŸ¥è¯†åº“ç‰‡æ®µ: {len(st.session_state.kb[1])} æ¡")
    st.caption(f"åˆ¤ä¾‹åº“æ¡ˆä¾‹: {len(st.session_state.cases[1])} æ¡")
    
    if st.button("ğŸ“¤ å¯¼å‡º RAG æ•°æ®"):
        # åˆ›å»ºå‹ç¼©åŒ…
        import zipfile, shutil
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = Path("./temp_export")
        temp_dir.mkdir(exist_ok=True)
        
        # å¤åˆ¶æ‰€æœ‰ RAG æ–‡ä»¶
        for key, path in PATHS.items():
            if path.exists():
                shutil.copy2(path, temp_dir / path.name)
        
        # åˆ›å»º zip æ–‡ä»¶
        zip_path = Path("./rag_export.zip")
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for file in temp_dir.iterdir():
                zipf.write(file, file.name)
        
        # æä¾›ä¸‹è½½
        with open(zip_path, 'rb') as f:
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ RAG æ•°æ®åŒ…",
                data=f,
                file_name="tea_rag_data.zip",
                mime="application/zip"
            )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(temp_dir)
        zip_path.unlink()
    
    if st.button("ğŸ“¥ å¯¼å…¥ RAG æ•°æ®"):
        uploaded_zip = st.file_uploader("ä¸Šä¼  RAG æ•°æ®åŒ…", type=['zip'])
        if uploaded_zip:
            with st.spinner("å¯¼å…¥ä¸­..."):
                # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
                import tempfile, zipfile
                with tempfile.TemporaryDirectory() as tmpdir:
                    zip_path = Path(tmpdir) / "uploaded.zip"
                    with open(zip_path, 'wb') as f:
                        f.write(uploaded_zip.getvalue())
                    
                    # è§£å‹
                    with zipfile.ZipFile(zip_path, 'r') as zipf:
                        zipf.extractall(DATA_DIR)
                    
                    # é‡æ–°åŠ è½½æ•°æ®
                    kb_idx, kb_data = DataManager.load(PATHS['kb_index'], PATHS['kb_chunks'])
                    case_idx, case_data = DataManager.load(PATHS['case_index'], PATHS['case_data'], is_json=True)
                    st.session_state.kb = (kb_idx, kb_data)
                    st.session_state.cases = (case_idx, case_data)
                    
                    st.success("âœ… RAG æ•°æ®å¯¼å…¥æˆåŠŸï¼")
                    st.rerun()
st.markdown('<div class="main-title">ğŸµ èŒ¶é¥®å…­å› å­ AI è¯„åˆ†å™¨ Pro</div>', unsafe_allow_html=True)
st.markdown('<div class="slogan">â€œä¸€ç‰‡å¶å­è½å…¥æ°´ä¸­ï¼Œæ”¹å˜äº†æ°´çš„å‘³é“...â€</div>', unsafe_allow_html=True)

# ==========================================
# 4. åŠŸèƒ½æ ‡ç­¾é¡µ
# ==========================================
tab1, tab2, tab3 = st.tabs(["ğŸ’¡ äº¤äº’è¯„åˆ†", "ğŸš€ æ‰¹é‡è¯„åˆ†", "ğŸ› ï¸ æ¨¡å‹è°ƒä¼˜"])

# --- Tab 1: äº¤äº’è¯„åˆ† ---
with tab1:
    st.info("AI å°†å‚è€ƒçŸ¥è¯†åº“ä¸åˆ¤ä¾‹åº“è¿›è¡Œè¯„åˆ†ã€‚ç¡®è®¤ç»“æœåå°†è‡ªåŠ¨æ›´æ–° RAG åº“å’Œåå°å¾®è°ƒæ•°æ®ã€‚")
    user_input = st.text_area("è¾“å…¥èŒ¶è¯„æè¿°:", height=120)
    
    if st.button("å¼€å§‹è¯„åˆ†", type="primary", use_container_width=True):
        if not user_input or not client: st.warning("è¯·æ£€æŸ¥è¾“å…¥æˆ– API Key")
        else:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹ {model_id} å“é‰´..."):
                scores, kb_hits, case_hits = run_scoring(
                    user_input, st.session_state.kb, st.session_state.cases,
                    st.session_state.prompt_config, embedder, client, model_id
                )
                if scores:
                    mc = scores.get("master_comment", "æš‚æ— æ€»è¯„")
                    st.markdown(f'<div class="master-comment"><b>ğŸ‘µ å®—å¸ˆæ€»è¯„ï¼š</b><br>{mc}</div>', unsafe_allow_html=True)
                    
                    cols = st.columns(3)
                    factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
                    s_dict = scores.get("scores", {})
                    
                    for i, fname in enumerate(factors):
                        if fname in s_dict:
                            data = s_dict[fname]
                            with cols[i%3]:
                                st.markdown(f"""<div class="factor-card"><div class="score-header"><span>{fname}</span><span>{data.get('score')}/9</span></div><div style="margin:5px 0; font-size:0.9em;">{data.get('comment')}</div><div class="advice-tag">ğŸ’¡ {data.get('suggestion','')}</div></div>""", unsafe_allow_html=True)
                    
                    with st.expander("ğŸ“¥ è®¤å¯æ­¤è¯„åˆ†ï¼Ÿ(ç‚¹å‡»ä¿å­˜)"):
                        if st.button("âœ… ç¡®è®¤ä¿å­˜ (è‡ªåŠ¨åŠ å…¥è®­ç»ƒé›†)"):
                            new_case = {"text": user_input, "scores": s_dict, "tags": "äº¤äº’ç”Ÿæˆ"}
                            st.session_state.cases[1].append(new_case)
                            vec = embedder.encode([user_input])
                            st.session_state.cases[0].add(vec)
                            DataManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS['case_index'], PATHS['case_data'], is_json=True)
                            
                            sys_p = st.session_state.prompt_config['system_template'].replace("{model_description}", get_model_desc())
                            DataManager.append_to_finetune(user_input, s_dict, sys_p, st.session_state.prompt_config['user_template'])
                            
                            st.success("å·²å­˜æ¡£ï¼æ•°æ®å·²åŠ å…¥ RAG åº“å’Œå¾®è°ƒé˜Ÿåˆ—ã€‚")
                            time.sleep(1)
                            st.rerun()

# --- Tab 2: æ‰¹é‡è¯„åˆ† ---
with tab2:
    up_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (æ”¯æŒ .txt / .docx)", type=['txt','docx'])
    if up_file and st.button("å¼€å§‹æ‰¹é‡å¤„ç†"):
        if not client: st.error("è¯·é…ç½® Key")
        else:
            txt = parse_file(up_file)
            lines = [l.strip() for l in txt.split('\n') if len(l)>10]
            results = []
            bar = st.progress(0)
            for i, line in enumerate(lines):
                s, _, _ = run_scoring(line, st.session_state.kb, st.session_state.cases, st.session_state.prompt_config, embedder, client, model_id)
                results.append({"id": i+1, "text": line, "scores": s})
                bar.progress((i+1)/len(lines))
            st.success("å®Œæˆï¼")
            doc_io = create_word_report(results)
            st.download_button("ğŸ“¥ ä¸‹è½½ Word æŠ¥å‘Š", doc_io, "èŒ¶è¯„æŠ¥å‘Š.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")

# --- Tab 3: æ¨¡å‹è°ƒä¼˜ (è‡ªåŠ¨åŒ–å¾®è°ƒæµç¨‹) ---
with tab3:
    c1, c2, c3 = st.columns(3)
    
    # Column 1: RAG çŸ¥è¯†åº“
    with c1:
        st.subheader("ğŸ“š RAG çŸ¥è¯†åº“")
        files = st.file_uploader("ä¸Šä¼ PDF", accept_multiple_files=True, key="kb_up")
        st.info(f"ğŸ’¾ å½“å‰å­˜å‚¨: {len(st.session_state.kb[1])} ç‰‡æ®µ")
        if files and st.button("æ›´æ–°çŸ¥è¯†åº“"):
            if not embedder: st.error("éœ€ API Key")
            else:
                with st.spinner("å¤„ç†å¹¶å­˜ç›˜..."):
                    raw = "".join([parse_file(f) for f in files])
                    chunks = [raw[i:i+600] for i in range(0,len(raw),500)]
                    vecs = embedder.encode(chunks)
                    idx = faiss.IndexFlatL2(1024)
                    idx.add(vecs)
                    st.session_state.kb = (idx, chunks)
                    DataManager.save(idx, chunks, PATHS['kb_index'], PATHS['kb_chunks'])
                    st.success("çŸ¥è¯†åº“å·²æ›´æ–°ï¼"); time.sleep(1); st.rerun()

    # Column 2: åˆ¤ä¾‹åº“ & å¾®è°ƒæ§åˆ¶å°
    with c2:
        st.subheader("âš–ï¸ åˆ¤ä¾‹åº“ & å¾®è°ƒ")
        st.caption("ä½ å½•å…¥çš„åˆ¤ä¾‹å°†è‡ªåŠ¨ç§¯ç´¯ä¸ºå¾®è°ƒæ•°æ®")
        
        # ä¿®å¤ç‚¹ï¼šå…ˆå®šä¹‰ case_count
        case_count = len(st.session_state.cases[1])
        st.info(f"ğŸ’¾ å½“å‰åˆ¤ä¾‹: {case_count} æ¡")

        # === å¾®è°ƒæ§åˆ¶é¢æ¿ ===
        st.markdown("#### â˜ï¸ äº‘ç«¯å¾®è°ƒæ§åˆ¶å°")
        
        line_count = 0
        if PATHS['training_file'].exists():
            try: line_count = sum(1 for _ in open(PATHS['training_file'], 'r', encoding='utf-8'))
            except: pass
        
        st.write(f"å¯ç”¨å¾®è°ƒæ•°æ®: **{line_count} æ¡**")
        
        if line_count >= 10:
            if st.button("ğŸš€ ä¸€é”®å¯åŠ¨å¾®è°ƒ (DeepSeek)"):
                if not client: st.error("è¯·å…ˆé…ç½® API Key")
                else:
                    try:
                        with open(PATHS['training_file'], "rb") as f:
                            file_obj = client.files.create(file=f, purpose="fine-tune")
                        job = client.fine_tuning.jobs.create(
                            training_file=file_obj.id,
                            model="deepseek-chat",
                            suffix="tea-expert"
                        )
                        DataManager.save_ft_status(job.id, "queued", fine_tuned_model=None)
                        st.success(f"å¾®è°ƒä»»åŠ¡å·²å¯åŠ¨ï¼Job ID: {job.id}")
                        time.sleep(1); st.rerun()
                    except Exception as e:
                        st.error(f"å¯åŠ¨å¾®è°ƒå¤±è´¥: {e}")
        else:
            st.warning("âš ï¸ å»ºè®®ç§¯ç´¯è‡³å°‘ 10 æ¡åˆ¤ä¾‹åè¿›è¡Œå¾®è°ƒã€‚")

        ft_status = DataManager.load_ft_status()
        if ft_status:
            st.markdown(f"""
            <div class="ft-card">
                <b>ğŸ”„ æœ€è¿‘ä»»åŠ¡çŠ¶æ€</b><br>
                Job ID: <code>{ft_status.get('job_id', 'N/A')}</code><br>
                çŠ¶æ€: <b>{ft_status.get('status', 'N/A')}</b><br>
                æ¨¡å‹: {ft_status.get('fine_tuned_model', 'N/A')}
            </div>
            """, unsafe_allow_html=True)
            
            if ft_status.get('status') in ['queued', 'running']:
                if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€"):
                    try:
                        job = client.fine_tuning.jobs.retrieve(ft_status['job_id'])
                        new_status = job.status
                        ft_info = {"job_id": job.id, "status": new_status}
                        if new_status == 'succeeded':
                            ft_info["fine_tuned_model"] = job.fine_tuned_model
                            st.success(f"è®­ç»ƒå®Œæˆï¼æ¨¡å‹: {ft_info['fine_tuned_model']}")
                            st.balloons()
                        elif new_status == 'failed':
                            ft_info["error"] = job.error.message
                            st.error(f"è®­ç»ƒå¤±è´¥: {job.error.message}")
                        
                        DataManager.save_ft_status(ft_info['job_id'], ft_info['status'], ft_info.get('fine_tuned_model'))
                        time.sleep(1); st.rerun()
                    except Exception as e:
                        st.error(f"æŸ¥è¯¢çŠ¶æ€å¤±è´¥: {e}")

        with st.expander("â• æ·»åŠ ç²¾ç»†åˆ¤ä¾‹"):
            with st.form("case_form"):
                f_txt = st.text_area("åˆ¤ä¾‹æè¿°", height=80)
                f_tag = st.text_input("æ ‡ç­¾", "äººå·¥å½•å…¥")
                st.markdown("**å› å­è¯„åˆ†è¯¦æƒ…**")
                fc1, fc2 = st.columns(2)
                factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
                input_scores = {}
                for i, f in enumerate(factors):
                    with (fc1 if i%2==0 else fc2):
                        val = st.number_input(f"{f}åˆ†æ•°", 0,9,7, key=f"s_{i}")
                        cmt = st.text_input(f"{f}è¯„è¯­", key=f"c_{i}")
                        sug = st.text_input(f"{f}å»ºè®®", key=f"a_{i}")
                        input_scores[f] = {"score": val, "comment": cmt, "suggestion": sug}
                
                if st.form_submit_button("ä¿å­˜"):
                    if not embedder: st.error("éœ€ API Key")
                    else:
                        new_c = {"text": f_txt, "tags": f_tag, "scores": input_scores}
                        st.session_state.cases[1].append(new_c)
                        vec = embedder.encode([f_txt])
                        st.session_state.cases[0].add(vec)
                        DataManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS['case_index'], PATHS['case_data'], is_json=True)
                        
                        sys_p = st.session_state.prompt_config['system_template'].replace("{model_description}", get_model_desc())
                        DataManager.append_to_finetune(f_txt, input_scores, sys_p, st.session_state.prompt_config['user_template'])
                        
                        st.success("å·²ä¿å­˜ï¼")
                        time.sleep(1); st.rerun()

        st.write(f"ç°æœ‰åˆ¤ä¾‹é¢„è§ˆ:")
        for i, c in enumerate(st.session_state.cases[1][-5:]):
            with st.expander(f"#{case_count-i} {c.get('tags','')}"):
                st.write(c['text'][:50]+"...")
                st.json(c['scores'])

    # Column 3: Prompt
    with c3:
        st.subheader("ğŸ“ Prompt æ¨¡æ¿")
        current_sys = st.session_state.prompt_config.get('system_template', '')
        current_user = st.session_state.prompt_config.get('user_template', '')
        
        if "{case_text}" not in current_user: st.warning("User Template ç¼ºå°‘ {case_text}")
        
        sys_t = st.text_area("System Template", current_sys, height=200)
        user_t = st.text_area("User Template", current_user, height=200)
        
        if st.button("ğŸ’¾ ä¿å­˜ Prompt"):
            new_cfg = {"system_template": sys_t, "user_template": user_t}
            st.session_state.prompt_config = new_cfg
            with open(PATHS['prompt'], 'w') as f: json.dump(new_cfg, f, ensure_ascii=False)

            st.success("Prompt å·²ä¿å­˜ï¼"); time.sleep(1); st.rerun()







