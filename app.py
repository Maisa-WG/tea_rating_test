import streamlit as st
import os
import json
import numpy as np
import faiss
import time
import pickle
import re
from pathlib import Path
from io import BytesIO
from typing import List, Dict, Any
from PyPDF2 import PdfReader
from http import HTTPStatus
import dashscope
from dashscope import TextEmbedding
from openai import OpenAI
from docx import Document

# ==========================================
# 0. åŸºç¡€é…ç½®ä¸æŒä¹…åŒ–è·¯å¾„
# ==========================================
st.set_page_config(
    page_title="èŒ¶é¥®å…­å› å­AIè¯„åˆ†å™¨ Pro",
    page_icon="ğŸµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# å®šä¹‰è®°å¿†å­˜å‚¨ç›®å½•
DATA_DIR = Path("./tea_data")
DATA_DIR.mkdir(exist_ok=True) 

# å®šä¹‰æ–‡ä»¶è·¯å¾„
PATHS = {
    "kb_index": DATA_DIR / "kb.index",
    "kb_chunks": DATA_DIR / "kb_chunks.pkl",
    "case_index": DATA_DIR / "cases.index",
    "case_data": DATA_DIR / "cases.json",
    "training_file": DATA_DIR / "deepseek_finetune.jsonl", # å¾®è°ƒæ•°æ®
    "ft_status": DATA_DIR / "ft_status.json", # è®°å½•å¾®è°ƒä»»åŠ¡IDå’ŒçŠ¶æ€
    "prompt": DATA_DIR / "prompts.json"
}

# æ ·å¼
st.markdown("""
    <style>
    .main-title {font-size: 2.5em; font-weight: bold; text-align: center; color: #2E7D32; margin-bottom: 0.5em;}
    .slogan {font-size: 1.2em; font-style: italic; text-align: center; color: #558B2F; margin-bottom: 30px; font-family: "KaiTi", "æ¥·ä½“", serif;}
    .factor-card {background-color: #F1F8E9; padding: 15px; border-radius: 10px; margin-bottom: 10px; border-left: 5px solid #4CAF50;}
    .score-header {display:flex; justify-content:space-between; font-weight:bold; color:#2E7D32;}
    .advice-tag {font-size: 0.85em; padding: 2px 6px; border-radius: 4px; margin-top: 5px; background-color: #fff; border: 1px dashed #4CAF50; color: #388E3C; display: inline-block;}
    .master-comment {background-color: #FFFDE7; border: 1px solid #FFF9C4; padding: 15px; border-radius: 8px; font-family: "KaiTi", serif; font-size: 1.1em; color: #5D4037; margin-bottom: 20px; line-height: 1.6;}
    .ft-card {border: 1px solid #ddd; padding: 15px; border-radius: 8px; background-color: #f8f9fa; margin-top: 10px;}
    </style>
""", unsafe_allow_html=True)

# ==========================================
# 1. æ ¸å¿ƒæ•°æ®ç®¡ç†
# ==========================================

class DataManager:
    @staticmethod
    def save(index, data, idx_path, data_path, is_json=False):
        if index: faiss.write_index(index, str(idx_path))
        with open(data_path, "w" if is_json else "wb") as f:
            if is_json: json.dump(data, f, ensure_ascii=False, indent=2)
            else: pickle.dump(data, f)

    @staticmethod
    def append_to_finetune(case_text, scores, system_prompt, user_template):
        try:
            user_content = user_template.format(product_desc=case_text, context_text="", case_text="")
            assistant_content = json.dumps({"master_comment": "ï¼ˆäººå·¥æ ¡å‡†ï¼‰", "scores": scores}, ensure_ascii=False)
            entry = {
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_content},
                    {"role": "assistant", "content": assistant_content}
                ]
            }
            with open(PATHS['training_file'], "a", encoding="utf-8") as f:
                f.write(json.dumps(entry, ensure_ascii=False) + "\n")
            return True
        except: return False

    @staticmethod
    def load(idx_path, data_path, is_json=False):
        if idx_path.exists() and data_path.exists():
            try:
                index = faiss.read_index(str(idx_path))
                with open(data_path, "r" if is_json else "rb") as f:
                    data = json.load(f) if is_json else pickle.load(f)
                return index, data
            except: pass
        return faiss.IndexFlatL2(1024), []
    
    @staticmethod
    def save_ft_status(job_id, status, fine_tuned_model=None):
        """ä¿å­˜å¾®è°ƒä»»åŠ¡çŠ¶æ€"""
        data = {"job_id": job_id, "status": status, "timestamp": time.time()}
        if fine_tuned_model: data["fine_tuned_model"] = fine_tuned_model
        with open(PATHS['ft_status'], 'w') as f:
            json.dump(data, f)

    @staticmethod
    def load_ft_status():
        if PATHS['ft_status'].exists():
            try: return json.load(open(PATHS['ft_status'], 'r'))
            except: pass
        return None

class AliyunEmbedder:
    def __init__(self, api_key):
        self.model_name = "text-embedding-v4"
        dashscope.api_key = api_key 

    def encode(self, texts: List[str]) -> np.ndarray:
        if not texts: return np.zeros((0, 1024), dtype="float32")
        if isinstance(texts, str): texts = [texts]
        try:
            resp = TextEmbedding.call(model=self.model_name, input=texts)
            if resp.status_code == HTTPStatus.OK:
                return np.array([i['embedding'] for i in resp.output['embeddings']]).astype("float32")
        except: pass
        return np.zeros((len(texts), 1024), dtype="float32")

# é»˜è®¤ Prompt
DEFAULT_PROMPT_CONFIG = {
    "system_template": """ä½ æ˜¯ä¸€åèµ„æ·±çš„èŒ¶é¥®äº§å“ç ”å‘ä¸æ„Ÿå®˜åˆ†æä¸“å®¶ï¼Œç²¾é€šã€Šä¸­å›½èŒ¶æ„Ÿå®˜å“é‰´æ‰‹å†Œã€‹ç­‰å·²ä¸Šä¼ çš„æƒå¨æ–‡çŒ®åŠæ‰‹å†Œã€‚
è¯·åŸºäºç»™å®šçš„äº§å“æè¿°ã€å‚è€ƒèµ„æ–™å’Œç›¸ä¼¼å†å²åˆ¤ä¾‹ï¼Œä¸¥æ ¼æŒ‰ç…§"ç½—é©¬æµ‹è¯„æ³•2.0"è¿›è¡Œä¸“ä¸šè¯„åˆ†ã€‚
è¯·ä»¥â€œæ¨ç†â€”è¡ŒåŠ¨â€”è§‚å¯Ÿâ€çš„æ–¹å¼å®Œæˆä»»åŠ¡ã€‚
ã€å·¥ä½œåè®®ï¼ˆReActï¼‰ã€‘
ä½ åœ¨å›ç­”æ—¶ï¼Œéœ€åœ¨å†…éƒ¨éµå¾ªå¦‚ä¸‹å¾ªç¯ï¼ˆæ— éœ€å¯¹ç”¨æˆ·å±•ç¤ºæ­¥éª¤æ ‡ç­¾ï¼‰ï¼š
1.Reasoningï¼ˆæ¨ç†ï¼‰
- åˆ¤æ–­äº§å“æè¿°ä¸­æœ€å…³é”®çš„æ„Ÿå®˜é£é™©ç‚¹ï¼ˆå°¤å…¶æ˜¯è‹¦æ¶©åº¦è½¬åŒ–ï¼‰
- æ˜ç¡®å“ªäº›å…­å› å­éœ€è¦è¢«é‡ç‚¹è¯„ä¼°
2.Actionï¼ˆè¡ŒåŠ¨ï¼‰
- å¿…é¡»å‚è€ƒæä¾›çš„ã€æ‰‹å†Œèµ„æ–™ã€‘ä¸ã€å†å²åˆ¤ä¾‹ã€‘RAG
- å¦‚æœåˆ¤ä¾‹ä¸å½“å‰äº§å“ç›¸ä¼¼ï¼Œåº”æå–å…¶å¯¹åº”å› å­å¾—åˆ†ä½œä¸ºæ ¡å‡†ä¾æ®
- ä¸å¾—å®Œå…¨å¿½ç•¥ä»»ä½•ä¸€ä¸ªä¿¡æ¯æº
3.Observationï¼ˆå¸æ”¶ä¿¡æ¯ï¼‰
- ç»¼åˆå‚è€ƒä¿¡æ¯ï¼Œè°ƒæ•´åŸå§‹åˆ¤æ–­
- è‹¥å‚è€ƒä¿¡æ¯ä¸è¶³ï¼Œéœ€æ˜ç¡®é™ä½ç½®ä¿¡åº¦å¹¶åæ˜ åœ¨è¯„åˆ†ä¸­
4.Final Decision
- ä¸¥æ ¼åŸºäºå…­å› å­æ¨¡å‹è¾“å‡ºè¯„åˆ†ä¸å»ºè®®
- ç¦æ­¢è·³è¿‡æ¨ç†ç›´æ¥ç»™åˆ†

ã€è¯„åˆ†æ¨¡å‹ã€‘
ä¸‰æ®µå…­å› å­ï¼šå‰é¦™(ä¼˜é›…/è¾¨è¯†)ã€ä¸­å‘³(åè°ƒ/é¥±å’Œ)ã€åéŸµ(æŒä¹…/è‹¦æ¶©)ã€‚

ã€æ€ç»´é“¾è¦æ±‚ã€‘
1. å…ˆåˆ¤æ–­æ³¨æ„äº‹é¡¹ï¼Œå¦‚è‹¦æ¶©åº¦çš„è½¬åŒ–æ˜¯åŒ–å¼€å›ç”˜è¿˜æ˜¯é”å–‰ç„¦è‹¦ã€‚
2. ç»“åˆé¦™æ°”å’Œå£æ„Ÿç»™äºˆå®¢è§‚åˆ†æ•°ï¼ˆ0-9åˆ†ï¼‰ã€‚
3. é’ˆå¯¹æ¯ä¸ªå› å­ç»™å‡ºå…·ä½“çš„ä¾æ®åŸå› ã€ã€é‰´èµå»ºè®®ã€‘ï¼ˆé«˜åˆ†ï¼‰æˆ–ã€æ”¹è¿›å»ºè®®ã€‘ï¼ˆä½åˆ†ï¼‰ã€‚

{model_description}""",
    
    "user_template": """ã€å¾…è¯„åˆ†äº§å“ã€‘
{product_desc}

ã€å‚è€ƒæ ‡å‡†ï¼ˆæ‰‹å†Œï¼‰ã€‘
{context_text}

ã€å†å²åˆ¤ä¾‹å‚è€ƒï¼ˆFew-Shotï¼‰ã€‘
{case_text}

è¯·ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹JSONæ ¼å¼ï¼ˆä¸å«Markdownï¼‰ï¼š
{{
  "master_comment": "çº¦100å­—çš„å®—å¸ˆçº§æ€»è¯„ï¼Œå¯Œå«æ–‡åŒ–æ„è•´...",
  "scores": {{
    "ä¼˜é›…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è¾¨è¯†åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "åè°ƒæ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "é¥±å’Œåº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "æŒä¹…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è‹¦æ¶©åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}}
  }}
}}"""
}

# ==========================================
# 2. é€»è¾‘å‡½æ•°
# ==========================================

def get_model_desc(): return "ä¼˜é›…æ€§/è¾¨è¯†åº¦/åè°ƒæ€§/é¥±å’Œåº¦/æŒä¹…æ€§/è‹¦æ¶©åº¦ï¼Œå…³æ³¨å„é˜¶æ®µæ„Ÿå®˜è¡¨ç°ã€‚"

def run_scoring(text, kb_res, case_res, prompt_cfg, embedder, client, model_id):
    vec = embedder.encode([text])
    ctx_txt, hits = "ï¼ˆæ— æ‰‹å†Œèµ„æ–™ï¼‰", []
    if kb_res[0].ntotal > 0:
        _, idx = kb_res[0].search(vec, 3)
        hits = [kb_res[1][i] for i in idx[0] if i < len(kb_res[1])]
        ctx_txt = "\n".join([f"- {h[:200]}..." for h in hits])
        
    case_txt, found_cases = "ï¼ˆæ— ç›¸ä¼¼åˆ¤ä¾‹ï¼‰", []
    if case_res[0].ntotal > 0:
        _, idx = case_res[0].search(vec, 2)
        for i in idx[0]:
            if i < len(case_res[1]) and i >= 0:
                c = case_res[1][i]
                found_cases.append(c)
                sc = c.get('scores', {})
                u_sc = sc.get('ä¼˜é›…æ€§',{}).get('score', 0) if isinstance(sc,dict) and 'ä¼˜é›…æ€§' in sc else 0
                k_sc = sc.get('è‹¦æ¶©åº¦',{}).get('score', 0) if isinstance(sc,dict) and 'è‹¦æ¶©åº¦' in sc else 0
                case_txt += f"\nå‚è€ƒæ¡ˆä¾‹: {c['text'][:30]}... -> ä¼˜é›…æ€§:{u_sc} è‹¦æ¶©åº¦:{k_sc}"

    sys_p = prompt_cfg.get('system_template', DEFAULT_PROMPT_CONFIG['system_template']).replace("{model_description}", get_model_desc())
    user_p = prompt_cfg.get('user_template', DEFAULT_PROMPT_CONFIG['user_template']).format(product_desc=text, context_text=ctx_txt, case_text=case_txt)

    try:
        resp = client.chat.completions.create(
            model=model_id, # ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ Model ID
            messages=[{"role":"system", "content":sys_p}, {"role":"user", "content":user_p}],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        return json.loads(resp.choices[0].message.content), hits, found_cases
    except Exception as e:
        st.error(f"Inference Error: {e}")
        return None, [], []

def parse_file(uploaded_file):
    try:
        if uploaded_file.name.endswith('.txt'): return uploaded_file.read().decode("utf-8")
        if uploaded_file.name.endswith('.pdf'): return "".join([p.extract_text() for p in PdfReader(uploaded_file).pages])
        if uploaded_file.name.endswith('.docx'): return "\n".join([p.text for p in Document(uploaded_file).paragraphs])
    except: return ""
    return ""

def create_word_report(results):
    doc = Document()
    doc.add_heading("èŒ¶è¯„æ‰¹é‡è¯„åˆ†æŠ¥å‘Š", 0)
    for item in results:
        doc.add_heading(f"æ¡ç›® {item['id']}", 1)
        doc.add_paragraph(f"åŸæ–‡ï¼š{item['text']}")
        s = item.get('scores', {}).get('scores', {})
        mc = item.get('scores', {}).get('master_comment', '')
        if mc: doc.add_paragraph(f"æ€»è¯„ï¼š{mc}", style="Intense Quote")
        
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'
        hdr = table.rows[0].cells
        hdr[0].text, hdr[1].text, hdr[2].text, hdr[3].text = 'å› å­', 'åˆ†æ•°', 'è¯„è¯­', 'å»ºè®®'
        for k, v in s.items():
            r = table.add_row().cells
            r[0].text = k
            r[1].text = str(v.get('score',''))
            r[2].text = v.get('comment','')
            r[3].text = v.get('suggestion','')
        doc.add_paragraph("_"*20)
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

# ==========================================
# 3. é¡µé¢åˆå§‹åŒ–
# ==========================================

if 'loaded' not in st.session_state:
    kb_idx, kb_data = DataManager.load(PATHS['kb_index'], PATHS['kb_chunks'])
    case_idx, case_data = DataManager.load(PATHS['case_index'], PATHS['case_data'], is_json=True)
    st.session_state.kb = (kb_idx, kb_data)
    st.session_state.cases = (case_idx, case_data)
    
    if PATHS['prompt'].exists():
        try:
            with open(PATHS['prompt'], 'r') as f: st.session_state.prompt_config = json.load(f)
        except: st.session_state.prompt_config = DEFAULT_PROMPT_CONFIG.copy()
    else:
        st.session_state.prompt_config = DEFAULT_PROMPT_CONFIG.copy()
    
    st.session_state.loaded = True
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    st.markdown("**ğŸ” API é…ç½®ï¼ˆé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰**")

    # å…ˆä»ç¯å¢ƒå˜é‡ / secrets è¯»
    env_aliyun_key = os.getenv("ALIYUN_API_KEY") or st.secrets.get("ALIYUN_API_KEY", "")
    env_deepseek_key = os.getenv("DEEPSEEK_API_KEY") or st.secrets.get("DEEPSEEK_API_KEY", "")

    # UI ä»ç„¶ä¿ç•™ï¼Œä½†é»˜è®¤å€¼æ˜¯ç¯å¢ƒå˜é‡
    aliyun_key = st.text_input(
        "é˜¿é‡Œäº‘ Keyï¼ˆå¯è¦†ç›–ï¼‰",
        value=env_aliyun_key,
        type="password"
    )

    deepseek_key = st.text_input(
        "DeepSeek Keyï¼ˆå¯è¦†ç›–ï¼‰",
        value=env_deepseek_key,
        type="password"
    )

    if not aliyun_key or not deepseek_key:
        st.warning("âš ï¸ å½“å‰æœªé…ç½® API Keyï¼Œç³»ç»Ÿå°†æ— æ³•è¿è¡Œ")
        st.stop()

    st.markdown("---")
    st.markdown("**ğŸ§  æ¨¡å‹è®¾å®š**")

    ft_status = DataManager.load_ft_status()
    default_model = "deepseek-chat"
    if ft_status and ft_status.get("status") == "succeeded":
        default_model = ft_status.get("fine_tuned_model", default_model)
        st.toast(f"å·²åŠ è½½å¾®è°ƒæ¨¡å‹: {default_model}", icon="ğŸ‰")

    model_id = st.text_input("Model ID", value=default_model)

    embedder = AliyunEmbedder(aliyun_key)
    client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")
    
    st.markdown("---")
    st.markdown("**ğŸ“š RAG çŸ¥è¯†åº“ç®¡ç†**")
    
    # æ˜¾ç¤ºå½“å‰ RAG çŠ¶æ€
    st.caption(f"çŸ¥è¯†åº“ç‰‡æ®µ: {len(st.session_state.kb[1])} æ¡")
    st.caption(f"åˆ¤ä¾‹åº“æ¡ˆä¾‹: {len(st.session_state.cases[1])} æ¡")
    
    if st.button("ğŸ“¤ å¯¼å‡º RAG æ•°æ®"):
        # åˆ›å»ºå‹ç¼©åŒ…
        import zipfile, shutil
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = Path("./temp_export")
        temp_dir.mkdir(exist_ok=True)
        
        # å¤åˆ¶æ‰€æœ‰ RAG æ–‡ä»¶
        for key, path in PATHS.items():
            if path.exists():
                shutil.copy2(path, temp_dir / path.name)
        
        # åˆ›å»º zip æ–‡ä»¶
        zip_path = Path("./rag_export.zip")
        with zipfile.ZipFile(zip_path, 'w') as zipf:
            for file in temp_dir.iterdir():
                zipf.write(file, file.name)
        
        # æä¾›ä¸‹è½½
        with open(zip_path, 'rb') as f:
            st.download_button(
                label="â¬‡ï¸ ä¸‹è½½ RAG æ•°æ®åŒ…",
                data=f,
                file_name="tea_rag_data.zip",
                mime="application/zip"
            )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        shutil.rmtree(temp_dir)
        zip_path.unlink()
    
    if st.button("ğŸ“¥ å¯¼å…¥ RAG æ•°æ®"):
        uploaded_zip = st.file_uploader("ä¸Šä¼  RAG æ•°æ®åŒ…", type=['zip'])
        if uploaded_zip:
            with st.spinner("å¯¼å…¥ä¸­..."):
                # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
                import tempfile, zipfile
                with tempfile.TemporaryDirectory() as tmpdir:
                    zip_path = Path(tmpdir) / "uploaded.zip"
                    with open(zip_path, 'wb') as f:
                        f.write(uploaded_zip.getvalue())
                    
                    # è§£å‹
                    with zipfile.ZipFile(zip_path, 'r') as zipf:
                        zipf.extractall(DATA_DIR)
                    
                    # é‡æ–°åŠ è½½æ•°æ®
                    kb_idx, kb_data = DataManager.load(PATHS['kb_index'], PATHS['kb_chunks'])
                    case_idx, case_data = DataManager.load(PATHS['case_index'], PATHS['case_data'], is_json=True)
                    st.session_state.kb = (kb_idx, kb_data)
                    st.session_state.cases = (case_idx, case_data)
                    
                    st.success("âœ… RAG æ•°æ®å¯¼å…¥æˆåŠŸï¼")
                    st.rerun()
st.markdown('<div class="main-title">ğŸµ èŒ¶é¥®å…­å› å­ AI è¯„åˆ†å™¨ Pro</div>', unsafe_allow_html=True)
st.markdown('<div class="slogan">â€œä¸€ç‰‡å¶å­è½å…¥æ°´ä¸­ï¼Œæ”¹å˜äº†æ°´çš„å‘³é“...â€</div>', unsafe_allow_html=True)

# ==========================================
# 4. åŠŸèƒ½æ ‡ç­¾é¡µ
# ==========================================
tab1, tab2, tab3 = st.tabs(["ğŸ’¡ äº¤äº’è¯„åˆ†", "ğŸš€ æ‰¹é‡è¯„åˆ†", "ğŸ› ï¸ æ¨¡å‹è°ƒä¼˜"])

# --- Tab 1: äº¤äº’è¯„åˆ† ---
with tab1:
    st.info("AI å°†å‚è€ƒçŸ¥è¯†åº“ä¸åˆ¤ä¾‹åº“è¿›è¡Œè¯„åˆ†ã€‚ç¡®è®¤ç»“æœåå°†è‡ªåŠ¨æ›´æ–° RAG åº“å’Œåå°å¾®è°ƒæ•°æ®ã€‚")
    user_input = st.text_area("è¾“å…¥èŒ¶è¯„æè¿°:", height=120)
    
    if st.button("å¼€å§‹è¯„åˆ†", type="primary", use_container_width=True):
        if not user_input or not client: st.warning("è¯·æ£€æŸ¥è¾“å…¥æˆ– API Key")
        else:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨æ¨¡å‹ {model_id} å“é‰´..."):
                scores, kb_hits, case_hits = run_scoring(
                    user_input, st.session_state.kb, st.session_state.cases,
                    st.session_state.prompt_config, embedder, client, model_id
                )
                if scores:
                    mc = scores.get("master_comment", "æš‚æ— æ€»è¯„")
                    st.markdown(f'<div class="master-comment"><b>ğŸ‘µ å®—å¸ˆæ€»è¯„ï¼š</b><br>{mc}</div>', unsafe_allow_html=True)
                    
                    cols = st.columns(3)
                    factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
                    s_dict = scores.get("scores", {})
                    
                    for i, fname in enumerate(factors):
                        if fname in s_dict:
                            data = s_dict[fname]
                            with cols[i%3]:
                                st.markdown(f"""<div class="factor-card"><div class="score-header"><span>{fname}</span><span>{data.get('score')}/9</span></div><div style="margin:5px 0; font-size:0.9em;">{data.get('comment')}</div><div class="advice-tag">ğŸ’¡ {data.get('suggestion','')}</div></div>""", unsafe_allow_html=True)
                    
                    with st.expander("ğŸ“¥ è®¤å¯æ­¤è¯„åˆ†ï¼Ÿ(ç‚¹å‡»ä¿å­˜)"):
                        if st.button("âœ… ç¡®è®¤ä¿å­˜ (è‡ªåŠ¨åŠ å…¥è®­ç»ƒé›†)"):
                            new_case = {"text": user_input, "scores": s_dict, "tags": "äº¤äº’ç”Ÿæˆ"}
                            st.session_state.cases[1].append(new_case)
                            vec = embedder.encode([user_input])
                            st.session_state.cases[0].add(vec)
                            DataManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS['case_index'], PATHS['case_data'], is_json=True)
                            
                            sys_p = st.session_state.prompt_config['system_template'].replace("{model_description}", get_model_desc())
                            DataManager.append_to_finetune(user_input, s_dict, sys_p, st.session_state.prompt_config['user_template'])
                            
                            st.success("å·²å­˜æ¡£ï¼æ•°æ®å·²åŠ å…¥ RAG åº“å’Œå¾®è°ƒé˜Ÿåˆ—ã€‚")
                            time.sleep(1)
                            st.rerun()

# --- Tab 2: æ‰¹é‡è¯„åˆ† ---
with tab2:
    up_file = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (æ”¯æŒ .txt / .docx)", type=['txt','docx'])
    if up_file and st.button("å¼€å§‹æ‰¹é‡å¤„ç†"):
        if not client: st.error("è¯·é…ç½® Key")
        else:
            txt = parse_file(up_file)
            lines = [l.strip() for l in txt.split('\n') if len(l)>10]
            results = []
            bar = st.progress(0)
            for i, line in enumerate(lines):
                s, _, _ = run_scoring(line, st.session_state.kb, st.session_state.cases, st.session_state.prompt_config, embedder, client, model_id)
                results.append({"id": i+1, "text": line, "scores": s})
                bar.progress((i+1)/len(lines))
            st.success("å®Œæˆï¼")
            doc_io = create_word_report(results)
            st.download_button("ğŸ“¥ ä¸‹è½½ Word æŠ¥å‘Š", doc_io, "èŒ¶è¯„æŠ¥å‘Š.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document")

# --- Tab 3: æ¨¡å‹è°ƒä¼˜ (è‡ªåŠ¨åŒ–å¾®è°ƒæµç¨‹) ---
with tab3:
    c1, c2, c3 = st.columns(3)
    
    # Column 1: RAG çŸ¥è¯†åº“
    with c1:
        st.subheader("ğŸ“š RAG çŸ¥è¯†åº“")
        files = st.file_uploader("ä¸Šä¼ PDF", accept_multiple_files=True, key="kb_up")
        st.info(f"ğŸ’¾ å½“å‰å­˜å‚¨: {len(st.session_state.kb[1])} ç‰‡æ®µ")
        if files and st.button("æ›´æ–°çŸ¥è¯†åº“"):
            if not embedder: st.error("éœ€ API Key")
            else:
                with st.spinner("å¤„ç†å¹¶å­˜ç›˜..."):
                    raw = "".join([parse_file(f) for f in files])
                    chunks = [raw[i:i+600] for i in range(0,len(raw),500)]
                    vecs = embedder.encode(chunks)
                    idx = faiss.IndexFlatL2(1024)
                    idx.add(vecs)
                    st.session_state.kb = (idx, chunks)
                    DataManager.save(idx, chunks, PATHS['kb_index'], PATHS['kb_chunks'])
                    st.success("çŸ¥è¯†åº“å·²æ›´æ–°ï¼"); time.sleep(1); st.rerun()

    # Column 2: åˆ¤ä¾‹åº“ & å¾®è°ƒæ§åˆ¶å°
    with c2:
        st.subheader("âš–ï¸ åˆ¤ä¾‹åº“ & å¾®è°ƒ")
        st.caption("ä½ å½•å…¥çš„åˆ¤ä¾‹å°†è‡ªåŠ¨ç§¯ç´¯ä¸ºå¾®è°ƒæ•°æ®")
        
        # ä¿®å¤ç‚¹ï¼šå…ˆå®šä¹‰ case_count
        case_count = len(st.session_state.cases[1])
        st.info(f"ğŸ’¾ å½“å‰åˆ¤ä¾‹: {case_count} æ¡")

        # === å¾®è°ƒæ§åˆ¶é¢æ¿ ===
        st.markdown("#### â˜ï¸ äº‘ç«¯å¾®è°ƒæ§åˆ¶å°")
        
        line_count = 0
        if PATHS['training_file'].exists():
            try: line_count = sum(1 for _ in open(PATHS['training_file'], 'r', encoding='utf-8'))
            except: pass
        
        st.write(f"å¯ç”¨å¾®è°ƒæ•°æ®: **{line_count} æ¡**")
        
        if line_count >= 10:
            if st.button("ğŸš€ ä¸€é”®å¯åŠ¨å¾®è°ƒ (DeepSeek)"):
                if not client: st.error("è¯·å…ˆé…ç½® API Key")
                else:
                    try:
                        with open(PATHS['training_file'], "rb") as f:
                            file_obj = client.files.create(file=f, purpose="fine-tune")
                        job = client.fine_tuning.jobs.create(
                            training_file=file_obj.id,
                            model="deepseek-chat",
                            suffix="tea-expert"
                        )
                        DataManager.save_ft_status(job.id, "queued", fine_tuned_model=None)
                        st.success(f"å¾®è°ƒä»»åŠ¡å·²å¯åŠ¨ï¼Job ID: {job.id}")
                        time.sleep(1); st.rerun()
                    except Exception as e:
                        st.error(f"å¯åŠ¨å¾®è°ƒå¤±è´¥: {e}")
        else:
            st.warning("âš ï¸ å»ºè®®ç§¯ç´¯è‡³å°‘ 10 æ¡åˆ¤ä¾‹åè¿›è¡Œå¾®è°ƒã€‚")

        ft_status = DataManager.load_ft_status()
        if ft_status:
            st.markdown(f"""
            <div class="ft-card">
                <b>ğŸ”„ æœ€è¿‘ä»»åŠ¡çŠ¶æ€</b><br>
                Job ID: <code>{ft_status.get('job_id', 'N/A')}</code><br>
                çŠ¶æ€: <b>{ft_status.get('status', 'N/A')}</b><br>
                æ¨¡å‹: {ft_status.get('fine_tuned_model', 'N/A')}
            </div>
            """, unsafe_allow_html=True)
            
            if ft_status.get('status') in ['queued', 'running']:
                if st.button("ğŸ”„ åˆ·æ–°çŠ¶æ€"):
                    try:
                        job = client.fine_tuning.jobs.retrieve(ft_status['job_id'])
                        new_status = job.status
                        ft_info = {"job_id": job.id, "status": new_status}
                        if new_status == 'succeeded':
                            ft_info["fine_tuned_model"] = job.fine_tuned_model
                            st.success(f"è®­ç»ƒå®Œæˆï¼æ¨¡å‹: {ft_info['fine_tuned_model']}")
                            st.balloons()
                        elif new_status == 'failed':
                            ft_info["error"] = job.error.message
                            st.error(f"è®­ç»ƒå¤±è´¥: {job.error.message}")
                        
                        DataManager.save_ft_status(ft_info['job_id'], ft_info['status'], ft_info.get('fine_tuned_model'))
                        time.sleep(1); st.rerun()
                    except Exception as e:
                        st.error(f"æŸ¥è¯¢çŠ¶æ€å¤±è´¥: {e}")

        with st.expander("â• æ·»åŠ ç²¾ç»†åˆ¤ä¾‹"):
            with st.form("case_form"):
                f_txt = st.text_area("åˆ¤ä¾‹æè¿°", height=80)
                f_tag = st.text_input("æ ‡ç­¾", "äººå·¥å½•å…¥")
                st.markdown("**å› å­è¯„åˆ†è¯¦æƒ…**")
                fc1, fc2 = st.columns(2)
                factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
                input_scores = {}
                for i, f in enumerate(factors):
                    with (fc1 if i%2==0 else fc2):
                        val = st.number_input(f"{f}åˆ†æ•°", 0,9,7, key=f"s_{i}")
                        cmt = st.text_input(f"{f}è¯„è¯­", key=f"c_{i}")
                        sug = st.text_input(f"{f}å»ºè®®", key=f"a_{i}")
                        input_scores[f] = {"score": val, "comment": cmt, "suggestion": sug}
                
                if st.form_submit_button("ä¿å­˜"):
                    if not embedder: st.error("éœ€ API Key")
                    else:
                        new_c = {"text": f_txt, "tags": f_tag, "scores": input_scores}
                        st.session_state.cases[1].append(new_c)
                        vec = embedder.encode([f_txt])
                        st.session_state.cases[0].add(vec)
                        DataManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS['case_index'], PATHS['case_data'], is_json=True)
                        
                        sys_p = st.session_state.prompt_config['system_template'].replace("{model_description}", get_model_desc())
                        DataManager.append_to_finetune(f_txt, input_scores, sys_p, st.session_state.prompt_config['user_template'])
                        
                        st.success("å·²ä¿å­˜ï¼")
                        time.sleep(1); st.rerun()

        st.write(f"ç°æœ‰åˆ¤ä¾‹é¢„è§ˆ:")
        for i, c in enumerate(st.session_state.cases[1][-5:]):
            with st.expander(f"#{case_count-i} {c.get('tags','')}"):
                st.write(c['text'][:50]+"...")
                st.json(c['scores'])

    # Column 3: Prompt
    with c3:
        st.subheader("ğŸ“ Prompt æ¨¡æ¿")
        current_sys = st.session_state.prompt_config.get('system_template', '')
        current_user = st.session_state.prompt_config.get('user_template', '')
        
        if "{case_text}" not in current_user: st.warning("User Template ç¼ºå°‘ {case_text}")
        
        sys_t = st.text_area("System Template", current_sys, height=200)
        user_t = st.text_area("User Template", current_user, height=200)
        
        if st.button("ğŸ’¾ ä¿å­˜ Prompt"):
            new_cfg = {"system_template": sys_t, "user_template": user_t}
            st.session_state.prompt_config = new_cfg
            with open(PATHS['prompt'], 'w') as f: json.dump(new_cfg, f, ensure_ascii=False)

            st.success("Prompt å·²ä¿å­˜ï¼"); time.sleep(1); st.rerun()


