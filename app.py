import streamlit as st
import os
import json
import requests
import numpy as np
import faiss
import time
import pickle
from github import Github, GithubException, Auth  # æ–°å¢ Auth
from pathlib import Path
from io import BytesIO
from typing import List, Dict, Any, Tuple, Optional
from PyPDF2 import PdfReader
from http import HTTPStatus
import dashscope
from dashscope import TextEmbedding
from openai import OpenAI
from docx import Document
import matplotlib.pyplot as plt
from scipy.interpolate import make_interp_spline
import base64

# ==========================================
# [SECTION 0] åŸºç¡€é…ç½®ä¸è·¯å¾„å®šä¹‰
# ==========================================

st.set_page_config(
    page_title="èŒ¶é¥®å…­å› å­AIè¯„åˆ†å™¨ Pro",
    page_icon="ğŸµ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ ·å¼å®šä¹‰
st.markdown("""
    <style>
    .main-title {font-size: 2.5em; font-weight: bold; text-align: center; color: #2E7D32; margin-bottom: 0.5em;}
    .slogan {font-size: 1.2em; font-style: italic; text-align: center; color: #558B2F; margin-bottom: 30px; font-family: "KaiTi", "æ¥·ä½“", serif;}
    .factor-card {background-color: #F1F8E9; padding: 15px; border-radius: 10px; margin-bottom: 10px; border-left: 5px solid #4CAF50;}
    .score-header {display:flex; justify-content:space-between; font-weight:bold; color:#2E7D32;}
    .advice-tag {font-size: 0.85em; padding: 2px 6px; border-radius: 4px; margin-top: 5px; background-color: #fff; border: 1px dashed #4CAF50; color: #388E3C; display: inline-block;}
    .master-comment {background-color: #FFFDE7; border: 1px solid #FFF9C4; padding: 15px; border-radius: 8px; font-family: "KaiTi", serif; font-size: 1.1em; color: #5D4037; margin-bottom: 20px; line-height: 1.6;}
    .ft-card {border: 1px solid #ddd; padding: 15px; border-radius: 8px; background-color: #f8f9fa; margin-top: 10px;}
    .case-card {border: 1px solid #e0e0e0; padding: 12px; border-radius: 8px; margin-bottom: 10px; background-color: #fafafa;}
    </style>
""", unsafe_allow_html=True)

class PathConfig:
    """è·¯å¾„ç®¡ç†ç±»"""
    # å¤–éƒ¨èµ„æºæ–‡ä»¶ï¼ˆä½äºåŒçº§ç›®å½•ï¼‰
    SRC_SYS_PROMPT = Path("sys_p.txt")
    SRC_CASES = Path("tea_data/case.json")  # Caseæ–‡ä»¶å­˜å‚¨
    # è¿è¡Œæ—¶æ•°æ®ç›®å½•
    DATA_DIR = Path("./tea_data")
    RAG_DIR = Path("./tea_data/RAG")  # RAGæ–‡ä»¶å­˜å‚¨ç›®å½•
    
    def __init__(self):
        self.DATA_DIR.mkdir(exist_ok=True)
        self.RAG_DIR.mkdir(exist_ok=True)  # ç¡®ä¿RAGç›®å½•å­˜åœ¨
        # å‘é‡åº“ä¸æŒä¹…åŒ–æ•°æ®
        self.kb_index = self.DATA_DIR / "kb.index"
        self.kb_chunks = self.DATA_DIR / "kb_chunks.pkl"
        self.kb_files = self.DATA_DIR / "kb_files.json"  # æ–°å¢ï¼šè®°å½•RAGæ–‡ä»¶åˆ—è¡¨
        self.case_index = self.DATA_DIR / "cases.index"
        self.case_data = self.DATA_DIR / "case.json"  # ä¿®æ”¹ï¼šä¸GitHubä¿æŒä¸€è‡´
        
        # å¾®è°ƒä¸Prompté…ç½®
        self.training_file = self.DATA_DIR / "deepseek_finetune.jsonl"
        self.ft_status = self.DATA_DIR / "ft_status.json"
        self.prompt_config_file = self.DATA_DIR / "prompts.json"

PATHS = PathConfig()

# é»˜è®¤çš„ç”¨æˆ·Promptæ¨¡æ¿ï¼ˆSystem Promptå°†ä»æ–‡ä»¶è¯»å–ï¼‰
DEFAULT_USER_TEMPLATE = """ã€å¾…è¯„åˆ†äº§å“ã€‘
{product_desc}

ã€å‚è€ƒæ ‡å‡†ï¼ˆçŸ¥è¯†åº“ï¼‰ã€‘
{context_text}

ã€ç›¸ä¼¼åˆ¤ä¾‹å¾—åˆ†å‚è€ƒï¼ˆæ¡ˆä¾‹åº“ï¼‰ã€‘
{case_text}

è¯·ä¸¥æ ¼è¾“å‡ºä»¥ä¸‹JSONæ ¼å¼ï¼ˆä¸å«Markdownï¼‰ï¼š
{{
  "master_comment": "çº¦100å­—çš„å®—å¸ˆçº§æ€»è¯„ï¼Œå¯Œå«æ–‡åŒ–æ„è•´...",
  "scores": {{
    "ä¼˜é›…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è¾¨è¯†åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "åè°ƒæ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "é¥±å’Œåº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "æŒä¹…æ€§": {{"score": 0-9, "comment": "...", "suggestion": "..."}},
    "è‹¦æ¶©åº¦": {{"score": 0-9, "comment": "...", "suggestion": "..."}}
  }}
}}"""

# ==========================================
# [SECTION 1] èµ„æºä¸æ•°æ®ç®¡ç†
# ==========================================

class ResourceManager:
    """è´Ÿè´£å¤–éƒ¨æ–‡ä»¶åŠ è½½ã€æ•°æ®æŒä¹…åŒ–åŠæ ¼å¼è½¬æ¢"""

    @staticmethod
    def load_external_text(path: Path, fallback: str = "") -> str:
        """è¯»å–å¤–éƒ¨æ–‡æœ¬æ–‡ä»¶ (å¦‚ sys_p.txt)"""
        if path.exists():
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return f.read().strip()
            except Exception as e:
                st.error(f"åŠ è½½æ–‡ä»¶ {path} å¤±è´¥: {e}")
        return fallback

    @staticmethod
    def load_external_json(path: Path, fallback: Any = None) -> Any:
        """è¯»å–å¤–éƒ¨JSONæ–‡ä»¶"""
        if path.exists():
            try:
                with open(path, "r", encoding="utf-8") as f:
                    return json.load(f)
            except Exception as e:
                st.error(f"åŠ è½½æ–‡ä»¶ {path} å¤±è´¥: {e}")
        return fallback if fallback is not None else []

    @staticmethod
    def save(index: Any, data: Any, idx_path: Path, data_path: Path, is_json: bool = False):
        """ä¿å­˜ FAISS ç´¢å¼•å’Œæ•°æ®æ–‡ä»¶"""
        if index: faiss.write_index(index, str(idx_path))
        with open(data_path, "w" if is_json else "wb", encoding="utf-8" if is_json else None) as f:
            if is_json: json.dump(data, f, ensure_ascii=False, indent=2)
            else: pickle.dump(data, f)
    
    @staticmethod
    def load(idx_path: Path, data_path: Path, is_json: bool = False) -> Tuple[Any, List]:
        """åŠ è½½ FAISS ç´¢å¼•å’Œæ•°æ®æ–‡ä»¶"""
        if idx_path.exists() and data_path.exists():
            try:
                index = faiss.read_index(str(idx_path))
                with open(data_path, "r" if is_json else "rb", encoding="utf-8" if is_json else None) as f:
                    data = json.load(f) if is_json else pickle.load(f)
                return index, data
            except: pass
        return faiss.IndexFlatIP(1024), []

    # ===== å¾®è°ƒç›¸å…³æ–¹æ³• =====
    @staticmethod
    def overwrite_finetune(cases: List[Dict], sys_prompt: str, user_tpl: str) -> int:
        """è¦†ç›–å†™å…¥å¾®è°ƒæ•°æ®é›† (.jsonl) - ä¿®æ”¹ä¸ºè¦†ç›–é€»è¾‘"""
        try:
            count = 0
            with open(PATHS.training_file, "w", encoding="utf-8") as f:
                for c in cases:
                    case_text = c.get("text", "")
                    scores = c.get("scores", {})
                    master_comment = c.get("master_comment", "ï¼ˆäººå·¥æ ¡å‡†ï¼‰")
                    
                    user_content = user_tpl.format(product_desc=case_text, context_text="", case_text="")
                    assistant_content = json.dumps({"master_comment": master_comment, "scores": scores}, ensure_ascii=False)
                    entry = {
                        "messages": [
                            {"role": "system", "content": sys_prompt},
                            {"role": "user", "content": user_content},
                            {"role": "assistant", "content": assistant_content}
                        ]
                    }
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                    count += 1
            return count
        except Exception as e:
            print(f"[ERROR] Finetune overwrite failed: {e}")
            return 0

    @staticmethod
    def save_ft_status(job_id, status, fine_tuned_model=None):
        data = {"job_id": job_id, "status": status, "timestamp": time.time()}
        if fine_tuned_model: data["fine_tuned_model"] = fine_tuned_model
        with open(PATHS.ft_status, 'w') as f: json.dump(data, f)

    @staticmethod
    def load_ft_status():
        if PATHS.ft_status.exists():
            try: return json.load(open(PATHS.ft_status, 'r'))
            except: pass
        return None

    # ===== RAGæ–‡ä»¶ç®¡ç† =====
    @staticmethod
    def save_kb_files(file_list: List[str]):
        """ä¿å­˜çŸ¥è¯†åº“æ–‡ä»¶åˆ—è¡¨"""
        with open(PATHS.kb_files, "w", encoding="utf-8") as f:
            json.dump(file_list, f, ensure_ascii=False, indent=2)
    
    @staticmethod
    def load_kb_files() -> List[str]:
        """åŠ è½½çŸ¥è¯†åº“æ–‡ä»¶åˆ—è¡¨"""
        if PATHS.kb_files.exists():
            try:
                with open(PATHS.kb_files, "r", encoding="utf-8") as f:
                    return json.load(f)
            except: pass
        return []

# ==========================================
# [SECTION 1.5] Github åŒæ­¥å·¥å…· (å¢å¼ºç‰ˆ)
# ==========================================

class GithubSync:
    """è´Ÿè´£å°†æ•°æ®åŒæ­¥å› Github ä»“åº“"""
    
    @staticmethod
    def _get_github_config():
        """è·å–GitHubé…ç½®"""
        token = st.secrets.get("GITHUB_TOKEN")
        repo_name = st.secrets.get("GITHUB_REPO")
        branch = st.secrets.get("GITHUB_BRANCH", "main")
        return token, repo_name, branch
    
    @staticmethod
    def _get_github_client():
        """è·å– GitHub å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨æ–°çš„è®¤è¯æ–¹å¼ï¼‰"""
        token, repo_name, branch = GithubSync._get_github_config()
        if not token or not repo_name:
            return None, None, None
        # ä½¿ç”¨æ–°çš„è®¤è¯æ–¹å¼ï¼Œé¿å… DeprecationWarning
        g = Github(auth=Auth.Token(token))
        return g, repo_name, branch
    
    @staticmethod
    def push_json(file_path_in_repo: str, data_dict: Dict, commit_msg: str = "Update via Streamlit") -> bool:
        """æ¨é€ JSON æ•°æ®åˆ° Github"""
        g, repo_name, branch = GithubSync._get_github_client()
        
        if not g or not repo_name:
            st.error("âŒ æœªé…ç½® Github Token æˆ– ä»“åº“å (GITHUB_TOKEN / GITHUB_REPO)")
            return False

        try:
            repo = g.get_repo(repo_name)
            content_str = json.dumps(data_dict, ensure_ascii=False, indent=2)
            
            try:
                contents = repo.get_contents(file_path_in_repo, ref=branch)
                repo.update_file(
                    path=contents.path,
                    message=commit_msg,
                    content=content_str,
                    sha=contents.sha,
                    branch=branch
                )
            except GithubException as e:
                if e.status == 404:
                    repo.create_file(
                        path=file_path_in_repo,
                        message=f"Create {file_path_in_repo}",
                        content=content_str,
                        branch=branch
                    )
                else:
                    raise e
            return True

        except Exception as e:
            st.error(f"Github åŒæ­¥å¤±è´¥: {str(e)}")
            return False
    @staticmethod
    def load_json(file_path_in_repo: str, default=None):
        """ä» Github è¯»å– JSON æ–‡ä»¶ï¼›ä¸å­˜åœ¨/è¯»å–å¤±è´¥åˆ™è¿”å› default"""
        if default is None:
            default = []
    
        g, repo_name, branch = GithubSync._get_github_client()
        if not g or not repo_name:
            return default
    
        try:
            repo = g.get_repo(repo_name)
            contents = repo.get_contents(file_path_in_repo, ref=branch)
            raw = contents.decoded_content.decode("utf-8").strip()
            if not raw:
                return default
            return json.loads(raw)
    
        except GithubException as e:
            if getattr(e, "status", None) == 404:
                return default
            st.error(f"Github è¯»å–å¤±è´¥: {str(e)}")
            return default
    
        except Exception as e:
            st.error(f"Github è¯»å–å¤±è´¥: {str(e)}")
            return default
    
    @staticmethod
    def push_binary_file(file_path_in_repo: str, file_content: bytes, commit_msg: str = "Upload file") -> bool:
            """æ¨é€äºŒè¿›åˆ¶æ–‡ä»¶åˆ° Github (å¦‚PDF, DOCXç­‰)
            
            é‡è¦ï¼šPyGithubçš„create_file/update_fileæ¥å—bytesç±»å‹æ—¶ä¼šè‡ªåŠ¨è¿›è¡Œbase64ç¼–ç 
            ä¸è¦æ‰‹åŠ¨ç¼–ç ï¼Œå¦åˆ™ä¼šå¯¼è‡´åŒé‡ç¼–ç ï¼
            """
            g, repo_name, branch = GithubSync._get_github_client()
            
            if not g or not repo_name:
                st.error("âŒ æœªé…ç½® Github Token æˆ– ä»“åº“å")
                return False
    
            try:
                repo = g.get_repo(repo_name)
                # æ³¨æ„ï¼šç›´æ¥ä¼ bytesï¼ŒPyGithubä¼šè‡ªåŠ¨base64ç¼–ç 
                # ä¸è¦æ‰‹åŠ¨ç¼–ç ï¼å¦åˆ™ä¼šå¯¼è‡´åŒé‡ç¼–ç ï¼Œæ–‡ä»¶æŸå
                
                try:
                    contents = repo.get_contents(file_path_in_repo, ref=branch)
                    repo.update_file(
                        path=contents.path,
                        message=commit_msg,
                        content=file_content,  # ç›´æ¥ä¼ bytes
                        sha=contents.sha,
                        branch=branch
                    )
                except GithubException as e:
                    if e.status == 404:
                        repo.create_file(
                            path=file_path_in_repo,
                            message=f"Create {file_path_in_repo}",
                            content=file_content,  # ç›´æ¥ä¼ bytes
                            branch=branch
                        )
                    else:
                        raise e
                return True
    
            except Exception as e:
                st.error(f"Github æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
                return False
    
    @staticmethod
    def delete_file(file_path_in_repo: str, commit_msg: str = "Delete file") -> bool:
        """ä» Github åˆ é™¤æ–‡ä»¶"""
        g, repo_name, branch = GithubSync._get_github_client()
        
        if not g or not repo_name:
            return False

        try:
            repo = g.get_repo(repo_name)
            
            try:
                contents = repo.get_contents(file_path_in_repo, ref=branch)
                repo.delete_file(
                    path=contents.path,
                    message=commit_msg,
                    sha=contents.sha,
                    branch=branch
                )
                return True
            except GithubException as e:
                if e.status == 404:
                    return True  # æ–‡ä»¶æœ¬æ¥å°±ä¸å­˜åœ¨
                raise e

        except Exception as e:
            st.error(f"Github åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    @staticmethod
    def add_rag_files(uploaded_files: List, rag_folder: str = "tea_data/RAG") -> Tuple[bool, List[str]]:
        """
        æ·»åŠ RAGæ–‡ä»¶åˆ°GitHubï¼ˆåªæ·»åŠ ï¼Œä¸åˆ é™¤ç°æœ‰æ–‡ä»¶ï¼‰
        - uploaded_files: Streamlitä¸Šä¼ çš„æ–‡ä»¶å¯¹è±¡åˆ—è¡¨
        - rag_folder: GitHubä¸Šçš„RAGæ–‡ä»¶å¤¹è·¯å¾„
        è¿”å›: (æ˜¯å¦æˆåŠŸ, æˆåŠŸä¸Šä¼ çš„æ–‡ä»¶ååˆ—è¡¨)
        """
        g, repo_name, branch = GithubSync._get_github_client()
        
        if not g or not repo_name:
            st.error("âŒ æœªé…ç½® Github Token æˆ– ä»“åº“å")
            return False, []

        try:
            uploaded_names = []
            for uf in uploaded_files:
                file_path = f"{rag_folder}/{uf.name}"
                uf.seek(0)
                file_content = uf.read()
                if GithubSync.push_binary_file(file_path, file_content, f"Add RAG file: {uf.name}"):
                    uploaded_names.append(uf.name)
                else:
                    st.warning(f"âš ï¸ ä¸Šä¼  {uf.name} å¤±è´¥")
            
            return len(uploaded_names) > 0, uploaded_names

        except Exception as e:
            st.error(f"RAGæ–‡ä»¶æ·»åŠ å¤±è´¥: {str(e)}")
            return False, []

    @staticmethod
    def list_rag_files(rag_folder: str = "tea_data/RAG") -> List[str]:
        """
        è·å–GitHubä¸ŠRAGæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶å
        è¿”å›: æ–‡ä»¶ååˆ—è¡¨
        """
        g, repo_name, branch = GithubSync._get_github_client()
        
        if not g or not repo_name:
            return []

        try:
            repo = g.get_repo(repo_name)
            contents = repo.get_contents(rag_folder, ref=branch)
            return [c.name for c in contents if c.type == "file"]
        except GithubException as e:
            if e.status == 404:
                return []  # æ–‡ä»¶å¤¹ä¸å­˜åœ¨
            print(f"[ERROR] è·å–RAGæ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []
        except Exception as e:
            print(f"[ERROR] è·å–RAGæ–‡ä»¶åˆ—è¡¨å¤±è´¥: {e}")
            return []

    @staticmethod
    def delete_rag_file(filename: str, rag_folder: str = "tea_data/RAG") -> bool:
        """
        ä»GitHubåˆ é™¤å•ä¸ªRAGæ–‡ä»¶
        - filename: è¦åˆ é™¤çš„æ–‡ä»¶å
        - rag_folder: GitHubä¸Šçš„RAGæ–‡ä»¶å¤¹è·¯å¾„
        è¿”å›: æ˜¯å¦æˆåŠŸ
        """
        file_path = f"{rag_folder}/{filename}"
        return GithubSync.delete_file(file_path, f"Delete RAG file: {filename}")

    @staticmethod
    def sync_cases(cases: List[Dict], file_path: str = "tea_data/case.json") -> bool:
        """åŒæ­¥åˆ¤ä¾‹åº“åˆ°GitHub"""
        return GithubSync.push_json(file_path, cases, "Update case.json from App")

    @staticmethod
    def pull_rag_folder(rag_folder: str = "tea_data/RAG") -> List[Tuple[str, bytes]]:
        """
        ä» GitHub æ‹‰å– RAG æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
        è¿”å›: [(æ–‡ä»¶å, æ–‡ä»¶å†…å®¹bytes), ...]
        
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. ä¼˜å…ˆä½¿ç”¨ Raw URLï¼ˆæœ€å¯é ï¼Œé€‚åˆå¤§æ–‡ä»¶ï¼‰
        2. å¤‡ç”¨æ–¹æ¡ˆï¼šGit Blob APIï¼ˆä»…å°äº1MBçš„æ–‡ä»¶ï¼‰
        3. å¢åŠ å®Œæ•´æ€§éªŒè¯ï¼šå¯¹æ¯”æ–‡ä»¶å¤§å°
        4. æ”¯æŒé‡è¯•æœºåˆ¶
        """
        token, repo_name, branch = GithubSync._get_github_config()
        
        if not token or not repo_name:
            print("[WARN] GitHub config not found, skip pulling RAG")
            return []

        def download_with_retry(url, headers, max_retries=3):
            """å¸¦é‡è¯•çš„ä¸‹è½½å‡½æ•°"""
            for attempt in range(1, max_retries + 1):
                try:
                    response = requests.get(url, headers=headers, timeout=180, stream=True)
                    if response.status_code == 200:
                        # ä½¿ç”¨ stream=True åˆ†å—ä¸‹è½½ï¼Œé¿å…å¤§æ–‡ä»¶è¶…æ—¶
                        content = b''
                        for chunk in response.iter_content(chunk_size=8192):
                            if chunk:
                                content += chunk
                        return content, True
                    else:
                        print(f"[WARN]     å°è¯• {attempt}/{max_retries}: HTTP {response.status_code}")
                except Exception as e:
                    print(f"[WARN]     å°è¯• {attempt}/{max_retries}: {e}")
                    if attempt < max_retries:
                        import time
                        time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
            return None, False

        try:
            g = Github(auth=Auth.Token(token))
            repo = g.get_repo(repo_name)
            
            files = []
            print(f"[INFO] ========== å¼€å§‹ä» GitHub æ‹‰å– RAG æ–‡ä»¶ ==========")
            print(f"[INFO] ä»“åº“: {repo_name}, åˆ†æ”¯: {branch}, æ–‡ä»¶å¤¹: {rag_folder}")
            
            try:
                contents = repo.get_contents(rag_folder, ref=branch)
                file_list = [c for c in contents if c.type == "file"]
                print(f"[INFO] å‘ç° {len(file_list)} ä¸ªæ–‡ä»¶")
                
                for idx, content in enumerate(file_list, 1):
                    print(f"\n[INFO] [{idx}/{len(file_list)}] æ­£åœ¨å¤„ç†: {content.name}")
                    print(f"[INFO]   â†’ æœŸæœ›å¤§å°: {content.size:,} bytes")
                    file_content = None
                    download_method = None
                    
                    # ===== æ–¹æ³•1ï¼šRaw URLï¼ˆä¼˜å…ˆï¼Œæœ€å¯é ï¼‰ =====
                    print(f"[INFO]   â†’ æ–¹æ³•1: Raw URL ä¸‹è½½...")
                    raw_url = f"https://raw.githubusercontent.com/{repo_name}/{branch}/{rag_folder}/{content.name}"
                    headers = {"Authorization": f"Bearer {token}"}
                    file_content, success = download_with_retry(raw_url, headers, max_retries=3)
                    
                    if success and file_content:
                        download_method = "Raw URL"
                        print(f"[INFO]   âœ“ ä¸‹è½½å®Œæˆ: {len(file_content):,} bytes")
                    
                    # ===== æ–¹æ³•2ï¼šGit Blob APIï¼ˆä»…ç”¨äºå°æ–‡ä»¶ <1MBï¼‰ =====
                    if file_content is None and content.size < 1024 * 1024:  # 1MB
                        try:
                            print(f"[INFO]   â†’ æ–¹æ³•2: Git Blob API...")
                            blob = repo.get_git_blob(content.sha)
                            if blob.encoding == "base64":
                                file_content = base64.b64decode(blob.content)
                                download_method = "Git Blob"
                                print(f"[INFO]   âœ“ ä¸‹è½½å®Œæˆ: {len(file_content):,} bytes")
                        except Exception as e:
                            print(f"[WARN]   âœ— Git Blob å¤±è´¥: {e}")
                    
                    # ===== æ–¹æ³•3ï¼šDownload URLï¼ˆå…œåº•ï¼‰ =====
                    if file_content is None and content.download_url:
                        print(f"[INFO]   â†’ æ–¹æ³•3: Download URL...")
                        headers = {
                            "Authorization": f"Bearer {token}",
                            "Accept": "application/vnd.github.v3.raw"
                        }
                        file_content, success = download_with_retry(content.download_url, headers, max_retries=3)
                        if success:
                            download_method = "Download URL"
                            print(f"[INFO]   âœ“ ä¸‹è½½å®Œæˆ: {len(file_content):,} bytes")
                    
                    # ===== éªŒè¯æ–‡ä»¶å®Œæ•´æ€§ =====
                    if file_content:
                        actual_size = len(file_content)
                        expected_size = content.size
                        
                        print(f"[INFO]   â†’ éªŒè¯å®Œæ•´æ€§...")
                        print(f"[INFO]     æœŸæœ›: {expected_size:,} bytes")
                        print(f"[INFO]     å®é™…: {actual_size:,} bytes")
                        
                        if actual_size == expected_size:
                            files.append((content.name, file_content))
                            print(f"[INFO]   âœ… {content.name} å®Œæ•´æ€§éªŒè¯é€šè¿‡ (æ–¹æ³•: {download_method})")
                        else:
                            size_diff = abs(actual_size - expected_size)
                            print(f"[ERROR]  âŒ {content.name} å¤§å°ä¸åŒ¹é… (å·®å¼‚: {size_diff:,} bytes)")
                            print(f"[ERROR]     æ–‡ä»¶å¯èƒ½æŸåï¼Œè·³è¿‡...")
                    else:
                        print(f"[ERROR]  âŒ {content.name} æ‰€æœ‰ä¸‹è½½æ–¹æ³•å‡å¤±è´¥")
                            
            except GithubException as e:
                if e.status == 404:
                    print(f"[INFO] RAG æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {rag_folder}")
                    return []
                print(f"[ERROR] GitHub API å¼‚å¸¸: {e}")
                raise e
            
            print(f"\n[INFO] ========== RAG æ‹‰å–å®Œæˆ: {len(files)}/{len(file_list)} ä¸ªæ–‡ä»¶éªŒè¯é€šè¿‡ ==========\n")
            return files

        except Exception as e:
            print(f"[ERROR] æ‹‰å– RAG æ–‡ä»¶å¤¹å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

# --- [æ–°å¢] æ—¥å¿—ä¸è¯„æµ‹ç®¡ç†ç±» ---
class EvaluationLogger:
    FILE_NAME = "tea_data/eval_logs.json"

    @staticmethod
    def load_logs():
        """ä» GitHub åŒæ­¥å¹¶åŠ è½½æ—¥å¿—"""
        content = GithubSync.load_json(EvaluationLogger.FILE_NAME)
        return content if content else []

    @staticmethod
    def log_evaluation(text, model_output, expert_output, model_name="Qwen2.5-7B-Instruct"):
        """
        æ ¸å¿ƒï¼šåŒæ—¶è®°å½• AI çš„åŸå§‹è¾“å‡ºå’Œä¸“å®¶çš„æ ¡å‡†ç»“æœ
        """
        logs = EvaluationLogger.load_logs()
        new_entry = {
            "id": str(int(time.time())),
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "input_text": text,
            "model_prediction": model_output, # åŸå§‹é¢„æµ‹åŒ… (scores + master_comment)
            "expert_ground_truth": expert_output, # ä¸“å®¶ä¿®æ­£åŒ… (scores + master_comment)
            "analysis": None,
            "meta": {"model": model_name}
        }
        logs.insert(0, new_entry) # æœ€æ–°è®°å½•åœ¨å‰
        if len(logs) > 500: logs = logs[:500] # é™åˆ¶æ—¥å¿—é•¿åº¦
        GithubSync.push_json(EvaluationLogger.FILE_NAME, logs, f"Eval log {new_entry['id']}")
        return logs

    @staticmethod
    def run_judge(log_id, llm_client):
        """è¿è¡Œ LLM è£åˆ¤ï¼šåˆ†æ AI ä¸ºä»€ä¹ˆè¯„é”™äº†"""
        logs = EvaluationLogger.load_logs()
        target = next((l for l in logs if l["id"] == log_id), None)
        if not target or not target.get("expert_ground_truth"): return "ç¼ºå°‘å¯¹æ¯”æ•°æ®"

        judge_prompt = f"""
        ä½ æ˜¯ä¸€åèŒ¶å¶æ„Ÿå®˜å®¡è¯„ä¸“å®¶æ•™ç»ƒã€‚è¯·å¯¹æ¯”ä»¥ä¸‹â€œæ¨¡å‹è¯„åˆ†â€ä¸â€œä¸“å®¶æ ‡å‡†è¯„åˆ†â€ï¼Œåˆ†æå·®å¼‚åŸå› ã€‚
        ã€åŸå§‹è¯„è¯­ã€‘: {target['input_text']}
        ã€æ¨¡å‹åŸå§‹åˆ†ã€‘: {json.dumps(target['model_prediction'], ensure_ascii=False)}
        ã€ä¸“å®¶æ ¡å‡†åˆ†ã€‘: {json.dumps(target['expert_ground_truth'], ensure_ascii=False)}
        è¯·è¾“å‡ºç®€çŸ­çš„è¯¯å·®åˆ†æï¼š
        1. å“ªäº›ç»´åº¦åå·®è¾ƒå¤§ï¼Ÿ2. æ¨¡å‹è¯¯è§£äº†è¯„è¯­ä¸­çš„å“ªä¸ªå…³é”®æè¿°ï¼Ÿ3. é’ˆå¯¹æ­¤æ¡ˆä¾‹ï¼Œåº”å¦‚ä½•ä¼˜åŒ– Promptï¼Ÿ
        """
        try:
            resp = llm_client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": judge_prompt}]
            )
            analysis = resp.choices[0].message.content
            # æ›´æ–°æ—¥å¿—å¹¶åŒæ­¥
            for l in logs:
                if l["id"] == log_id: l["analysis"] = analysis
            GithubSync.push_json(EvaluationLogger.FILE_NAME, logs, f"Update judge {log_id}")
            return analysis
        except Exception as e:
            return f"è£åˆ¤åˆ†æå¤±è´¥: {str(e)}"
# ==========================================
# [SECTION 2] AI æœåŠ¡ (Embedding & LLM)
# ==========================================

class AliyunEmbedder:
    def __init__(self, api_key):
        self.model_name = "text-embedding-v3"
        dashscope.api_key = api_key # ç¡®ä¿ API KEY è¢«æ­£ç¡®è®¾ç½®ç»™å…¨å±€
        
    def encode(self, texts: List[str]) -> np.ndarray:
        if not texts:
            return np.zeros((0, 1024), dtype="float32")
        if isinstance(texts, str):
            texts = [texts]
    
        try:
            resp = TextEmbedding.call(model=self.model_name, input=texts)
        except Exception as e:
            # å…³é”®ï¼šä¸è¦åæ‰ï¼Œå¦åˆ™æ£€ç´¢ä¼šâ€œæ°¸è¿œä¸å˜â€
            raise RuntimeError(f"[Embedding] call failed: {type(e).__name__}: {e}")
    
        if resp.status_code != HTTPStatus.OK:
            # æŠŠé”™è¯¯ä¿¡æ¯æš´éœ²å‡ºæ¥
            msg = getattr(resp, "message", "")
            raise RuntimeError(f"[Embedding] HTTP not OK: {resp.status_code}, message={msg}")
    
        vecs = np.array([i["embedding"] for i in resp.output["embeddings"]], dtype="float32")
    
        # å…³é”®ï¼šæ£€æµ‹å…¨ 0 / å¸¸é‡å‘é‡ï¼ˆå…¸å‹â€œæ£€ç´¢æ°¸è¿œä¸€æ ·â€ï¼‰
        norms = np.linalg.norm(vecs, axis=1)
        if np.any(norms < 1e-6):
            raise RuntimeError("[Embedding] got near-zero vector(s). Check ALIYUN_API_KEY / dashscope / model availability.")
    
        return vecs


def _ensure_ip_index_from_texts(texts, embedder):
    """Build an IndexFlatIP (cosine via L2-normalized vectors) from texts."""
    if not texts:
        return faiss.IndexFlatIP(1024)
    vecs = embedder.encode(texts).astype("float32")
    # normalize for cosine similarity
    faiss.normalize_L2(vecs)
    dim = vecs.shape[1] if vecs.ndim == 2 and vecs.shape[0] > 0 else 1024
    idx = faiss.IndexFlatIP(dim)
    if vecs.shape[0] > 0:
        idx.add(vecs)
    return idx

def ensure_case_index_cosine(embedder):
    """Migrate / rebuild case index to cosine (IP + normalized vectors) if needed."""
    case_idx, case_data = st.session_state.get("cases", (faiss.IndexFlatIP(1024), []))
    # If empty, nothing to do
    if not case_data:
        st.session_state.cases = (faiss.IndexFlatIP(1024), case_data)
        return

    # If metric not IP or ntotal mismatch, rebuild
    metric = getattr(case_idx, "metric_type", None)
    if metric != faiss.METRIC_INNER_PRODUCT or case_idx.ntotal != len(case_data):
        texts = [c.get("text", "") for c in case_data]
        new_idx = _ensure_ip_index_from_texts(texts, embedder)
        st.session_state.cases = (new_idx, case_data)
        ResourceManager.save(new_idx, case_data, PATHS.case_index, PATHS.case_data, is_json=True)

def ensure_kb_index_cosine(embedder):
    """Migrate / rebuild kb index to cosine (IP + normalized vectors) if needed."""
    kb_idx, kb_chunks = st.session_state.get("kb", (faiss.IndexFlatIP(1024), []))
    if not kb_chunks:
        st.session_state.kb = (faiss.IndexFlatIP(1024), kb_chunks)
        return

    metric = getattr(kb_idx, "metric_type", None)
    if metric != faiss.METRIC_INNER_PRODUCT or kb_idx.ntotal != len(kb_chunks):
        new_idx = _ensure_ip_index_from_texts(kb_chunks, embedder)
        st.session_state.kb = (new_idx, kb_chunks)
        ResourceManager.save(new_idx, kb_chunks, PATHS.kb_index, PATHS.kb_chunks)


def llm_normalize_user_input(raw_query: str, client: OpenAI) -> str:
    """ä½¿ç”¨ LLM å¯¹ç”¨æˆ·è¾“å…¥åšè¯­ä¹‰è§„èŒƒåŒ– / å»å™ª"""
    system_prompt = (
        """
          A. è§’è‰²ä¸ç›®æ ‡
          ä½ æ˜¯"èŒ¶è¯„æ¸…æ´—å™¨"ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä»è¾“å…¥æ–‡æœ¬ä¸­æå–å¹¶è¾“å‡ºåªä¸èŒ¶è¯„ç›¸å…³çš„ä¿¡æ¯ï¼Œåˆ é™¤æ— å…³å†…å®¹ï¼Œä¿æŒåŸæ„ä¸åŸæœ‰è¡¨è¿°é£æ ¼ï¼Œåªèƒ½åˆ å‡ä¸èƒ½ä¿®æ”¹ã€‚
          B. ä»€ä¹ˆç®—"ç›¸å…³ä¿¡æ¯"ï¼ˆä¿ç•™ï¼‰
          ä»…ä¿ç•™ä¸ä»¥ä¸‹å†…å®¹æœ‰å…³çš„å¥å­/çŸ­è¯­ï¼š
          èŒ¶çš„åŸºæœ¬ä¿¡æ¯ï¼šèŒ¶å/å“ç±»ã€äº§åœ°ã€å¹´ä»½ã€å·¥è‰ºã€ç­‰çº§ã€åŸæ–™ã€é¦™å‹ç­‰
          å¹²èŒ¶/èŒ¶æ±¤/å¶åº•ï¼šå¤–è§‚ã€è‰²æ³½ã€æ¡ç´¢ã€æ±¤è‰²ã€å¶åº•æè¿°
          é¦™æ°”ä¸æ»‹å‘³ï¼šé¦™æ°”ç±»å‹ã€å¼ºå¼±ã€å±‚æ¬¡ã€å›ç”˜ã€ç”Ÿæ´¥ã€æ¶©æ„Ÿã€è‹¦æ„Ÿã€ç”œåº¦ã€é†‡åšåº¦ã€å–‰éŸµã€ä½“æ„Ÿç­‰
          å†²æ³¡ä¿¡æ¯ä¸è¡¨ç°ï¼šå™¨å…·ã€æŠ•èŒ¶é‡ã€æ°´æ¸©ã€æ—¶é—´ã€å‡ºæ±¤ã€å‡ æ³¡å˜åŒ–ã€è€æ³¡åº¦ã€é€‚é¥®å»ºè®®
          ä¸»è§‚è¯„ä»·ä¸ç»“è®ºï¼šå¥½å–/ä¸€èˆ¬/ç¼ºç‚¹/æ€§ä»·æ¯”
          C. ä»€ä¹ˆç®—"æ— å…³ä¿¡æ¯"ï¼ˆåˆ é™¤ï¼‰
          åˆ é™¤ä¸èŒ¶è¯„æ— ç›´æ¥å…³ç³»çš„å†…å®¹ï¼Œä¾‹å¦‚ï¼š
          ä¸èŒ¶æ— å…³çš„ç”Ÿæ´»æ—¥å¸¸ã€æƒ…ç»ªå®£æ³„ã€ç¤¾äº¤èŠå¤©ã€æ®µå­
          åº—é“º/ç‰©æµ/å®¢æœ/åŒ…è£…ç ´æŸ/å‘è´§æ…¢ï¼ˆé™¤é"åŒ…è£…å¼‚å‘³å½±å“èŒ¶"è¿™ç±»ç›´æ¥å½±å“å“é¥®ï¼‰
          å¹¿å‘Šã€ä»·æ ¼é“¾æ¥ã€ä¼˜æƒ åˆ¸ã€å¼•æµè¯æœ¯ã€å“ç‰Œå¹æ°´ï¼ˆé™¤éæ˜¯"æ€§ä»·æ¯”"ä¸”ä¸å“é¥®ç»“è®ºç›¸å…³ï¼‰
          ä¸å…¶å®ƒäº§å“/è¯é¢˜æ— å…³çš„å¯¹æ¯”é—²èŠ
          å‡‘å­—æ•°å†…å®¹
          D. è¾“å‡ºæ ¼å¼
          åªè¾“å‡ºæ¸…æ´—åçš„èŒ¶è¯„æ­£æ–‡ï¼Œä¸è¦è§£é‡Šã€ä¸åŠ æ ‡é¢˜ã€ä¸è¾“å‡º"åˆ é™¤äº†ä»€ä¹ˆ"
          å¦‚æœè¾“å…¥ä¸­æ²¡æœ‰ä»»ä½•èŒ¶è¯„ç›¸å…³ä¿¡æ¯ï¼Œåˆ™è¾“å‡ºï¼š"æ— ç›¸å…³èŒ¶è¯„ä¿¡æ¯"
          E. æ“ä½œåŸåˆ™
          å°½é‡ä¿ç•™åŸå¥ï¼›åªåšåˆ é™¤/å°‘é‡æ‹¼æ¥
          ä¸è¦è¡¥å……ä¸å­˜åœ¨çš„ç»†èŠ‚ï¼Œä¸è¦æ¨æµ‹        
          """
    )

    resp = client.chat.completions.create(
        model="deepseek-chat",
        temperature=0,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": raw_query}
        ]
    )
    return resp.choices[0].message.content.strip()

def run_scoring(text: str, kb_res: Tuple, case_res: Tuple, prompt_cfg: Dict, embedder: AliyunEmbedder, client: OpenAI, model_id: str, k_num: int, c_num: int):
    """æ‰§è¡Œ RAG æ£€ç´¢ä¸ LLM è¯„åˆ†"""
    vec = embedder.encode([text]).astype("float32")
    faiss.normalize_L2(vec)
    # Debugï¼šnorm åº”è¯¥çº¦ç­‰äº 1.0ï¼›å¦‚æœä¸æ˜¯ï¼Œembedding æˆ– normalize æœ‰é—®é¢˜
    print(f"[DEBUG] query_vec_norm={float(np.linalg.norm(vec[0])):.6f}")

    # --- KB ---
    ctx_txt, hits = "ï¼ˆæ— æ‰‹å†Œèµ„æ–™ï¼‰", []
    if kb_res[0].ntotal > 0:
        _, idx = kb_res[0].search(vec, k_num)
        hits = [kb_res[1][i] for i in idx[0] if i < len(kb_res[1])]
        ctx_txt = "\n".join([f"- {h[:200]}..." for h in hits])

    # --- CASES ---
    case_txt, found_cases = "", []
    if case_res[0].ntotal > 0:
        _, idx = case_res[0].search(vec, c_num)
        for i in idx[0]:
            if 0 <= i < len(case_res[1]):
                c = case_res[1][i]
                found_cases.append(c)

                score_details = []
                for factor, info in c.get("scores", {}).items():
                    if isinstance(info, dict):
                        score_details.append(
                            f"{factor}: {info.get('score')}åˆ† (ç†ç”±: {info.get('comment', 'æ— ')})"
                        )
                scores_str = " | ".join(score_details)

                case_txt += (
                    f"\n---\n"
                    f"ã€ç›¸ä¼¼åˆ¤ä¾‹ã€‘: {c.get('text','')}\n"
                    f"ã€è¯¥åˆ¤ä¾‹ä¸“å®¶åˆ†ã€‘{scores_str}\n"
                    f"ã€ç¡¬çº¦æŸã€‘å¦‚æœå¾…è¯„åˆ†æ–‡æœ¬ä¸è¯¥åˆ¤ä¾‹é«˜åº¦ä¸€è‡´ï¼ˆè¯­ä¹‰åŸºæœ¬ç›¸åŒï¼‰ï¼Œå…­å› å­åˆ†æ•°åº”ä¼˜å…ˆå¯¹é½è¯¥åˆ¤ä¾‹çš„ä¸“å®¶åˆ†ï¼›åªæœ‰æ˜ç¡®å‡ºç°ç›¸åæè¿°æ—¶æ‰å…è®¸åç¦»ï¼Œå¹¶å¿…é¡»åœ¨commenté‡Œè§£é‡Šåç¦»åŸå› ã€‚\n"
                )

    if not found_cases:
        case_txt = "ï¼ˆæ— ç›¸ä¼¼åˆ¤ä¾‹ï¼‰"

    sys_p = prompt_cfg.get('system_template', "")
    user_p = prompt_cfg.get('user_template', "").format(product_desc=text, context_text=ctx_txt, case_text=case_txt)

    try:
        resp = client.chat.completions.create(
            model=model_id,
            messages=[{"role":"system", "content":sys_p}, {"role":"user", "content":user_p}],
            response_format={"type": "json_object"},
            temperature=0.3
        )
        return json.loads(resp.choices[0].message.content), hits, found_cases
    except Exception as e:
        st.error(f"Inference Error: {e}")
        return None, [], []

# ==========================================
# [SECTION 3] è¾…åŠ©ä¸å¯è§†åŒ–
# ==========================================

def parse_file(uploaded_file) -> str:
    """è§£æä¸Šä¼ æ–‡ä»¶"""
    try:
        if uploaded_file.name.endswith('.txt'): return uploaded_file.read().decode("utf-8")
        if uploaded_file.name.endswith('.pdf'): return "".join([p.extract_text() for p in PdfReader(uploaded_file).pages])
        if uploaded_file.name.endswith('.docx'): return "\n".join([p.text for p in Document(uploaded_file).paragraphs])
    except: return ""
    return ""

def parse_file_bytes(filename: str, content: bytes) -> str:
    """
    è§£ææ–‡ä»¶å†…å®¹ (ä» bytes) - ç”¨äºä» GitHub æ‹‰å–çš„æ–‡ä»¶
    æ”¯æŒæ ¼å¼: .txt, .pdf, .docx
    """
    try:
        # 1. å¤„ç† TXT æ–‡ä»¶
        if filename.lower().endswith('.txt'):
            text = content.decode('utf-8', errors='ignore')
            print(f"[INFO]     â†’ TXT è§£ææˆåŠŸ: {len(text)} å­—ç¬¦")
            return text
        
        # 2. å¤„ç† PDF æ–‡ä»¶
        elif filename.lower().endswith('.pdf'):
            try:
                print(f"[INFO]     â†’ å¼€å§‹è§£æ PDF...")
                print(f"[INFO]     â†’ æ–‡ä»¶å¤§å°: {len(content):,} bytes")
                
                # éªŒè¯ PDF æ–‡ä»¶å¤´
                if not content.startswith(b'%PDF'):
                    print(f"[ERROR]    â†’ ä¸æ˜¯æœ‰æ•ˆçš„ PDF æ–‡ä»¶ï¼ˆæ–‡ä»¶å¤´é”™è¯¯ï¼‰")
                    print(f"[ERROR]    â†’ å‰20å­—èŠ‚: {content[:20]}")
                    return ""
                
                # éªŒè¯ PDF æ–‡ä»¶å°¾
                if b'%%EOF' not in content[-1024:]:
                    print(f"[WARN]     â†’ PDF æ–‡ä»¶å°¾æ ‡è®°ç¼ºå¤±ï¼Œæ–‡ä»¶å¯èƒ½ä¸å®Œæ•´")
                    print(f"[WARN]     â†’ å50å­—èŠ‚: {content[-50:]}")
                
                # å°è¯•è§£æ PDF
                reader = PdfReader(BytesIO(content))
                page_count = len(reader.pages)
                print(f"[INFO]     â†’ PDF å…± {page_count} é¡µ")
                
                text = ""
                failed_pages = []
                
                for idx, page in enumerate(reader.pages, 1):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            text += page_text + "\n"
                            if idx % 10 == 0:  # æ¯ 10 é¡µè¾“å‡ºä¸€æ¬¡è¿›åº¦
                                print(f"[INFO]     â†’ å·²å¤„ç† {idx}/{page_count} é¡µ")
                    except Exception as e:
                        failed_pages.append(idx)
                        print(f"[WARN]     â†’ ç¬¬ {idx} é¡µè§£æå¤±è´¥: {e}")
                        continue
                
                if failed_pages:
                    print(f"[WARN]     â†’ å…± {len(failed_pages)} é¡µè§£æå¤±è´¥: {failed_pages[:10]}{'...' if len(failed_pages) > 10 else ''}")
                
                if text.strip():
                    print(f"[INFO]     â†’ PDF è§£æå®Œæˆ: {len(text):,} å­—ç¬¦ (æˆåŠŸç‡: {(page_count-len(failed_pages))/page_count*100:.1f}%)")
                    return text
                else:
                    print(f"[WARN]     â†’ PDF è§£æç»“æœä¸ºç©º")
                    return ""
                    
            except Exception as e:
                print(f"[ERROR]    âœ— PDF è§£æå¤±è´¥: {type(e).__name__}: {e}")
                
                # å¦‚æœæ˜¯ EOF é”™è¯¯ï¼Œæä¾›æ›´å¤šè¯Šæ–­ä¿¡æ¯
                if "EOF" in str(e) or "PdfReadError" in str(type(e).__name__):
                    print(f"[ERROR]    â†’ è¿™é€šå¸¸æ„å‘³ç€ PDF æ–‡ä»¶ä¸‹è½½ä¸å®Œæ•´æˆ–æŸå")
                    print(f"[ERROR]    â†’ æ–‡ä»¶å¤§å°: {len(content):,} bytes")
                    print(f"[ERROR]    â†’ æ–‡ä»¶å¤´: {content[:20]}")
                    print(f"[ERROR]    â†’ æ–‡ä»¶å°¾: {content[-50:] if len(content) > 50 else content}")
                
                import traceback
                traceback.print_exc()
                return ""
        
        # 3. å¤„ç† DOCX æ–‡ä»¶
        elif filename.lower().endswith('.docx'):
            doc = Document(BytesIO(content))
            text = "\n".join([p.text for p in doc.paragraphs if p.text.strip()])
            print(f"[INFO]     â†’ DOCX è§£ææˆåŠŸ: {len(text)} å­—ç¬¦")
            return text
        
        else:
            print(f"[WARN]     â†’ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {filename}")
            return ""
            
    except Exception as e:
        print(f"[ERROR]    âœ— è§£æ {filename} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return ""

def create_word_report(results: List[Dict]) -> BytesIO:
    """ç”ŸæˆWordæŠ¥å‘Š"""
    doc = Document()
    doc.add_heading("èŒ¶è¯„æ‰¹é‡è¯„åˆ†æŠ¥å‘Š", 0)
    for item in results:
        doc.add_heading(f"æ¡ç›® {item['id']}", 1)
        doc.add_paragraph(f"åŸæ–‡ï¼š{item['text']}")
        s = item.get('scores', {}).get('scores', {})
        mc = item.get('scores', {}).get('master_comment', '')
        if mc: doc.add_paragraph(f"æ€»è¯„ï¼š{mc}", style="Intense Quote")
        
        table = doc.add_table(rows=1, cols=4)
        table.style = 'Table Grid'
        hdr = table.rows[0].cells
        hdr[0].text, hdr[1].text, hdr[2].text, hdr[3].text = 'å› å­', 'åˆ†æ•°', 'è¯„è¯­', 'å»ºè®®'
        for k, v in s.items():
            r = table.add_row().cells
            r[0].text = k
            r[1].text = str(v.get('score',''))
            r[2].text = v.get('comment','')
            r[3].text = v.get('suggestion','')
        doc.add_paragraph("_"*20)
    bio = BytesIO()
    doc.save(bio)
    bio.seek(0)
    return bio

def plot_flavor_shape(scores_data: Dict):
    """ç»˜åˆ¶é£å‘³å½¢æ€å›¾"""
    s = scores_data["scores"]
    top = (s["ä¼˜é›…æ€§"]["score"] + s["è¾¨è¯†åº¦"]["score"]) / 2
    mid = (s["åè°ƒæ€§"]["score"] + s["é¥±å’Œåº¦"]["score"]) / 2
    base = (s["æŒä¹…æ€§"]["score"] + s["è‹¦æ¶©åº¦"]["score"]) / 2
    
    fig, ax = plt.subplots(figsize=(4, 5))
    fig.patch.set_alpha(0); ax.patch.set_alpha(0)

    y = np.array([1, 2, 3]) 
    x = np.array([base, mid, top])
    y_new = np.linspace(1, 3, 300)
    try:
        spl = make_interp_spline(y, x, k=2)
        x_smooth = spl(y_new)
    except:
        x_smooth = np.interp(y_new, y, x)
    x_smooth = np.maximum(x_smooth, 0.1)

    colors = {'base': '#8B4513', 'mid': '#D2691E', 'top': '#FFD700'}
    for mask, col in [((y_new>=1.0)&(y_new<=1.6), colors['base']), 
                      ((y_new>1.6)&(y_new<=2.4), colors['mid']), 
                      ((y_new>2.4)&(y_new<=3.0), colors['top'])]:
        ax.fill_betweenx(y_new[mask], -x_smooth[mask], x_smooth[mask], color=col, alpha=0.9, edgecolor=None)

    ax.plot(x_smooth, y_new, 'k', linewidth=1, alpha=0.2)
    ax.plot(-x_smooth, y_new, 'k', linewidth=1, alpha=0.2)
    ax.axhline(y=1.6, color='w', linestyle=':', alpha=0.5)
    ax.axhline(y=2.4, color='w', linestyle=':', alpha=0.5)
    
    font = {'ha': 'center', 'va': 'center', 'color': 'white', 'fontweight': 'bold', 'fontsize': 12}
    ax.text(0, 2.7, f"Top\n{top:.1f}", **font)
    ax.text(0, 2.0, f"Mid\n{mid:.1f}", **font)
    ax.text(0, 1.3, f"Base\n{base:.1f}", **font)
    ax.axis('off'); ax.set_xlim(-10, 10); ax.set_ylim(0.8, 3.2)
    return fig

def bootstrap_seed_cases(embedder: AliyunEmbedder):
    """åˆå§‹åŒ–åˆ¤ä¾‹åº“ï¼šå¦‚æœå†…å­˜/ç£ç›˜ä¸­ä¸ºç©ºï¼Œåˆ™ä» case.json æ–‡ä»¶è¯»å–"""
    case_idx, case_data = st.session_state.cases
    if len(case_data) > 0: return

    # ä»å¤–éƒ¨ JSON åŠ è½½ (ä¿®æ”¹è·¯å¾„)
    seed_cases = ResourceManager.load_external_json(PATHS.SRC_CASES)
    if not seed_cases:
        # å…¼å®¹æ—§è·¯å¾„
        old_path = Path("seed_case.json")
        seed_cases = ResourceManager.load_external_json(old_path)
    
    if not seed_cases:
        st.warning("case.json æœªæ‰¾åˆ°æˆ–ä¸ºç©ºï¼Œåˆ¤ä¾‹åº“åˆå§‹åŒ–è·³è¿‡ã€‚")
        return

    texts = [c["text"] for c in seed_cases]
    vecs = embedder.encode(texts)
    faiss.normalize_L2(vecs)

    if case_idx.ntotal == 0: case_idx = faiss.IndexFlatIP(1024)
    if len(vecs) > 0:
        case_idx.add(vecs)
        case_data.extend(seed_cases)
        st.session_state.cases = (case_idx, case_data)
        ResourceManager.save(case_idx, case_data, PATHS.case_index, PATHS.case_data, is_json=True)

def load_rag_from_github(aliyun_key: str) -> Tuple[bool, str]:
    """
    ä» GitHub åŠ è½½ RAG æ–‡ä»¶
    è¿”å›: (æ˜¯å¦æˆåŠŸ, æ¶ˆæ¯)
    """
    print("\n[INFO] ========== å¼€å§‹ä» GitHub åŠ è½½ RAG æ•°æ® ==========")
    
    try:
        # 1. æ‹‰å–æ–‡ä»¶
        print("[INFO] æ­¥éª¤ 1/4: ä» GitHub æ‹‰å– RAG æ–‡ä»¶...")
        rag_files = GithubSync.pull_rag_folder("tea_data/RAG")
        
        if not rag_files:
            msg = "GitHub ä¸Šæ²¡æœ‰æ‰¾åˆ° RAG æ–‡ä»¶ï¼Œæˆ–æ‰€æœ‰æ–‡ä»¶ä¸‹è½½å¤±è´¥"
            print(f"[WARN] {msg}")
            return False, msg
        
        print(f"[INFO] æˆåŠŸæ‹‰å–å¹¶éªŒè¯ {len(rag_files)} ä¸ªæ–‡ä»¶")
        
        # 2. è§£ææ–‡ä»¶å†…å®¹
        print("[INFO] æ­¥éª¤ 2/4: è§£ææ–‡ä»¶å†…å®¹...")
        all_text = ""
        file_names = []
        parse_success = 0
        parse_failed = []
        
        for fname, fcontent in rag_files:
            file_names.append(fname)
            print(f"\n[INFO]   â†’ è§£æ {fname} ({len(fcontent):,} bytes)...")
            
            parsed_text = parse_file_bytes(fname, fcontent)
            if parsed_text and len(parsed_text.strip()) > 100:  # è‡³å°‘è¦æœ‰100ä¸ªå­—ç¬¦
                all_text += parsed_text + "\n"
                parse_success += 1
                print(f"[INFO]   âœ… æˆåŠŸæå– {len(parsed_text):,} å­—ç¬¦")
            else:
                parse_failed.append(fname)
                print(f"[WARN]   âŒ æå–å¤±è´¥æˆ–æ–‡æœ¬è¿‡çŸ­ ({len(parsed_text) if parsed_text else 0} å­—ç¬¦)")
        
        print(f"\n[INFO] æ–‡ä»¶è§£æå®Œæˆ: {parse_success}/{len(rag_files)} æˆåŠŸ")
        if parse_failed:
            print(f"[WARN] è§£æå¤±è´¥çš„æ–‡ä»¶: {', '.join(parse_failed)}")
        
        if not all_text.strip():
            msg = f"æ— æ³•ä» RAG æ–‡ä»¶ä¸­æå–æœ‰æ•ˆæ–‡æœ¬ï¼ˆå…±å°è¯• {len(rag_files)} ä¸ªæ–‡ä»¶ï¼‰"
            print(f"[ERROR] {msg}")
            return False, msg
        
        # 3. åˆ‡ç‰‡
        print(f"\n[INFO] æ­¥éª¤ 3/4: å°†æ–‡æœ¬åˆ‡ç‰‡...")
        print(f"[INFO]   â†’ æ€»æ–‡æœ¬é•¿åº¦: {len(all_text):,} å­—ç¬¦")
        chunks = [all_text[i:i+600] for i in range(0, len(all_text), 500)]
        print(f"[INFO]   âœ“ åˆ‡ç‰‡å®Œæˆ: {len(chunks)} ä¸ªç‰‡æ®µ")
        
        if not chunks:
            msg = "åˆ‡ç‰‡å¤±è´¥"
            print(f"[ERROR] {msg}")
            return False, msg
        
        # 4. å‘é‡åŒ–å¹¶æ„å»ºç´¢å¼•
        print("\n[INFO] æ­¥éª¤ 4/4: å‘é‡åŒ–å¹¶æ„å»º FAISS ç´¢å¼•...")
        temp_embedder = AliyunEmbedder(aliyun_key)
        kb_idx = faiss.IndexFlatIP(1024)
        
        print(f"[INFO]   â†’ è°ƒç”¨é˜¿é‡Œäº‘ Embedding API (æ‰¹æ¬¡å¤§å°: 25)...")
        
        # åˆ†æ‰¹å‘é‡åŒ–ï¼Œé¿å… API é™åˆ¶
        batch_size = 25
        all_vecs = []
        for i in range(0, len(chunks), batch_size):
            batch = chunks[i:i+batch_size]
            try:
                vecs = temp_embedder.encode(batch)
                all_vecs.append(vecs)
                print(f"[INFO]   â†’ å·²å¤„ç† {min(i+batch_size, len(chunks))}/{len(chunks)} ç‰‡æ®µ")
            except Exception as e:
                print(f"[WARN]   â†’ æ‰¹æ¬¡ {i}-{i+batch_size} å‘é‡åŒ–å¤±è´¥: {e}")
        
        if not all_vecs:
            msg = "å‘é‡åŒ–å¤±è´¥"
            print(f"[ERROR] {msg}")
            return False, msg
        
        vecs = np.vstack(all_vecs)
        print(f"[INFO]   âœ“ è·å¾—å‘é‡: {vecs.shape}")
        faiss.normalize_L2(vecs)
        
        kb_idx.add(vecs)
        print(f"[INFO]   âœ“ FAISS ç´¢å¼•æ„å»ºå®Œæˆ (å…± {kb_idx.ntotal} æ¡)")
        
        # 5. ä¿å­˜åˆ° session_state å’Œç£ç›˜
        st.session_state.kb = (kb_idx, chunks)
        st.session_state.kb_files = file_names
        
        ResourceManager.save(kb_idx, chunks, PATHS.kb_index, PATHS.kb_chunks)
        ResourceManager.save_kb_files(file_names)
        
        success_files = [f for f in file_names if f not in parse_failed]
        msg = f"âœ… æˆåŠŸåŠ è½½ {len(chunks)} æ¡çŸ¥è¯†ç‰‡æ®µ\nğŸ“ æ¥æºæ–‡ä»¶: {', '.join(success_files)}"
        if parse_failed:
            msg += f"\nâš ï¸  è§£æå¤±è´¥: {', '.join(parse_failed)}"
        
        print(f"[INFO] {msg}")
        print("[INFO] ========== RAG åŠ è½½å®Œæˆ ==========\n")
        return True, msg
        
    except Exception as e:
        msg = f"åŠ è½½å¤±è´¥: {str(e)}"
        print(f"[ERROR] âŒ {msg}")
        import traceback
        traceback.print_exc()
        print("[INFO] ========== RAG åŠ è½½å¤±è´¥ ==========\n")
        return False, msg


# ==========================================
# [SECTION 3.5] åˆ¤ä¾‹ç®¡ç†å¼¹çª—
# ==========================================

@st.dialog("ğŸ“‹ åˆ¤ä¾‹åº“ç®¡ç†", width="large")
def show_cases_dialog(embedder: AliyunEmbedder):
    """å±•ç¤ºå¹¶ç®¡ç†æ‰€æœ‰åˆ¤ä¾‹çš„å¼¹çª—"""
    cases = st.session_state.cases[1]
    
    if not cases:
        st.info("å½“å‰åˆ¤ä¾‹åº“ä¸ºç©º")
        return
    
    st.write(f"å…± **{len(cases)}** æ¡åˆ¤ä¾‹")
    st.caption("ğŸ’¡ å‹¾é€‰è¦åˆ é™¤çš„åˆ¤ä¾‹ï¼Œç„¶åç‚¹å‡»åº•éƒ¨çš„ç¡®è®¤æŒ‰é’®")
    
    # ç”¨äºè¿½è¸ªç¼–è¾‘çŠ¶æ€
    if 'editing_case_idx' not in st.session_state:
        st.session_state.editing_case_idx = None
    
    # ä½¿ç”¨checkboxæ”¶é›†è¦åˆ é™¤çš„åˆ¤ä¾‹ï¼ˆä¸ä¼šè§¦å‘rerunå¯¼è‡´å¼¹çª—å…³é—­ï¼‰
    selected_to_delete = []
    
    for idx, case in enumerate(cases):
        with st.container(border=True):
            col1, col2, col3 = st.columns([6, 1, 1])
            
            with col1:
                # æ˜¾ç¤ºåˆ¤ä¾‹æ‘˜è¦
                text_preview = case.get('text', '')[:100] + ('...' if len(case.get('text', '')) > 100 else '')
                st.markdown(f"**#{idx+1}** {text_preview}")
                
                # æ˜¾ç¤ºåˆ†æ•°æ‘˜è¦
                scores = case.get('scores', {})
                if scores:
                    score_str = " | ".join([f"{k}:{v.get('score', '?')}" for k, v in scores.items()])
                    st.caption(score_str)
            
            with col2:
                if st.button("âœï¸", key=f"edit_{idx}", help="ç¼–è¾‘æ­¤åˆ¤ä¾‹"):
                    st.session_state.editing_case_idx = idx
                    st.rerun()
            
            with col3:
                # ä½¿ç”¨checkboxä»£æ›¿buttonï¼Œé¿å…rerunå¯¼è‡´å¼¹çª—å…³é—­
                if st.checkbox("åˆ é™¤", key=f"del_check_{idx}", label_visibility="collapsed"):
                    selected_to_delete.append(idx)
    
    # å¦‚æœæœ‰é€‰ä¸­è¦åˆ é™¤çš„åˆ¤ä¾‹
    if selected_to_delete:
        st.warning(f"âš ï¸ å·²é€‰ä¸­ {len(selected_to_delete)} æ¡åˆ¤ä¾‹å¾…åˆ é™¤")
        if st.button("âœ… ç¡®è®¤åˆ é™¤å¹¶åŒæ­¥", type="primary", use_container_width=True):
            # æ‰§è¡Œåˆ é™¤
            new_cases = [c for i, c in enumerate(cases) if i not in selected_to_delete]
            
            # é‡å»ºFAISSç´¢å¼•
            new_idx = faiss.IndexFlatIP(1024)
            if new_cases:
                texts = [c["text"] for c in new_cases]
                vecs = embedder.encode(texts)
                faiss.normalize_L2(vecs)
                new_idx.add(vecs)
            
            st.session_state.cases = (new_idx, new_cases)
            ResourceManager.save(new_idx, new_cases, PATHS.case_index, PATHS.case_data, is_json=True)
            
            # åŒæ­¥åˆ°GitHub
            with st.spinner("åŒæ­¥åˆ°GitHub..."):
                GithubSync.sync_cases(new_cases)
            
            st.success("åˆ é™¤å®Œæˆï¼")
            time.sleep(1)
            st.rerun()


@st.dialog("âœï¸ ç¼–è¾‘åˆ¤ä¾‹", width="large")
def edit_case_dialog(case_idx: int, embedder: AliyunEmbedder):
    """ç¼–è¾‘å•ä¸ªåˆ¤ä¾‹çš„å¼¹çª—"""
    cases = st.session_state.cases[1]
    if case_idx >= len(cases):
        st.error("åˆ¤ä¾‹ä¸å­˜åœ¨")
        return
    
    case = cases[case_idx]
    factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
    
    st.subheader(f"ç¼–è¾‘åˆ¤ä¾‹ #{case_idx + 1}")
    
    # ç¼–è¾‘æ–‡æœ¬
    new_text = st.text_area("åˆ¤ä¾‹æè¿°", case.get("text", ""), height=100)
    new_master = st.text_area("æ€»è¯„", case.get("master_comment", ""), height=60)
    new_tags = st.text_input("æ ‡ç­¾", case.get("tags", ""))
    
    # ç¼–è¾‘å„å› å­åˆ†æ•°
    st.markdown("**å› å­è¯„åˆ†**")
    new_scores = {}
    cols = st.columns(3)
    
    old_scores = case.get("scores", {})
    for i, f in enumerate(factors):
        with cols[i % 3]:
            with st.container(border=True):
                st.markdown(f"**{f}**")
                old_f = old_scores.get(f, {})
                new_scores[f] = {
                    "score": st.number_input(f"åˆ†æ•°", 0, 9, int(old_f.get("score", 5)), key=f"edit_s_{f}"),
                    "comment": st.text_input(f"è¯„è¯­", old_f.get("comment", ""), key=f"edit_c_{f}"),
                    "suggestion": st.text_input(f"å»ºè®®", old_f.get("suggestion", ""), key=f"edit_sg_{f}")
                }
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ’¾ ä¿å­˜ä¿®æ”¹å¹¶åŒæ­¥", type="primary"):
            # æ›´æ–°åˆ¤ä¾‹
            cases[case_idx] = {
                "text": new_text,
                "scores": new_scores,
                "tags": new_tags,
                "master_comment": new_master,
                "created_at": case.get("created_at", time.strftime("%Y-%m-%d"))
            }
            
            # é‡å»ºFAISSç´¢å¼•ï¼ˆå› ä¸ºæ–‡æœ¬å¯èƒ½å˜äº†ï¼‰
            new_idx = faiss.IndexFlatIP(1024)
            texts = [c["text"] for c in cases]
            vecs = embedder.encode(texts)
            faiss.normalize_L2(vecs)
            new_idx.add(vecs)
            
            st.session_state.cases = (new_idx, cases)
            ResourceManager.save(new_idx, cases, PATHS.case_index, PATHS.case_data, is_json=True)
            
            # åŒæ­¥åˆ°GitHub
            with st.spinner("åŒæ­¥åˆ°GitHub..."):
                GithubSync.sync_cases(cases)
            
            st.session_state.editing_case_idx = None
            st.success("ä¿å­˜æˆåŠŸï¼")
            time.sleep(1)
            st.rerun()
    
    with col2:
        if st.button("âŒ å–æ¶ˆ"):
            st.session_state.editing_case_idx = None
            st.rerun()


# ==========================================
# [SECTION 4] ä¸»ç¨‹åºé€»è¾‘
# ==========================================
# A. åˆå§‹åŒ– Session
if 'loaded' not in st.session_state:
    print("\n" + "="*70)
    print("[INFO] ========== èŒ¶é¥®å…­å› å­AIè¯„åˆ†å™¨ - ç³»ç»Ÿåˆå§‹åŒ– ==========")
    print("="*70)
    
    # 1. åŠ è½½æœ¬åœ°ç¼“å­˜çš„ RAG ä¸åˆ¤ä¾‹æ•°æ®
    print("[INFO] æ­¥éª¤ 1/3: åŠ è½½æœ¬åœ°ç¼“å­˜æ•°æ®...")
    kb_idx, kb_data = ResourceManager.load(PATHS.kb_index, PATHS.kb_chunks)
    case_idx, case_data = ResourceManager.load(PATHS.case_index, PATHS.case_data, is_json=True)
    # (removed) case self-heal moved to cosine-migration helper after embedder init

    st.session_state.kb = (kb_idx, kb_data)
    st.session_state.cases = (case_idx, case_data)
    st.session_state.kb_files = ResourceManager.load_kb_files()
    
    print(f"[INFO]   â†’ çŸ¥è¯†åº“: {len(kb_data)} ä¸ªç‰‡æ®µ")
    print(f"[INFO]   â†’ åˆ¤ä¾‹åº“: {len(case_data)} æ¡åˆ¤ä¾‹")
    print(f"[INFO]   â†’ RAG æ–‡ä»¶: {st.session_state.kb_files}")
    
    # 2. æ ‡è®°æ˜¯å¦éœ€è¦ä» GitHub åŠ è½½ RAGï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
    print("[INFO] æ­¥éª¤ 2/3: æ£€æŸ¥ RAG çŠ¶æ€...")
    if len(kb_data) == 0:
        st.session_state.rag_loading_needed = True
        st.session_state.rag_loading_status = "pending"
        print("[INFO]   âš ï¸  æœ¬åœ°çŸ¥è¯†åº“ä¸ºç©ºï¼Œå°†åœ¨åº”ç”¨å¯åŠ¨åä» GitHub åŠ è½½")
    else:
        st.session_state.rag_loading_needed = False
        st.session_state.rag_loading_status = "complete"
        print(f"[INFO]   âœ… ä½¿ç”¨æœ¬åœ°ç¼“å­˜: {len(kb_data)} ä¸ªç‰‡æ®µ")
    
    # 3. åŠ è½½ Prompt é…ç½®
    print("[INFO] æ­¥éª¤ 3/3: åŠ è½½ Prompt é…ç½®...")
    if PATHS.prompt_config_file.exists():
        try:
            with open(PATHS.prompt_config_file, 'r', encoding='utf-8') as f:
                st.session_state.prompt_config = json.load(f)
                print("[INFO]   âœ… å·²åŠ è½½è‡ªå®šä¹‰ Prompt é…ç½®")
        except Exception as e:
            print(f"[WARN]   âš ï¸  åŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
    if 'prompt_config' not in st.session_state:
        sys_prompt_content = ResourceManager.load_external_text(PATHS.SRC_SYS_PROMPT, fallback="ä½ æ˜¯ä¸€åèŒ¶è¯„ä¸“å®¶...")
        st.session_state.prompt_config = {
            "system_template": sys_prompt_content,
            "user_template": DEFAULT_USER_TEMPLATE
        }
        print("[INFO]   âœ… ä½¿ç”¨é»˜è®¤ Prompt é…ç½®")
    
    st.session_state.loaded = True
    print("="*70)
    print("[INFO] ========== ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼ˆå¿«é€Ÿå¯åŠ¨æ¨¡å¼ï¼‰==========")
    print("="*70 + "\n")



# B. ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ ç³»ç»Ÿé…ç½®")
    st.markdown("**ğŸ” API é…ç½®**")
    aliyun_key = os.getenv("ALIYUN_API_KEY") or st.secrets.get("ALIYUN_API_KEY", "")
    deepseek_key = os.getenv("DEEPSEEK_API_KEY") or st.secrets.get("DEEPSEEK_API_KEY", "")

    if not aliyun_key or not deepseek_key:
        st.warning("âš ï¸ æœªé…ç½® API Key")
        st.stop()
    else:
        st.success("âœ… API å°±ç»ª")

    st.markdown("---")
    st.markdown(f"**é¢„å¤„ç†æ¨¡å‹ï¼š** `Deepseek-chat`")
    st.markdown(f"**è¯„åˆ†æ¨¡å‹ï¼š** `Qwen2.5-7B-Instruct`")
    model_id = "Qwen2.5-7B-Instruct"
    try:
        resp = requests.get("http://117.50.89.74:8001/status", timeout=2)
        if resp.status_code == 200 and resp.json().get("lora_available"):
            model_id = "default_lora"
            st.success("ğŸ‰ å·²å¯ç”¨å¾®è°ƒæ¨¡å‹")
    except:
        pass
    ft_status = ResourceManager.load_ft_status()
    if ft_status and ft_status.get("status") == "succeeded":
        st.info(f"ğŸ‰ å‘ç°å¾®è°ƒæ¨¡å‹ï¼š`{ft_status.get('fine_tuned_model')}`")

    embedder = AliyunEmbedder(aliyun_key)
    client = OpenAI(api_key="dummy", base_url="http://117.50.89.74:8000/v1")
    client_d = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")
    
    bootstrap_seed_cases(embedder)
    
    # âœ… Ensure FAISS indices use cosine similarity (IP + normalized vectors)
    ensure_case_index_cosine(embedder)
    ensure_kb_index_cosine(embedder)
    st.markdown("---")
    
    # ===== å»¶è¿ŸåŠ è½½ RAG é€»è¾‘ =====
    kb_files = st.session_state.get('kb_files', [])
    kb_count = len(st.session_state.kb[1])
    case_count = len(st.session_state.cases[1])
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦ä» GitHub åŠ è½½ RAG
    if st.session_state.get('rag_loading_needed', False):
        loading_status = st.session_state.get('rag_loading_status', 'pending')
        
        if loading_status == 'pending':
            # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            with st.status("ğŸ”„ æ­£åœ¨ä» GitHub åŠ è½½çŸ¥è¯†åº“...", expanded=True) as status:
                st.write("ğŸ“¥ ä¸‹è½½ RAG æ–‡ä»¶...")
                st.session_state.rag_loading_status = 'loading'
                
                try:
                    # æ‰§è¡ŒåŠ è½½
                    success, msg = load_rag_from_github(aliyun_key)
                    
                    if success:
                        status.update(label="âœ… çŸ¥è¯†åº“åŠ è½½å®Œæˆ", state="complete", expanded=False)
                        st.session_state.rag_loading_status = 'complete'
                        st.session_state.rag_loading_needed = False
                        time.sleep(1)
                        st.rerun()
                    else:
                        status.update(label="âŒ çŸ¥è¯†åº“åŠ è½½å¤±è´¥", state="error", expanded=True)
                        st.error(msg)
                        st.info("ğŸ’¡ æ‚¨å¯ä»¥åœ¨ Tab3 æ‰‹åŠ¨ä¸Šä¼  RAG æ–‡ä»¶")
                        st.session_state.rag_loading_status = 'failed'
                        
                        # æ·»åŠ é‡è¯•æŒ‰é’®
                        if st.button("ğŸ”„ é‡è¯•åŠ è½½", type="secondary"):
                            st.session_state.rag_loading_status = 'pending'
                            st.rerun()
                except Exception as e:
                    status.update(label="âŒ åŠ è½½å‡ºé”™", state="error", expanded=True)
                    st.error(f"åŠ è½½å¤±è´¥: {str(e)}")
                    st.session_state.rag_loading_status = 'failed'
                    
                    if st.button("ğŸ”„ é‡è¯•åŠ è½½", type="secondary"):
                        st.session_state.rag_loading_status = 'pending'
                        st.rerun()
        
        elif loading_status == 'loading':
            st.info("ğŸ”„ æ­£åœ¨åŠ è½½çŸ¥è¯†åº“ï¼Œè¯·ç¨å€™...")
        
        elif loading_status == 'failed':
            st.warning("âš ï¸ çŸ¥è¯†åº“åŠ è½½å¤±è´¥")
            if st.button("ğŸ”„ é‡è¯•ä» GitHub åŠ è½½", type="secondary"):
                st.session_state.rag_loading_status = 'pending'
                st.rerun()
    
    # æ›´æ–°æ˜¾ç¤ºçš„æ•°æ®
    kb_count = len(st.session_state.kb[1])
    kb_files = st.session_state.get('kb_files', [])
    
    st.markdown(f"çŸ¥è¯†åº“: **{kb_count}** æ¡ | åˆ¤ä¾‹åº“: **{case_count}** æ¡")
    if kb_files:
        pass
    elif kb_count == 0:
        st.caption("âš ï¸ çŸ¥è¯†åº“ä¸ºç©ºï¼Œè¯·ä¸Šä¼ æ–‡ä»¶æˆ–ä»ä»äº‘ç«¯åŠ è½½")
    
    st.caption("å¿«é€Ÿä¸Šä¼ ä»…æ”¯æŒ.zipæ–‡ä»¶æ ¼å¼ã€‚")
    st.caption("å°‘é‡æ–‡ä»¶ä¸Šä¼ è¯·è‡³\"çŸ¥è¯†åº“è®¾è®¡\"æ¿å—ã€‚")
    
    if st.button("ğŸ“¤ å¯¼å‡ºæ•°æ®"):
        import zipfile, shutil
        temp_dir = Path("./temp_export"); temp_dir.mkdir(exist_ok=True)
        for p in [PATHS.kb_index, PATHS.kb_chunks, PATHS.case_index, PATHS.case_data, PATHS.prompt_config_file]:
            if p.exists(): shutil.copy2(p, temp_dir / p.name)
        zip_path = Path("./rag_export.zip")
        with zipfile.ZipFile(zip_path, 'w') as z:
            for f in temp_dir.iterdir(): z.write(f, f.name)
        with open(zip_path, 'rb') as f:
            st.download_button("â¬‡ï¸ ä¸‹è½½ZIP", f, "tea_data.zip", "application/zip")
        shutil.rmtree(temp_dir); zip_path.unlink()

    if st.button("ğŸ“¥ å¯¼å…¥æ•°æ®"):
        u_zip = st.file_uploader("ä¸Šä¼ ZIP", type=['zip'])
        if u_zip:
            import zipfile, tempfile
            with tempfile.TemporaryDirectory() as td:
                zp = Path(td)/"u.zip"
                with open(zp,'wb') as f: f.write(u_zip.getvalue())
                with zipfile.ZipFile(zp,'r') as z: z.extractall(PATHS.DATA_DIR)
                st.success("å¯¼å…¥æˆåŠŸï¼Œè¯·åˆ·æ–°"); st.rerun()

# C. ä¸»ç•Œé¢
st.markdown('<div class="main-title">ğŸµ èŒ¶å“å…­å› å­ AI è¯„åˆ†å™¨ Pro</div>', unsafe_allow_html=True)
st.markdown('<div class="slogan">"ä¸€ç‰‡å¶å­è½å…¥æ°´ä¸­ï¼Œæ”¹å˜äº†æ°´çš„å‘³é“..."</div>', unsafe_allow_html=True)

tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs(["ğŸ’¡ äº¤äº’è¯„åˆ†", "ğŸš€ æ‰¹é‡è¯„åˆ†", "ğŸ“• çŸ¥è¯†åº“è®¾è®¡", "ğŸ› ï¸ åˆ¤ä¾‹åº“ä¸å¾®è°ƒ", "ğŸ“² æç¤ºè¯ï¼ˆPromptï¼‰é…ç½®","æµ‹è¯•æ—¥å¿—"])

# --- Tab 1: äº¤äº’è¯„åˆ† ---
with tab1:
    st.info("å°†å‚è€ƒçŸ¥è¯†åº“ä¸åˆ¤ä¾‹åº“è¿›è¡Œè¯„åˆ†ã€‚ç¡®è®¤ç»“æœå¯ä¸€é”®æ›´æ–°åˆ¤ä¾‹åº“ã€‚")
    c1, c2, c3, c4, c5 = st.columns([1, 3, 1, 3, 1])
    r_num = c2.number_input("å‚è€ƒçŸ¥è¯†åº“æ¡ç›®æ•°é‡", 1, 20, 3, key="r1")
    c_num = c4.number_input("å‚è€ƒåˆ¤ä¾‹åº“æ¡ç›®æ•°é‡", 1, 20, 2, key="c1")
    
    if 'current_user_input' not in st.session_state: st.session_state.current_user_input = ""
    user_input = st.text_area("è¯·è¾“å…¥èŒ¶è¯„æè¿°:", value=st.session_state.current_user_input, height=150, key="ui")
    st.session_state.current_user_input = user_input
    
    if 'last_scores' not in st.session_state: 
        st.session_state.last_scores = None
        st.session_state.last_master_comment = ""
    
    # ç”¨äºç”ŸæˆåŠ¨æ€keyï¼Œç¡®ä¿æ¯æ¬¡æ–°è¯„åˆ†æ—¶æ ¡å‡†è¾“å…¥æ¡†æ˜¾ç¤ºæ–°å†…å®¹
    if 'score_version' not in st.session_state:
        st.session_state.score_version = 0
        
    if st.button("å¼€å§‹è¯„åˆ†", type="primary", use_container_width=True):
        if not user_input:
            st.warning("è¯·è¾“å…¥å†…å®¹")
        else:
            with st.spinner(f"æ­£åœ¨ä½¿ç”¨ {model_id} å“é‰´."):
                user_input = llm_normalize_user_input(user_input, client_d)
                st.session_state.current_user_input = user_input
    
                scores, kb_h, case_h = run_scoring(
                    user_input,
                    st.session_state.kb,
                    st.session_state.cases,
                    st.session_state.prompt_config,
                    embedder,
                    client,
                    "Qwen2.5-7B-Instruct",
                    r_num,
                    c_num
                )
    
                # âœ… åªåœ¨è¿™é‡Œä¿å­˜ï¼šæ­¤æ—¶ case_h ä¸€å®šå·²å®šä¹‰
                st.session_state.last_case_hits = case_h or []
                st.session_state.last_kb_hits = kb_h or []
    
                if scores:
                    st.session_state.last_scores = scores
                    st.session_state.last_master_comment = scores.get("master_comment", "")
                    st.session_state.score_version += 1
                    st.rerun()


        if st.session_state.last_scores:
            s = st.session_state.last_scores["scores"]
            mc = st.session_state.last_master_comment
            st.markdown(f'<div class="master-comment"><b>ğŸ‘µ å®—å¸ˆæ€»è¯„ï¼š</b><br>{mc}</div>', unsafe_allow_html=True)
            

    # âœ… Debug: å±•ç¤ºæœ¬æ¬¡å‘½ä¸­çš„åˆ¤ä¾‹ï¼ˆrerun åä»å¯è§ï¼‰
    st.caption(f"case_data æ¡æ•° = {len(st.session_state.cases[1])} | case_index.ntotal = {st.session_state.cases[0].ntotal}")
    case_h = st.session_state.get("last_case_hits", [])
    st.subheader("ğŸ” Debug: å‘½ä¸­çš„åˆ¤ä¾‹ï¼ˆTop-Kï¼‰")
    if case_h:
        for j, c in enumerate(case_h[:c_num], start=1):
            st.markdown(f"**#{j}** {c.get('text','')[:80]}...")
            st.caption(" | ".join([f"{k}:{v.get('score')}" for k,v in (c.get('scores') or {}).items()]))
    else:
        st.warning("Debug: æœªå‘½ä¸­ä»»ä½•åˆ¤ä¾‹ï¼ˆcase_h ä¸ºç©ºï¼‰")
    s = (st.session_state.last_scores or {}).get("scores", {}) or {}
    mc = st.session_state.get("last_master_comment", "")
    factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
    left_col, right_col = st.columns([35, 65]) 
    with left_col:
        st.subheader("ğŸ“Š é£å‘³å½¢æ€")
        st.pyplot(plot_flavor_shape(st.session_state.last_scores), use_container_width=True)
    with right_col:
        cols = st.columns(2)
        factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
        for i, f in enumerate(factors):
            if f in s:
                d = s[f]
                with cols[i%2]:
                    st.markdown(f"""<div class="factor-card"><div class="score-header"><span>{f}</span><span>{d['score']}/9</span></div><div>{d['comment']}</div><div class="advice-tag">ğŸ’¡ {d.get('suggestion','')}</div></div>""", unsafe_allow_html=True)
    
    st.subheader("ğŸ› ï¸ è¯„åˆ†æ ¡å‡†ä¸ä¿®æ­£")
    v = st.session_state.score_version  # è·å–å½“å‰ç‰ˆæœ¬å·
    mc = st.session_state.get("last_master_comment", "")
    cal_master = st.text_area("æ ¡å‡†æ€»è¯„", mc, key=f"cal_master_{v}")
    cal_scores = {}
    st.write("åˆ†é¡¹è°ƒæ•´")
    active_factors = [f for f in factors if f in s]
    grid_cols = st.columns(3) 
    for i, f in enumerate(active_factors):
        with grid_cols[i % 3]:
            with st.container(border=True):
                t_col, s_col = st.columns([1, 1])
                with t_col:
                    st.markdown(f"<div style='padding-top: 5px;'><b>ğŸ“Œ {f}</b></div>", unsafe_allow_html=True)
                with s_col:
                    new_score = st.number_input("åˆ†æ•°", 0, 9, int(s[f]['score']), 1, key=f"s_{f}_{v}", label_visibility="collapsed")
                cal_scores[f] = {
                    "score": new_score,
                    "comment": st.text_area(f"è¯„è¯­", s[f]['comment'], key=f"c_{f}_{v}", height=80, placeholder="è¯„è¯­"),
                    "suggestion": st.text_area(f"å»ºè®®", s[f].get('suggestion',''), key=f"sg_{f}_{v}", height=68, placeholder="å»ºè®®")
                }
    if st.button("ğŸ’¾ ä¿å­˜æ ¡å‡†è¯„åˆ†", type="primary"):
        # A. æ„é€ ä¸“å®¶æ•°æ®åŒ…
        expert_package = {"scores": cal_scores, "master_comment": cal_master}
        # B. æ„é€  AI æ•°æ®åŒ… (ç¡®ä¿ st.session_state.last_scores å­˜åœ¨)
        ai_package = st.session_state.last_scores

        with st.spinner("åŒæ­¥æ•°æ®åˆ°äº‘ç«¯è®°å¿†æ¨¡å—..."):
            # 1. å­˜å…¥åˆ¤ä¾‹åº“ (åŸæœ‰é€»è¾‘)
            nc_text = st.session_state.get("current_user_input", user_input)
            nc = {"text": nc_text, "scores": cal_scores, "tags": "äº¤äº’-æ ¡å‡†", "master_comment": cal_master, "created_at": time.strftime("%Y-%m-%d")}
            st.session_state.cases[1].append(nc)
            
            # âœ… embedding ä¸ nc["text"] å®Œå…¨ä¸€è‡´
            v = embedder.encode([nc_text]).astype("float32")
            faiss.normalize_L2(v)
            st.session_state.cases[0].add(v)
            ResourceManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS.case_index, PATHS.case_data, is_json=True)
            GithubSync.sync_cases(st.session_state.cases[1])
            
            # 2. å­˜å…¥è¯„æµ‹æ—¥å¿— (æ–°å¢é€»è¾‘ï¼šLLM-as-a-judge çš„åŸæ–™)
            EvaluationLogger.log_evaluation(
                text= st.session_state.get("current_user_input", user_input), 
                model_output=ai_package, 
                expert_output=expert_package
            )
        
        st.success("æ ¡å‡†å·²å­˜å…¥åˆ¤ä¾‹åº“ï¼Œè¯¯å·®æ•°æ®å·²å½’æ¡£ï¼")
        time.sleep(1)
        st.rerun()

# --- Tab 2: æ‰¹é‡è¯„åˆ† ---
with tab2:
    f = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ (.txt/.docx)")
    c1, c2, c3, c4, c5 = st.columns([1, 3, 1, 3, 1])
    r_n = c2.number_input("å‚è€ƒçŸ¥è¯†åº“æ¡ç›®æ•°é‡", 1, 20, 3, key="rb")
    c_n = c4.number_input("å‚è€ƒåˆ¤ä¾‹åº“æ¡ç›®æ•°é‡", 1, 20, 2, key="cb")
    if f and st.button("æ‰¹é‡å¤„ç†"):
        lines = [l.strip() for l in parse_file(f).split('\n') if len(l)>10]
        res, bar = [], st.progress(0)
        for i, l in enumerate(lines):
            l = llm_normalize_user_input(l, client_d)
            s, _, _ = run_scoring(l, st.session_state.kb, st.session_state.cases, st.session_state.prompt_config, embedder, client, "Qwen2.5-7B-Instruct", r_n, c_n)
            res.append({"id":i+1, "text":l, "scores":s})
            bar.progress((i+1)/len(lines))
        st.success("å®Œæˆ")
        st.download_button("ä¸‹è½½Word", create_word_report(res), "report.docx")
    
    # --- Tab 3: RAG ---
with tab3:
    st.subheader("ğŸ“š çŸ¥è¯†åº“ (RAG)")
    st.caption("ä¸Šä¼ PDF/æ–‡æ¡£ä»¥å¢å¼ºæ¨¡å‹å›ç­”çš„å‡†ç¡®æ€§ã€‚æ–‡ä»¶å°†åŒæ­¥åˆ°äº‘ç«¯ã€‚")
    colu1, colu2 = st.columns([7,3])
    with colu1:
        # ===== æ˜¾ç¤ºGitHubä¸Šçš„RAGæ–‡ä»¶åˆ—è¡¨ =====
        st.markdown("**ğŸ“ äº‘ç«¯ä¸Šçš„RAGæ–‡ä»¶ï¼š**")
        
        # è·å–GitHubä¸Šçš„æ–‡ä»¶åˆ—è¡¨
        if 'github_rag_files' not in st.session_state:
            st.session_state.github_rag_files = []
        
        col_refresh, col_spacer = st.columns([1, 3])
        with col_refresh:
            if st.button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", key="refresh_rag_list"):
                with st.spinner("æ­£åœ¨è·å–æ–‡ä»¶åˆ—è¡¨..."):
                    st.session_state.github_rag_files = GithubSync.list_rag_files()
                st.rerun()
        
        github_files = st.session_state.github_rag_files
    if not github_files:
        # é¦–æ¬¡åŠ è½½æ—¶å°è¯•è·å–
        github_files = GithubSync.list_rag_files()
        st.session_state.github_rag_files = github_files
    
    if github_files:
        st.info(f"å…± {len(github_files)} ä¸ªæ–‡ä»¶")
        
        # ç”¨äºè¿½è¸ªéœ€è¦åˆ é™¤çš„æ–‡ä»¶
        if 'rag_files_to_delete' not in st.session_state:
            st.session_state.rag_files_to_delete = set()
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªæ–‡ä»¶å¸¦åˆ é™¤æŒ‰é’®
        for fname in github_files:
            file_col, del_col = st.columns([5, 1])
            with file_col:
                if fname in st.session_state.rag_files_to_delete:
                    st.markdown(f"~~ğŸ“„ {fname}~~ *(å¾…åˆ é™¤)*")
                else:
                    st.markdown(f"ğŸ“„ {fname}")
            with del_col:
                if fname not in st.session_state.rag_files_to_delete:
                    if st.button("ğŸ—‘ï¸", key=f"del_rag_{fname}", help=f"åˆ é™¤ {fname}"):
                        st.session_state.rag_files_to_delete.add(fname)
                        st.rerun()
                else:
                    if st.button("â†©ï¸", key=f"undo_rag_{fname}", help="æ’¤é”€åˆ é™¤"):
                        st.session_state.rag_files_to_delete.discard(fname)
                        st.rerun()
        
        # å¦‚æœæœ‰å¾…åˆ é™¤çš„æ–‡ä»¶ï¼Œæ˜¾ç¤ºç¡®è®¤æŒ‰é’®
        if st.session_state.rag_files_to_delete:
            st.warning(f"âš ï¸ å°†åˆ é™¤ {len(st.session_state.rag_files_to_delete)} ä¸ªæ–‡ä»¶")
            del_col1, del_col2 = st.columns(2)
            with del_col1:
                if st.button("âœ… ç¡®è®¤åˆ é™¤", type="primary", key="confirm_del_rag"):
                    with st.spinner("æ­£åœ¨åˆ é™¤æ–‡ä»¶..."):
                        deleted = []
                        for fname in st.session_state.rag_files_to_delete:
                            if GithubSync.delete_rag_file(fname):
                                deleted.append(fname)
                        
                        # æ›´æ–°session state
                        st.session_state.github_rag_files = [f for f in github_files if f not in deleted]
                        
                        # æ›´æ–°æœ¬åœ°çŸ¥è¯†åº“æ–‡ä»¶åˆ—è¡¨
                        current_kb_files = st.session_state.get('kb_files', [])
                        st.session_state.kb_files = [f for f in current_kb_files if f not in deleted]
                        ResourceManager.save_kb_files(st.session_state.kb_files)
                        
                        st.session_state.rag_files_to_delete = set()
                        st.success(f"âœ… å·²åˆ é™¤ {len(deleted)} ä¸ªæ–‡ä»¶")
                        
                        # æç¤ºéœ€è¦é‡å»ºçŸ¥è¯†åº“
                        st.info("ğŸ’¡ æ–‡ä»¶å·²ä»äº‘ç«¯åˆ é™¤ã€‚å¦‚éœ€æ›´æ–°æœ¬åœ°çŸ¥è¯†åº“ï¼Œè¯·ç‚¹å‡»ä¸‹æ–¹çš„'é‡å»ºæœ¬åœ°çŸ¥è¯†åº“'æŒ‰é’®ã€‚")
                        time.sleep(1)
                        st.rerun()
            with del_col2:
                if st.button("âŒ å–æ¶ˆ", key="cancel_del_rag"):
                    st.session_state.rag_files_to_delete = set()
                    st.rerun()
    else:
        st.caption("æš‚æ— RAGæ–‡ä»¶")
    
    st.markdown("---")
    
    # ===== ä¸Šä¼ æ–°æ–‡ä»¶ï¼ˆæ·»åŠ æ¨¡å¼ï¼‰ =====
    st.markdown("**â• æ·»åŠ æ–°æ–‡ä»¶ï¼š**")
    up = st.file_uploader("é€‰æ‹©æ–‡ä»¶", accept_multiple_files=True, key="kb_uploader", 
                        type=['pdf', 'txt', 'docx'])
    
    if up and st.button("ğŸ“¤ æ·»åŠ åˆ°çŸ¥è¯†åº“", type="primary"):
        # æ£€æŸ¥æ˜¯å¦æœ‰é‡åæ–‡ä»¶
        new_names = [u.name for u in up]
        existing_names = st.session_state.get('github_rag_files', [])
        duplicate_names = set(new_names) & set(existing_names)
        
        if duplicate_names:
            st.warning(f"âš ï¸ ä»¥ä¸‹æ–‡ä»¶å·²å­˜åœ¨ï¼Œå°†è¢«è¦†ç›–ï¼š{', '.join(duplicate_names)}")
        
        with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶..."):
            # 1. è§£ææ–‡ä»¶å†…å®¹
            raw = "".join([parse_file(u) for u in up])
            
            if not raw.strip():
                st.error("âŒ æ— æ³•ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­æå–æœ‰æ•ˆæ–‡æœ¬")
            else:
                # 2. ä¸Šä¼ åˆ°GitHub
                with st.spinner("ä¸Šä¼ åˆ°GitHub..."):
                    success, uploaded_names = GithubSync.add_rag_files(up, "tea_data/RAG")
                
                if success:
                    # 3. æ›´æ–°æœ¬åœ°æ–‡ä»¶åˆ—è¡¨
                    current_kb_files = st.session_state.get('kb_files', [])
                    # åˆå¹¶æ–‡ä»¶åˆ—è¡¨ï¼ˆå»é‡ï¼‰
                    all_files = list(set(current_kb_files + uploaded_names))
                    st.session_state.kb_files = all_files
                    st.session_state.github_rag_files = list(set(existing_names + uploaded_names))
                    ResourceManager.save_kb_files(all_files)
                    
                    st.success(f"âœ… å·²ä¸Šä¼  {len(uploaded_names)} ä¸ªæ–‡ä»¶åˆ°GitHub")
                    st.info("ğŸ’¡ è¯·ç‚¹å‡»ä¸‹æ–¹çš„'é‡å»ºæœ¬åœ°çŸ¥è¯†åº“'æŒ‰é’®ä»¥æ›´æ–°å‘é‡ç´¢å¼•ã€‚")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.error("âŒ ä¸Šä¼ åˆ°GitHubå¤±è´¥")

# ===== é‡å»ºæœ¬åœ°çŸ¥è¯†åº“æŒ‰é’® =====
with colu2:
    st.markdown("**ğŸ”§ çŸ¥è¯†åº“ç»´æŠ¤ï¼š**")
    local_kb_count = len(st.session_state.kb[1])
    st.caption(f"ç½‘é¡µç«¯çŸ¥è¯†åº“ï¼š{local_kb_count} ä¸ªç‰‡æ®µ")
    
    # æ¯ä¸ªæ–‡ä»¶æ¢è¡Œæ˜¾ç¤º
    if kb_files:
        st.markdown("**ç½‘é¡µç«¯çŸ¥è¯†åº“æ–‡ä»¶:**")
        for fname in kb_files:
            st.markdown(f"- ğŸ“„ {fname}")
    else:
        st.markdown("**ç½‘é¡µç«¯çŸ¥è¯†åº“æ–‡ä»¶:** æ— ") 
    st.markdown("---")
    st.markdown("äº‘ç«¯æ•°æ®ä¸ç½‘é¡µæ•°æ®ä¸ç»Ÿä¸€ï¼Ÿ")
    if st.button("ğŸ”„ ä»äº‘ç«¯åŠ è½½çŸ¥è¯†åº“", use_container_width=True, type="primary"):
        with st.spinner("æ­£åœ¨ä»äº‘ç«¯æ‹‰å–å¹¶é‡å»ºçŸ¥è¯†åº“..."):
            success, msg = load_rag_from_github(aliyun_key)
            if success:
                st.success(msg)
                # æ›´æ–°GitHubæ–‡ä»¶åˆ—è¡¨
                st.session_state.github_rag_files = GithubSync.list_rag_files()
            else:
                st.error(msg)
        time.sleep(1)
        st.rerun()



with tab4:
    MANAGER_URL = "http://117.50.89.74:8001"
    c1, c2 = st.columns([5, 5])
    
    with c1:
        st.subheader("ğŸ“• åˆ¤ä¾‹åº“ (CASE)")        
        if st.button("ğŸ“‹ å±•ç¤ºå½“å‰åˆ¤ä¾‹", use_container_width=True):
            show_cases_dialog(embedder)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰“å¼€ç¼–è¾‘å¼¹çª—
        if st.session_state.get('editing_case_idx') is not None:
            edit_case_dialog(st.session_state.editing_case_idx, embedder)
        
        with st.expander("â• æ‰‹åŠ¨æ·»åŠ ç²¾ç»†åˆ¤ä¾‹"):
            with st.form("case_form"):
                f_txt = st.text_area("åˆ¤ä¾‹æè¿°", height=80)
                f_tag = st.text_input("æ ‡ç­¾", "äººå·¥å½•å…¥")
                st.markdown("**å› å­è¯„åˆ†è¯¦æƒ…**")
                fc1, fc2 = st.columns(2)
                factors = ["ä¼˜é›…æ€§", "è¾¨è¯†åº¦", "åè°ƒæ€§", "é¥±å’Œåº¦", "æŒä¹…æ€§", "è‹¦æ¶©åº¦"]
                input_scores = {}
                for i, f in enumerate(factors):
                    with (fc1 if i%2==0 else fc2):
                        val = st.number_input(f"{f}åˆ†æ•°", 0,9,7, key=f"s_{i}")
                        cmt = st.text_input(f"{f}è¯„è¯­", key=f"c_{i}")
                        sug = st.text_input(f"{f}å»ºè®®", key=f"a_{i}")
                        input_scores[f] = {"score": val, "comment": cmt, "suggestion": sug}
                
                if st.form_submit_button("ä¿å­˜åˆ¤ä¾‹å¹¶åŒæ­¥"):
                    new_c = {"text": f_txt, "tags": f_tag, "scores": input_scores, "created_at": time.strftime("%Y-%m-%d")}
                    st.session_state.cases[1].append(new_c)
                    vec = embedder.encode([f_txt]).astype("float32")
                    faiss.normalize_L2(vec)
                    st.session_state.cases[0].add(vec)
                    ResourceManager.save(st.session_state.cases[0], st.session_state.cases[1], PATHS.case_index, PATHS.case_data, is_json=True)
                    
                    # åŒæ­¥åˆ°GitHub
                    with st.spinner("åŒæ­¥åˆ°GitHub..."):
                        GithubSync.sync_cases(st.session_state.cases[1])
                    
                    st.success("å·²ä¿å­˜å¹¶åŒæ­¥ï¼")
                    time.sleep(1); st.rerun()
    
    # --- å³ä¾§ï¼šå¾®è°ƒæ§åˆ¶ ---
    with c2:
        st.subheader("ğŸš€ æ¨¡å‹å¾®è°ƒ (LoRA)")
        
        server_status = "unknown"
        try:
            resp = requests.get(f"{MANAGER_URL}/status", timeout=2)
            if resp.status_code == 200:
                status_data = resp.json()
                if status_data.get("vllm_status") == "running":
                    server_status = "idle"
                else:
                    server_status = "training"
            else:
                server_status = "error"
        except:
            server_status = "offline"
        
        if server_status == "idle":
            st.success("ğŸŸ¢ æœåŠ¡å™¨å°±ç»ª (æ­£åœ¨è¿›è¡Œæ¨ç†æœåŠ¡)")
        elif server_status == "training":
            st.warning("ğŸŸ  æ­£åœ¨å¾®è°ƒè®­ç»ƒä¸­... (æ¨ç†æœåŠ¡æš‚åœ)")
            st.markdown("âš ï¸ **æ³¨æ„ï¼š** æ­¤æ—¶æ— æ³•è¿›è¡Œè¯„åˆ†äº¤äº’ï¼Œè¯·è€å¿ƒç­‰å¾…è®­ç»ƒå®Œæˆã€‚")
        elif server_status == "offline":
            st.error("ğŸ”´ æ— æ³•è¿æ¥åˆ° GPU æœåŠ¡å™¨ (è¯·è”ç³»ç®¡ç†å‘˜)")
    
        st.markdown("#### 1. æ•°æ®å‡†å¤‡")
        
        if PATHS.training_file.exists():
            with open(PATHS.training_file, "r", encoding="utf-8") as f:
                lines = f.readlines()
            data_count = len(lines)
        else:
            data_count = 0
            
        st.info(f"å½“å‰å¾®è°ƒæ•°æ®ï¼š**{data_count} æ¡** | åˆ¤ä¾‹åº“ï¼š**{len(st.session_state.cases[1])} æ¡**")
        
        # ===== ä¿®æ”¹ï¼šè¦†ç›–é€»è¾‘ =====
        if st.button("ğŸ”„ å°†å½“å‰æ‰€æœ‰åˆ¤ä¾‹è½¬ä¸ºå¾®è°ƒæ•°æ®ï¼ˆè¦†ç›–ï¼‰"):
            cnt = ResourceManager.overwrite_finetune(
                st.session_state.cases[1],
                st.session_state.prompt_config.get('system_template',''), 
                st.session_state.prompt_config.get('user_template','')
            )
            st.success(f"å·²è¦†ç›–å†™å…¥ {cnt} æ¡å¾®è°ƒæ•°æ®ï¼")
            time.sleep(1); st.rerun()
    
        st.markdown("#### 2. å¯åŠ¨è®­ç»ƒ")
        st.caption("ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å°†æŠŠæ•°æ®ä¸Šä¼ è‡³ GPU æœåŠ¡å™¨å¹¶å¼€å§‹è®­ç»ƒã€‚è®­ç»ƒæœŸé—´æœåŠ¡å°†ä¸­æ–­çº¦ 2-5 åˆ†é’Ÿã€‚")
    
        btn_disabled = (server_status != "idle") or (data_count == 0)
        
        if st.button("ğŸ”¥ å¼€å§‹å¾®è°ƒ (Start LoRA)", type="primary", disabled=btn_disabled):
            if not PATHS.training_file.exists():
                st.error("æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼")
            else:
                try:
                    with open(PATHS.training_file, "rb") as f:
                        with st.spinner("æ­£åœ¨ä¸Šä¼ æ•°æ®å¹¶å¯åŠ¨è®­ç»ƒä»»åŠ¡..."):
                            files = {'file': ('tea_feedback.jsonl', f, 'application/json')}
                            r = requests.post(f"{MANAGER_URL}/upload_and_train", files=files, timeout=100)
                            
                        if r.status_code == 200:
                            st.balloons()
                            st.success(f"âœ… ä»»åŠ¡å·²æäº¤ï¼æœåŠ¡å™¨å“åº”: {r.json().get('message')}")
                            st.info("ğŸ’¡ ä½ å¯ä»¥ç¨ååˆ·æ–°é¡µé¢æŸ¥çœ‹çŠ¶æ€ï¼Œè®­ç»ƒå®ŒæˆåæœåŠ¡ä¼šè‡ªåŠ¨æ¢å¤ã€‚")
                        else:
                            st.error(f"âŒ æäº¤å¤±è´¥: {r.text}")
                except Exception as e:
                    st.error(f"âŒ è¿æ¥é”™è¯¯: {e}")

# --- Tab 4: Prompté…ç½® ---
with tab5:
    pc = st.session_state.prompt_config
    st.markdown("ç³»ç»Ÿæç¤ºè¯**å¯ä»¥ä¿®æ”¹**ã€‚å®Œæ•´å…¨é¢çš„æç¤ºè¯ä¼šè®©å¤§è¯­è¨€æ¨¡å‹è¿”å›çš„æ›´å‡†ç¡®ç»“æœã€‚")    
    sys_t = st.text_area("ç³»ç»Ÿæç¤ºè¯", pc.get('system_template',''), height=350)
    st.markdown("ç”¨æˆ·æç¤ºè¯**ä¸å¯ä¿®æ”¹**ã€‚å…¶ä¿è¯äº†å‘é€å†…å®¹ä¸å›ç­”å†…å®¹çš„åŸºæœ¬ç»“æ„ï¼Œå› æ­¤å¤§è¯­è¨€æ¨¡å‹çš„å›ç­”å¯è¢«å‡†ç¡®è§£æã€‚")
    user_t = st.text_area("ç”¨æˆ·æç¤ºè¯", pc.get('user_template',''), height=250, disabled=True)
    
    if st.button("ğŸ’¾ ä¿å­˜ï¼ˆæ°¸ä¹…åŒ–åŒæ­¥ï¼‰", type="primary"):
        if sys_t == pc.get('system_template'):
            st.info("å†…å®¹æ²¡æœ‰å˜åŒ–ï¼Œæ— éœ€ä¿å­˜ã€‚")
        else:
            new_cfg = {"system_template": sys_t, "user_template": user_t}
            
            with st.spinner("æ­£åœ¨è¿æ¥äº‘ç«¯ä»“åº“å¹¶å†™å…¥æ•°æ®..."):
                success = GithubSync.push_json(
                    file_path_in_repo="tea_data/prompts.json", 
                    data_dict=new_cfg,
                    commit_msg="Update prompts.json from App"
                )
            
            if success:
                st.success("âœ… æˆåŠŸå†™å…¥äº‘ç«¯ï¼")
                st.session_state.prompt_config = new_cfg
                with open(PATHS.prompt_config_file, 'w', encoding='utf-8') as f:
                    json.dump(new_cfg, f, ensure_ascii=False, indent=2)

with tab6:
    st.header("ğŸ§  æ¨¡å‹æ•ˆæœé‡åŒ–ä¸è¯¯å·®åˆ†æï¼ˆåŸºäºæ—¥å¿—ï¼‰")
    
    logs = EvaluationLogger.load_logs() or []
    logs = [l for l in logs if isinstance(l, dict)]
    
    # åªç»Ÿè®¡æœ‰â€œä¸“å®¶çœŸå€¼â€çš„æ ·æœ¬
    paired = [
        l for l in logs
        if l.get("model_prediction") and l.get("expert_ground_truth")
    ]
    
    total = len(logs)
    paired_n = len(paired)
    st.metric("æ—¥å¿—æ€»æ•°", total)
    st.metric("å¯è¯„ä¼°æ ·æœ¬ï¼ˆæœ‰ä¸“å®¶çœŸå€¼ï¼‰", paired_n)
    
    if paired_n == 0:
        st.info("æš‚æ— å¯é‡åŒ–çš„æ ·æœ¬ï¼šéœ€è¦å…ˆåœ¨äº¤äº’è¯„åˆ†é‡Œä¿å­˜ä¸“å®¶æ ¡å‡†ï¼ˆexpert_ground_truthï¼‰ã€‚")
    else:
        # --- è®¡ç®—æŒ‡æ ‡ ---
        per_factor_abs = {}   # factor -> list[abs_err]
        per_factor_signed = {}# factor -> list[signed_err] (model - expert)
        case_errors = []      # (total_abs_err, log_dict)
    
        for l in paired:
            m_scores = (l.get("model_prediction") or {}).get("scores", {}) or {}
            e_scores = (l.get("expert_ground_truth") or {}).get("scores", {}) or {}
    
            abs_list = []
            for factor, m_item in m_scores.items():
                e_item = e_scores.get(factor)
                if not isinstance(m_item, dict) or not isinstance(e_item, dict):
                    continue
                ms = m_item.get("score")
                es = e_item.get("score")
                if not isinstance(ms, (int, float)) or not isinstance(es, (int, float)):
                    continue
    
                signed = ms - es
                abs_err = abs(signed)
    
                per_factor_abs.setdefault(factor, []).append(abs_err)
                per_factor_signed.setdefault(factor, []).append(signed)
                abs_list.append(abs_err)
    
            # è¯¥æ¡æ ·æœ¬çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆè·¨ç»´åº¦ï¼‰
            if abs_list:
                case_errors.append((sum(abs_list) / len(abs_list), l))
    
        # æ€»ä½“ MAEï¼ˆè·¨æ‰€æœ‰ç»´åº¦çš„å¹³å‡ç»å¯¹è¯¯å·®ï¼‰
        all_abs = [x for xs in per_factor_abs.values() for x in xs]
        overall_mae = sum(all_abs) / len(all_abs) if all_abs else 0.0
    
        # æ–¹å‘æ€§åå·®ï¼šå¹³å‡ (model - expert)
        all_signed = [x for xs in per_factor_signed.values() for x in xs]
        overall_bias = sum(all_signed) / len(all_signed) if all_signed else 0.0
    
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("æ€»ä½“ MAEï¼ˆåˆ†ï¼‰", f"{overall_mae:.3f}")
        with c2:
            st.metric("æ€»ä½“åå·®ï¼ˆmodel-expertï¼‰", f"{overall_bias:+.3f}")
        with c3:
            st.metric("æ ¡å‡†è¦†ç›–ç‡", f"{paired_n/total:.1%}" if total else "0%")
    
        st.divider()
    
        # --- æ¯ç»´åº¦æŒ‡æ ‡ ---
        st.subheader("ğŸ“Š å„ç»´åº¦è¯¯å·®ï¼ˆMAEï¼‰ä¸åå·®æ–¹å‘")
        rows = []
        for factor in sorted(per_factor_abs.keys()):
            abs_errs = per_factor_abs[factor]
            signed_errs = per_factor_signed.get(factor, [])
            mae = sum(abs_errs) / len(abs_errs) if abs_errs else 0.0
            bias = sum(signed_errs) / len(signed_errs) if signed_errs else 0.0
            rows.append((factor, mae, bias, len(abs_errs)))
    
        # ç”¨ st.dataframe å±•ç¤ºï¼ˆä¸ä¾èµ– pandasï¼‰
        st.dataframe(
            [{"factor": f, "mae": round(mae, 3), "bias(model-expert)": round(bias, 3), "n": n}
             for (f, mae, bias, n) in rows],
            use_container_width=True
        )
    
        st.divider()
    
        # --- Top-N è¯¯å·®æ ·æœ¬å®šä½ ---
        st.subheader("ğŸ” è¯¯å·®æœ€å¤§æ ·æœ¬ Top-Nï¼ˆç”¨äºå®šä½é—®é¢˜ï¼‰")
        topn = st.slider("Top-N", min_value=3, max_value=30, value=10, step=1)
    
        case_errors.sort(key=lambda x: x[0], reverse=True)
        for rank, (err, l) in enumerate(case_errors[:topn], start=1):
            ts = l.get("timestamp", "unknown")
            txt = (l.get("input_text") or "")
            title = f"#{rank} | å¹³å‡è¯¯å·®={err:.3f} | {ts} | è¾“å…¥: {txt[:20]}..."
            with st.expander(title):
                col1, col2 = st.columns(2)
                with col1:
                    st.caption("ğŸ¤– æ¨¡å‹è¾“å‡º")
                    st.json(l.get("model_prediction", {}))
                with col2:
                    st.caption("ğŸ‘¨â€ğŸ« ä¸“å®¶çœŸå€¼")
                    st.json(l.get("expert_ground_truth", {}))
    
                # å¯é€‰ï¼šä¸€é”®è®© AI å†™â€œå·®å¼‚åŸå› åˆ†æâ€
                if not l.get("analysis"):
                    if st.button("âš–ï¸ è®© AI åˆ†æå·®å¼‚åŸå› ï¼ˆå†™å…¥æ—¥å¿—ï¼‰", key=f"judge_{l.get('id','noid')}"):
                        with st.spinner("AI æ­£åœ¨ç”Ÿæˆå·®å¼‚åŸå› åˆ†æ..."):
                            EvaluationLogger.run_judge(l["id"], client_d)  # ä½ é¡¹ç›®é‡Œä¸€èˆ¬å« client_d
                            st.success("å®Œæˆï¼Œå·²å†™å…¥æ—¥å¿— analysis å­—æ®µ")
                            st.rerun()
                else:
                    st.info(l["analysis"])
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    










